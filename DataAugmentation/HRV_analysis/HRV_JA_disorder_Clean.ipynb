{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2a20b02d-6ef3-4a6e-a45e-69cddd886137",
   "metadata": {},
   "source": [
    "# Data Augmentation- VAE, Diffusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21e6a98c-2f59-452a-b8b1-ee762e22acf9",
   "metadata": {},
   "source": [
    "> This script adopts HRV dataset for 3-class disease classification. \\\n",
    "> Major Depressive Disorder, Panic Disorder, Control. \\\n",
    "> Also contains various psychological scales (HAMD, HAMA, ...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4ddbef65-77a1-43fe-989a-0a0c7d4ead5e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "# import shap ## for XAI\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "# import pingouin as pg\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn.metrics as metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4882e3a3-161d-4d3e-bef3-b83010ca2cb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import dot\n",
    "from numpy.linalg import norm\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense , Dropout , Lambda, Flatten\n",
    "from keras.layers import Dense , Activation, Dropout, BatchNormalization\n",
    "from keras.optimizers import Adam ,RMSprop\n",
    "from keras.callbacks import Callback\n",
    "\n",
    "from scipy.special import rel_entr\n",
    "from scipy.stats import gaussian_kde\n",
    "from scipy.spatial.distance import jensenshannon\n",
    "\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, KFold, ParameterGrid\n",
    "from sklearn import decomposition\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import accuracy_score, cohen_kappa_score, f1_score, confusion_matrix, roc_auc_score, classification_report, precision_score, recall_score\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.preprocessing import Normalizer, MinMaxScaler, RobustScaler, StandardScaler\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler, EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.layers import Input, Concatenate, Dense, Lambda, Conv1D, Flatten, Reshape, UpSampling1D, MaxPooling1D, concatenate, Layer\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import layers, models, backend as K\n",
    "from tensorflow.keras.losses import mse, MeanSquaredError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3bf01643-b981-4d57-ae21-6822cf681a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "173afa80-706e-4320-b3c5-cabc098f7115",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler() #set the scaler (between 0 and 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57cfaf0e-1296-43a9-a547-8dba9168a6ba",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03baaf49-19f6-4559-8906-1d8fb2d49ae7",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cdf5bb1-4eca-4da1-b06e-5c62e8549841",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2eecc614-ad90-4684-b320-e30dc72b4870",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_ori = pd.read_csv('E:/RESEARCH/Datasets/HRV/JA/HRV_dataset_processed_240920.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "908e53a5-d0d4-469a-9aa3-72c9f0f2f413",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3969, 38)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_ori.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9a2e4e00-27f6-4477-a68a-c03cae9e20de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['subject', 'gender', 'age', 'auto_activity', 'auto_balance',\n",
       "       'stress_resist', 'stress_index', 'tired', 'avg_hr', 'heart_stable',\n",
       "       'abnormal_hr', 'sdnn', 'psi', 'tp', 'vlf', 'lf', 'hf', 'lfnorm',\n",
       "       'hfnorm', 'lf_hf', 'rmssd', 'apen', 'srd', 'tsrd', 'tp_ln', 'vlf_ln',\n",
       "       'lf_ln', 'hf_ln', 'main_dx', 'subtype', 'second_dx', 'third_dx', 'HAMD',\n",
       "       'HAMA', 'BDI-II', 'BAI', 'MDQ', 'HCL-32'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_ori.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ef0ff73-a6ae-43e2-ad2d-d39061e6ea85",
   "metadata": {},
   "source": [
    "> processing the NaN values and outlier values (due to the srd and abnormal_hr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "50c10540-7820-4eb9-b55f-bc1e56ff585b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_ori = data_ori.dropna(subset=['srd'])\n",
    "data_ori = data_ori[(data_ori.srd >=0.8) & (data_ori.srd <= 1.0)] ## srd outlier removed - there were 1424 outlier data\n",
    "data_ori = data_ori[(data_ori.abnormal_hr) <= 5] ## abnormal heart rate outlier removed - there were 175 outlier data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a4403115-0081-4087-b098-c3c3c484b367",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2196, 38)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_ori.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c7b7cb3a-dd1e-43a6-9f71-e3d97900f97b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of the original dataset is: (2196, 38)\n"
     ]
    }
   ],
   "source": [
    "### data shape, variables check\n",
    "print(f\"The shape of the original dataset is: {data_ori.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d0edc4b1-37db-4c95-ad24-e143b4094011",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of rows of the original dataset is: 2196\n",
      "The number of rows that contains at least one missing value: 2173\n"
     ]
    }
   ],
   "source": [
    "# 결측값이 하나라도 있는 행의 개수 확인\n",
    "num_missing_rows = data_ori.isna().any(axis=1).sum()\n",
    "print(f\"The number of rows of the original dataset is: {data_ori.shape[0]}\")\n",
    "print(f\"The number of rows that contains at least one missing value: {num_missing_rows}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d6b4f18-73bf-4bf3-87aa-87484a359d25",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d57267d7-1656-4f5a-aed2-22c4fc92c88c",
   "metadata": {},
   "source": [
    "### target check"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a991786-c830-4ea6-890f-4df0cfe0bdac",
   "metadata": {},
   "source": [
    "> combine HAMD, BDI to depression, and HAMA, BAI to anxious"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "10f25bad-bb4d-4ef3-a398-caade0c4870f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['subject', 'gender', 'age', 'auto_activity', 'auto_balance',\n",
       "       'stress_resist', 'stress_index', 'tired', 'avg_hr', 'heart_stable',\n",
       "       'abnormal_hr', 'sdnn', 'psi', 'tp', 'vlf', 'lf', 'hf', 'lfnorm',\n",
       "       'hfnorm', 'lf_hf', 'rmssd', 'apen', 'srd', 'tsrd', 'tp_ln', 'vlf_ln',\n",
       "       'lf_ln', 'hf_ln', 'main_dx', 'subtype', 'second_dx', 'third_dx', 'HAMD',\n",
       "       'HAMA', 'BDI-II', 'BAI', 'MDQ', 'HCL-32'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_ori.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "63fa6e68-d632-417e-be3a-6b7574c6ad70",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "main_dx\n",
       "MDDs                   325\n",
       "MDDr                   277\n",
       "BP_II                  204\n",
       "PD                     194\n",
       "Adj                    194\n",
       "PDAG                   170\n",
       "SSD                    159\n",
       "PDD                    119\n",
       "DEP_NOS                106\n",
       "GAD                     93\n",
       "ANX_NOS                 68\n",
       "OCD                     35\n",
       "ADHD                    34\n",
       "BP_I                    33\n",
       "insomnia                28\n",
       "SAD                     27\n",
       "PTSD                    26\n",
       "SPR                     20\n",
       "Alcohol dependence      19\n",
       "Tourette                12\n",
       "Tic                      8\n",
       "Normal                   7\n",
       "OMS                      5\n",
       "MCI                      5\n",
       "SP                       5\n",
       "acute stress             5\n",
       "AG                       2\n",
       "IED                      2\n",
       "PMDD                     2\n",
       "Conversion               2\n",
       "conversion               2\n",
       "Asperger                 1\n",
       "body dysmorphic          1\n",
       "Pathologic gambling      1\n",
       "Tabacco withdrawal       1\n",
       "adj                      1\n",
       "x                        1\n",
       "AN                       1\n",
       "Delirium                 1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_ori.main_dx.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5d20bc14-5af4-4551-b48e-3a5cc63e591d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>auto_activity</th>\n",
       "      <th>auto_balance</th>\n",
       "      <th>stress_resist</th>\n",
       "      <th>stress_index</th>\n",
       "      <th>tired</th>\n",
       "      <th>avg_hr</th>\n",
       "      <th>heart_stable</th>\n",
       "      <th>...</th>\n",
       "      <th>main_dx</th>\n",
       "      <th>subtype</th>\n",
       "      <th>second_dx</th>\n",
       "      <th>third_dx</th>\n",
       "      <th>HAMD</th>\n",
       "      <th>HAMA</th>\n",
       "      <th>BDI-II</th>\n",
       "      <th>BAI</th>\n",
       "      <th>MDQ</th>\n",
       "      <th>HCL-32</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A0001</td>\n",
       "      <td>F</td>\n",
       "      <td>64</td>\n",
       "      <td>50.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>...</td>\n",
       "      <td>SSD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PDD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>7</td>\n",
       "      <td>2.0</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A0002</td>\n",
       "      <td>F</td>\n",
       "      <td>27</td>\n",
       "      <td>101.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>105.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>...</td>\n",
       "      <td>BP_II</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cluster B</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A0004</td>\n",
       "      <td>F</td>\n",
       "      <td>41</td>\n",
       "      <td>93.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>105.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>116.0</td>\n",
       "      <td>...</td>\n",
       "      <td>SSD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PDAG</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>A0006</td>\n",
       "      <td>F</td>\n",
       "      <td>47</td>\n",
       "      <td>81.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>124.0</td>\n",
       "      <td>109.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>...</td>\n",
       "      <td>PDD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GAD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>10</td>\n",
       "      <td>4.0</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>A0008</td>\n",
       "      <td>F</td>\n",
       "      <td>35</td>\n",
       "      <td>139.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>...</td>\n",
       "      <td>SSD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>6</td>\n",
       "      <td>12.0</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  subject gender  age  auto_activity  auto_balance  stress_resist  \\\n",
       "0   A0001      F   64           50.0          76.0           59.0   \n",
       "1   A0002      F   27          101.0          74.0          105.0   \n",
       "3   A0004      F   41           93.0          92.0          100.0   \n",
       "5   A0006      F   47           81.0          53.0           73.0   \n",
       "7   A0008      F   35          139.0          89.0          129.0   \n",
       "\n",
       "   stress_index  tired  avg_hr  heart_stable  ...  main_dx  subtype  \\\n",
       "0         150.0  150.0    82.0          50.0  ...      SSD      NaN   \n",
       "1          87.0   92.0    68.0          91.0  ...    BP_II      NaN   \n",
       "3          91.0  105.0    71.0         116.0  ...      SSD      NaN   \n",
       "5         124.0  109.0    86.0          82.0  ...      PDD      NaN   \n",
       "7          66.0   77.0    60.0         150.0  ...      SSD      NaN   \n",
       "\n",
       "   second_dx  third_dx  HAMD  HAMA  BDI-II  BAI   MDQ  HCL-32  \n",
       "0        PDD       NaN  11.0  14.0    19.0    7   2.0    11.0  \n",
       "1  cluster B       NaN  18.0  17.0    43.0  NaN   7.0     1.0  \n",
       "3       PDAG       NaN  26.0  32.0    40.0  NaN   3.0     0.0  \n",
       "5        GAD       NaN  14.0  16.0    21.0   10   4.0    12.0  \n",
       "7        NaN       NaN  16.0  19.0    11.0    6  12.0    17.0  \n",
       "\n",
       "[5 rows x 38 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_ori.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "89a7ab2b-a247-475b-ba33-fe82d3e15612",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = data_ori[data_ori['main_dx'].isin(['MDDs','MDDr','PDD','BP_II','PD','Adj', 'PDAG','SSD','PDD','GAD'])]\n",
    "# df = data_ori[data_ori['main_dx'].isin(['MDDs','MDDr','PDD'])]\n",
    "df = data_ori"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51992614-6827-492c-aedf-d1eca8a6555e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebe8c844-ccdf-4e31-a745-512c1afe732f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7d0d266c-c4f4-41e2-a73d-b8539c403dec",
   "metadata": {},
   "source": [
    "### Variables drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "0342d987-312d-4388-9e04-0fcba04e73f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['subject', 'gender', 'age', 'auto_activity', 'auto_balance',\n",
       "       'stress_resist', 'stress_index', 'tired', 'avg_hr', 'heart_stable',\n",
       "       'abnormal_hr', 'sdnn', 'psi', 'tp', 'vlf', 'lf', 'hf', 'lfnorm',\n",
       "       'hfnorm', 'lf_hf', 'rmssd', 'apen', 'srd', 'tsrd', 'tp_ln', 'vlf_ln',\n",
       "       'lf_ln', 'hf_ln', 'main_dx', 'subtype', 'second_dx', 'third_dx', 'HAMD',\n",
       "       'HAMA', 'BDI-II', 'BAI', 'MDQ', 'HCL-32'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "d6981a7e-29ff-44e0-b2df-5047d1463e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "info_list = ['subject' ,'gender', 'age']\n",
    "scale_list = ['HAMD', 'HAMA', 'BDI-II', 'BAI', 'MDQ', 'HCL-32']\n",
    "target_list = ['main_dx']\n",
    "hr_list = ['auto_activity', 'auto_balance', 'stress_resist', 'stress_index', 'tired', 'avg_hr', 'heart_stable', 'abnormal_hr']\n",
    "\n",
    "# drop_list = info_list + scale_list + target_list\n",
    "drop_list = info_list + scale_list + target_list + hr_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "1a4aa9e2-1e28-4517-a21e-56b0ee28ec2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['subtype', 'second_dx', 'third_dx'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "f058ba67-2e2e-4412-be84-74c7940ad11e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['subject', 'gender', 'age', 'auto_activity', 'auto_balance',\n",
       "       'stress_resist', 'stress_index', 'tired', 'avg_hr', 'heart_stable',\n",
       "       'abnormal_hr', 'sdnn', 'psi', 'tp', 'vlf', 'lf', 'hf', 'lfnorm',\n",
       "       'hfnorm', 'lf_hf', 'rmssd', 'apen', 'srd', 'tsrd', 'tp_ln', 'vlf_ln',\n",
       "       'lf_ln', 'hf_ln', 'main_dx', 'HAMD', 'HAMA', 'BDI-II', 'BAI', 'MDQ',\n",
       "       'HCL-32'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "743dad16-0d46-4fa7-9ca8-31085a0c2b5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gender\n",
       "F    505\n",
       "M    216\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.gender.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6cd31bd-fa3f-4841-a4a5-4c04c539f9c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8f99886c-d984-4989-a955-acfd917dbd27",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dd7f908-d2a5-4939-b109-2f2f784b0bce",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Distribution check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37422c91-54a5-48d7-a3b4-7b9403b7f3ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_vis = data_ori.copy()\n",
    "data_vis.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0de08029-7af1-485c-af10-7ed88ba7eb54",
   "metadata": {},
   "outputs": [],
   "source": [
    "info_ = ['sub', 'VISIT', 'age', 'gender', 'disorder_mdd']\n",
    "# info_ = ['sub', 'VISIT', 'age', 'gender', 'disorder', 'disorder_mdd']\n",
    "scale_ = ['HAMD', 'HAMA', 'PDSS', 'ASI', 'APPQ', 'PSWQ', 'SPI', 'PSS', 'BIS', 'SSI']\n",
    "drop_ = info_ + scale_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a49d31d-d3ea-49b5-841b-ab40fdbc47a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_ = data_vis.drop(drop_, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9f8cb63-fac8-4b72-9c4d-884142dce35e",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78a2ecae-f6ae-44eb-bbba-490845d1c19e",
   "metadata": {},
   "source": [
    "#### KDE plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc513b78-1111-4303-a85b-981be282841b",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [col for col in list(x.columns)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f93b026-aed9-4b00-9038-f2f9c0672650",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kdeplot_features(data, feature, title):\n",
    "    \n",
    "    df0 = data[data['disorder']==\"mdd\"]\n",
    "    df1 = data[data['disorder']==\"pd\"]\n",
    "    df2 = data[data['disorder']==\"con\"]\n",
    "\n",
    "    df0 = df0.drop(['disorder'], axis=1)\n",
    "    df1 = df1.drop(['disorder'], axis=1)\n",
    "    df2 = df2.drop(['disorder'], axis=1)\n",
    "    \n",
    "    df0_values = df0[feature].to_numpy()\n",
    "    df1_values = df1[feature].to_numpy()\n",
    "    df2_values = df2[feature].to_numpy()\n",
    "     \n",
    "    plt.figure(figsize = (6, 2.5))\n",
    "    \n",
    "    sns.kdeplot(df0_values, color = 'y')\n",
    "    sns.kdeplot(df1_values, color = 'b')\n",
    "    sns.kdeplot(df2_values, color = 'g')\n",
    "    \n",
    "    plt.title(title, fontsize=15)\n",
    "    plt.legend()\n",
    "    plt.show();\n",
    "    \n",
    "    # del values_train , values_test\n",
    "    # gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "145f370a-e7e2-43d8-a852-9d2eecbbc57a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for var in features:\n",
    "    kdeplot_features(x_, feature=var, title = var + \"distribution\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85bc4e77-3523-4066-986d-bb6f9b24ca2a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c1a965d6-b485-4eb2-9bab-eb817409832e",
   "metadata": {},
   "source": [
    "#### JSD calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f06c5f9-2a6d-4e6c-be28-8e10c7186e24",
   "metadata": {},
   "outputs": [],
   "source": [
    "## list to append distributional differences\n",
    "variable = []\n",
    "diff01 = []\n",
    "diff02 = []\n",
    "diff03 = []\n",
    "diff12 = []\n",
    "diff13 = []\n",
    "diff23 = []\n",
    "\n",
    "for feature in features:\n",
    "    ## deleting any NA values in each feature column, for distance calculation\n",
    "    data = data_vis.dropna(subset=[feature])\n",
    "\n",
    "    ## split the dataset into each classes\n",
    "    df0 = data[data['target_info']==\"control\"]\n",
    "    df1 = data[data['target_info']==\"mdd\"]\n",
    "    df2 = data[data['target_info']==\"bpi\"]\n",
    "    df3 = data[data['target_info']==\"bpii\"]\n",
    "\n",
    "    df0 = df0.drop(['target_info'], axis=1)\n",
    "    df1 = df1.drop(['target_info'], axis=1)\n",
    "    df2 = df2.drop(['target_info'], axis=1)\n",
    "    df3 = df3.drop(['target_info'], axis=1)\n",
    "    \n",
    "    df0_values = df0[feature]\n",
    "    df1_values = df1[feature]\n",
    "    df2_values = df2[feature]\n",
    "    df3_values = df3[feature]\n",
    "\n",
    "    ## sampling based on the minimum size of the target info.\n",
    "    sample_size = (min(df0_values.shape[0], df1_values.shape[0], df2_values.shape[0], df3_values.shape[0]))\n",
    "    df0_sample = df0_values.sample(n=(sample_size))\n",
    "    df1_sample = df1_values.sample(n=(sample_size))\n",
    "    df2_sample = df2_values.sample(n=(sample_size))\n",
    "    df3_sample = df3_values.sample(n=(sample_size))\n",
    "\n",
    "    ## jensen-shannon divergence calculation and append\n",
    "    variable.append(feature)\n",
    "    diff01.append(jensenshannon(df0_sample, df1_sample))\n",
    "    diff02.append(jensenshannon(df0_sample, df2_sample))\n",
    "    diff03.append(jensenshannon(df0_sample, df3_sample))\n",
    "    diff12.append(jensenshannon(df1_sample, df2_sample))\n",
    "    diff13.append(jensenshannon(df1_sample, df3_sample))\n",
    "    diff23.append(jensenshannon(df2_sample, df3_sample)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f76991d9-f00c-4eff-be6e-239c519eaca3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d990b52e-f0f1-4e37-8e78-52ad9acdc13d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1a790933-91fd-4c5e-81b8-7fbf723533cf",
   "metadata": {},
   "source": [
    "--------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c1cd5d4-ff8e-4c15-b42f-276833e80bec",
   "metadata": {},
   "source": [
    "----------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad1a5c67-d878-405a-a9f8-82423bbc0f86",
   "metadata": {},
   "source": [
    "# Data Augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72688524-49ea-430b-b106-45a383ae0483",
   "metadata": {},
   "source": [
    "## dataset for model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0997cdb8-24cf-4e5c-97af-15df171e525e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data_ori.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb6d7157-98be-41dd-86a7-f5608e50c9b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_CON = data[data['disorder']==\"con\"]\n",
    "data_PD = data[data['disorder']==\"pd\"]\n",
    "data_MDD = data[data['disorder']==\"mdd\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00b20739-123e-4919-b470-8927a558f62c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_vae = data.copy()\n",
    "# data_vae = data_con.copy()\n",
    "# data_vae = data_pd.copy()\n",
    "# data_vae = data_mdd.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40387281-62c2-4293-9bba-99636db90593",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b22dbbc0-3dd7-4fd0-9041-e53865ff384f",
   "metadata": {},
   "source": [
    "## Variational Autoencoder (VAE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12d7aefa-d3f3-4d5f-bb6b-5263c40e8385",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Args_vae:\n",
    "    # arugments\n",
    "    epochs=150\n",
    "    bs=32\n",
    "    lr=0.0001\n",
    "    momentum=0.9\n",
    "    num_classes= 2\n",
    "    latent_dim = 2\n",
    "    seed=710674\n",
    "\n",
    "args_vae = Args_vae()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2e77906-6db1-4e08-a0cf-9f745d2c62d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4a9fc98d-616a-4be3-bbce-8e19f3307c9c",
   "metadata": {},
   "source": [
    "### preparing x, y dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dcfc6e8-e64f-4aad-a0e9-b42f3f05a7b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "scale_list = ['HAMD', 'HAMA', 'PDSS', 'ASI', 'APPQ', 'PSWQ', 'SPI', 'PSS', 'BIS', 'SSI']\n",
    "etc_list = ['sub', 'VISIT', 'disorder_mdd']\n",
    "demo_list = ['age', 'gender', 'disorder']\n",
    "drop_list = scale_list + etc_list + demo_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2a10a29-e8fb-4768-93fe-6168376f0d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = data.drop((drop_list), axis=1)\n",
    "x = x.fillna(x.mean())\n",
    "y = data.disorder# mdd / pd / con"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "640ad571-cd55-43dd-88a8-1520cfd717bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_x = x.copy()\n",
    "data_x[:] = (scaler.fit_transform(data_x[:])).round(decimals=6) ## scaling x values\n",
    "\n",
    "label = y.copy()\n",
    "label = label.replace({'mdd': 0})\n",
    "label = label.replace({'pd': 1})\n",
    "label = label.replace({'con' : 2})\n",
    "data_y = to_categorical(label, 3) ## into the format of one-hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bce530e4-07f7-49d5-be98-a0692741743b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The size of x dataset is:\", data_x.shape)\n",
    "print(\"The size of y dataset is:\", data_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8254ba3-98e7-446b-b9cb-17c28c07934f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5f0f958b-c75f-46cf-ba90-aabe6e3b242a",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "797d6516-5f26-4afd-a1ca-21efe1021660",
   "metadata": {},
   "source": [
    "### vae model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12bd6248-3ced-4948-a427-8149c8e180d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE:\n",
    "    def __init__(self, input_dim, latent_dim):\n",
    "        self.input_dim = input_dim\n",
    "        self.latent_dim = latent_dim\n",
    "        self.encoder = None\n",
    "        self.decoder = None\n",
    "        self.vae = None\n",
    "        self.build_model()\n",
    "\n",
    "    ## VAE model for data augmentation\n",
    "    def build_model(self):\n",
    "        ####################################################\n",
    "        ## defining encoder section\n",
    "        inputs = Input(shape=(self.input_dim,))\n",
    "        \n",
    "        # shallow model use\n",
    "        h = Dense(32, activation='relu')(inputs)\n",
    "\n",
    "        # # deeper model use\n",
    "        # h = Dense(128, activation='relu')(inputs)\n",
    "        # h = Dense(64, activation='relu')(h)\n",
    "        # h = Dense(32, activation='relu')(h)\n",
    "\n",
    "        # calculating mean/var\n",
    "        z_mean = Dense(self.latent_dim)(h)\n",
    "        z_log_var = Dense(self.latent_dim)(h)\n",
    "\n",
    "        ## sampling section (for gaussian distribution)\n",
    "        def sampling(args):\n",
    "            z_mean, z_log_var = args\n",
    "            batch = K.shape(z_mean)[0]\n",
    "            dim = K.int_shape(z_mean)[1]\n",
    "            epsilon = K.random_normal(shape=(batch, dim))\n",
    "            return z_mean + K.exp(0.5 * z_log_var) * epsilon\n",
    "\n",
    "        z = Lambda(sampling, output_shape=(self.latent_dim,))([z_mean, z_log_var])\n",
    "\n",
    "        ####################################################\n",
    "        ## defining decoder section\n",
    "\n",
    "        # shallower model use\n",
    "        decoder_h = Dense(32, activation='relu')\n",
    "        decoder_mean = Dense(self.input_dim, activation='sigmoid')\n",
    "        h_decoded = decoder_h(z)\n",
    "        x_decoded_mean = decoder_mean(h_decoded)\n",
    "        \n",
    "        # # deeper model use\n",
    "        # decoder_h1 = Dense(32, activation='relu')\n",
    "        # decoder_h2 = Dense(64, activation='relu')\n",
    "        # decoder_h3 = Dense(128, activation='relu')\n",
    "        # decoder_mean = Dense(self.input_dim, activation='sigmoid')\n",
    "\n",
    "        # h_decoded = decoder_h1(z)\n",
    "        # h_decoded = decoder_h2(h_decoded)\n",
    "        # h_decoded = decoder_h3(h_decoded)\n",
    "        # x_decoded_mean = decoder_mean(h_decoded)\n",
    "\n",
    "        ####################################################\n",
    "        ## defining VAE model\n",
    "        self.vae = Model(inputs, x_decoded_mean)\n",
    "\n",
    "        ####################################################\n",
    "        ## defining loss function (reconstruction + KL divergence)\n",
    "        reconstruction_loss = MeanSquaredError()(inputs, x_decoded_mean)\n",
    "        kl_loss = -0.5 * K.sum(1 + z_log_var - K.square(z_mean) - K.exp(z_log_var + K.epsilon()), axis=-1)\n",
    "        vae_loss = K.mean(reconstruction_loss + kl_loss)\n",
    "        self.vae.add_loss(vae_loss)\n",
    "\n",
    "        ####################################################\n",
    "        ## compiling model\n",
    "        self.vae.compile(optimizer=Adam(learning_rate=0.001))\n",
    "\n",
    "        ####################################################\n",
    "        ## Extracting encoder and decoder separately\n",
    "        ## encoder section\n",
    "        self.encoder = Model(inputs, z_mean)\n",
    "\n",
    "        ## decoder section\n",
    "        decoder_input = Input(shape=(self.latent_dim,))\n",
    "        _h_decoded = decoder_h(decoder_input)\n",
    "        _x_decoded_mean = decoder_mean(_h_decoded)\n",
    "        self.decoder = Model(decoder_input, _x_decoded_mean)\n",
    "        \n",
    "        # #### deeper model\n",
    "        # decoder_input = Input(shape=(self.latent_dim,))\n",
    "        # _h_decoded = decoder_h1(decoder_input)\n",
    "        # _h_decoded = decoder_h2(_h_decoded)\n",
    "        # _h_decoded = decoder_h3(_h_decoded)\n",
    "        # _x_decoded_mean = decoder_mean(_h_decoded)\n",
    "        # self.decoder = Model(decoder_input, _x_decoded_mean)\n",
    "    \n",
    "    ####################################################\n",
    "    ####################################################\n",
    "    ## Model training\n",
    "    def train(self, data, epochs, batch_size, validation_split):\n",
    "        self.vae.fit(data, epochs=epochs, batch_size=batch_size, validation_split=validation_split)\n",
    "\n",
    "    def encode(self, data):\n",
    "        return self.encoder.predict(data)\n",
    "\n",
    "    def decode(self, latent_points):\n",
    "        return self.decoder.predict(latent_points)\n",
    "\n",
    "    def generate_synthetic_data(self, num_samples=1):\n",
    "        latent_samples = np.random.normal(size=(num_samples, self.latent_dim)) ## sampling from latent space\n",
    "        return self.decode(latent_samples) ## synthetic data generation with decoder section\n",
    "\n",
    "    def visualize_latent_space(self, data, labels):\n",
    "        ## encode the dataset into latent space\n",
    "        encoded_data = self.encode(data)\n",
    "\n",
    "        ## latent space visualization with t-SNE\n",
    "        tsne = TSNE(n_components=2, random_state=710674)\n",
    "        encoded_data_tsne = tsne.fit_transform(encoded_data)\n",
    "\n",
    "        ## Visualize\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        plt.scatter(encoded_data_tsne[:, 0], encoded_data_tsne[:, 1], c=labels, cmap='viridis')\n",
    "        plt.colorbar()\n",
    "        plt.xlabel(\"t-SNE component 1\")\n",
    "        plt.ylabel(\"t-SNE component 2\")\n",
    "        plt.title(\"t-SNE visualization of the latent space\")\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b519795-e972-46dd-aa18-6485cd044e76",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "vae = VAE(input_dim=data_x.shape[1], latent_dim=args_vae.latent_dim)\n",
    "vae.train(data_x, epochs = args_vae.epochs, batch_size = args_vae.bs, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eec8c330-9e7d-4339-be91-ca88cde8972d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d41ae535-2ade-4963-a709-d96f43475e01",
   "metadata": {},
   "source": [
    "### Latent space visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32e235a2-97e6-477d-a78e-2d0ab44bd129",
   "metadata": {},
   "outputs": [],
   "source": [
    "vae.visualize_latent_space(data_x, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fb4121a-9bdd-4b39-b752-ad3afe3b8ff4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5c8de385-71df-496c-ae62-f99725b6f39e",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a782e6f7-f737-4dc9-9265-df31bd7a7e15",
   "metadata": {},
   "source": [
    "### Synthetic data generation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dc58508-4b08-43b7-8a09-b7576b8e65da",
   "metadata": {},
   "source": [
    "> We use two different synthetic data generation functions.\n",
    "> 1. Adopting single VAE model(trained on all data classes)\n",
    "> 2. Adopting individual VAE model for each data classes. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc60dfc3-5254-40e6-b71a-a0a06bd6f34d",
   "metadata": {},
   "source": [
    "#### single VAE model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b0e7f06-e243-419a-a18d-843058e1aba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_ori['disorder'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a77cc22a-1632-4adb-be4c-4a8b7e36fd25",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_synthetic_data_for_classes(vae_model, latent_dim, class_labels, num_samples_per_class):\n",
    "    synthetic_data = {}\n",
    "    for class_label in class_labels:\n",
    "        num_samples = num_samples_per_class[class_label]\n",
    "        ## sampling from latent space\n",
    "        z_samples = np.random.normal(size=(num_samples, latent_dim))\n",
    "        ## use sampled data to generate synthetic dataset\n",
    "        generated_samples = vae_model.decoder.predict(z_samples)\n",
    "        ## save synthetic dataset with class label\n",
    "        synthetic_data[class_label] = generated_samples\n",
    "    return synthetic_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee7835c7-80b2-47c3-949a-5a81f6a1b999",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 생성할 클래스 라벨들과 각 클래스별 생성할 샘플 수\n",
    "num_samples_per_class = {0:164, 1:151, 2: 106} ##Set to total 300 for each class\n",
    "\n",
    "# 각 클래스별 synthetic data 생성\n",
    "synthetic_data = generate_synthetic_data_for_classes(vae, args_vae.latent_dim, label, num_samples_per_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e251b81-d4f1-4c79-97fc-9c95ab0e9a85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 각 클래스에 대한 데이터프레임화\n",
    "gen_mdd = pd.DataFrame(synthetic_data[0], columns=data_x.columns)\n",
    "gen_pd = pd.DataFrame(synthetic_data[1], columns=data_x.columns)\n",
    "gen_con = pd.DataFrame(synthetic_data[2], columns=data_x.columns)\n",
    "print(f\"The synthetic data size is... \\n\\nSynthetic for MDD class: {gen_mdd.shape[0]} \\nSynthetic for PD class: {gen_pd.shape[0]} \\nSynthetic for control class: {gen_con.shape[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1688b2b-cc7c-4ee3-bd7b-d25e917fe6ad",
   "metadata": {},
   "source": [
    "> now move to \"Classification performance check - Augmented datasets add\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aded5443-440f-4ab1-9263-a7243f37b23e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f2dbfadc-32b6-4641-99a5-38cf2e3ca0e0",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d212692c-5901-4188-aaac-f730acb897b9",
   "metadata": {},
   "source": [
    "#### individual VAE model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1ce9692-9794-48c4-9dfe-87bcb7f9d5b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_class_synthetic_data_vae(vae_model, latent_dim, num_samples):\n",
    "    ## sampling from latent space\n",
    "    z_samples = np.random.normal(size=(num_samples, latent_dim))\n",
    "    ## use sampled latent space vector to generate synthetic dataset\n",
    "    synthetic_data = vae_model.decoder.predict(z_samples)\n",
    "    return synthetic_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3e516a0-0667-4cde-9b53-b19577cdfce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_mdd, data_pd, data_con = (data_MDD.drop(drop_list, axis=1), data_PD.drop(drop_list, axis=1), data_CON.drop(drop_list, axis=1))\n",
    "\n",
    "data_mdd[:] = (scaler.fit_transform(data_mdd[:])).round(decimals=6)\n",
    "data_pd[:] = (scaler.fit_transform(data_pd[:])).round(decimals=6)\n",
    "data_con[:] = (scaler.fit_transform(data_con[:])).round(decimals=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ce85933-2807-438b-9832-d8b0937e8df9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# MDD 클래스에 대한 VAE 모델 학습\n",
    "vae_mdd = VAE(data_mdd.shape[1], latent_dim = args_vae.latent_dim)\n",
    "vae_mdd.train(data_mdd, epochs=args_vae.epochs, batch_size=args_vae.bs, validation_split=0.2)\n",
    "\n",
    "# PD 클래스에 대한 VAE 모델 학습\n",
    "vae_pd = VAE(data_pd.shape[1], latent_dim = args_vae.latent_dim)\n",
    "vae_pd.train(data_pd, epochs=args_vae.epochs, batch_size=args_vae.bs, validation_split=0.2)\n",
    "\n",
    "# Control 클래스에 대한 VAE 모델 학습\n",
    "vae_con = VAE(data_con.shape[1], latent_dim = args_vae.latent_dim)\n",
    "vae_con.train(data_con, epochs=args_vae.epochs, batch_size=args_vae.bs, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6e9a269-5a81-4140-91c7-a82bfea06018",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples_per_class = {0:164, 1:151, 2: 106}\n",
    "\n",
    "num_samples_mdd = num_samples_per_class[0]\n",
    "synthetic_data_mdd = generate_class_synthetic_data_vae(vae_mdd, args_vae.latent_dim, num_samples_mdd)\n",
    "\n",
    "num_samples_pd = num_samples_per_class[1]\n",
    "synthetic_data_pd = generate_class_synthetic_data_vae(vae_pd, args_vae.latent_dim, num_samples_pd)\n",
    "\n",
    "num_samples_con = num_samples_per_class[2]\n",
    "synthetic_data_con = generate_class_synthetic_data_vae(vae_con, args_vae.latent_dim, num_samples_con)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5abe0d1-b678-4307-b31d-d781681a3746",
   "metadata": {},
   "outputs": [],
   "source": [
    "## transform into the dataframe format\n",
    "gen_mdd = pd.DataFrame(synthetic_data_mdd, columns=data_x.columns)\n",
    "gen_pd = pd.DataFrame(synthetic_data_pd, columns=data_x.columns)\n",
    "gen_con = pd.DataFrame(synthetic_data_con, columns=data_x.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5277f2a8-02ad-45f0-bf64-c9e2d5e0f2f2",
   "metadata": {},
   "source": [
    "> now move to \"Classification performance check - Augmented datasets add\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f40d3851-908f-4687-bcfa-e38b4f1a052e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9743ac3-520e-4654-ac30-3534ceff5881",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "95411c46-079c-4c9c-ab27-ff0efab3ebb8",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b995646d-680f-4e9b-82de-d2a5c100b308",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "143e2c7a-98b9-4dd5-bc53-cd541a0abf17",
   "metadata": {},
   "source": [
    "## Conditional VAE model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6b9b771-ad71-492c-bdc7-ec62558c9e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Args_cvae:\n",
    "    # arugments\n",
    "    epochs=150\n",
    "    bs=32\n",
    "    lr=0.0001\n",
    "    momentum=0.9\n",
    "    num_classes= 3\n",
    "    latent_dim = 2\n",
    "    seed=710674\n",
    "\n",
    "args_cvae = Args_cvae()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e358116f-32bc-47c1-8a9b-e175f214d8e3",
   "metadata": {},
   "source": [
    "> preparing x, y dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f7196dd-d531-4896-b879-0c922ff17877",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_cvae = data_ori.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76b83362-5a42-434b-b671-92b322f99b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## relabeling data_cvae's disorder variable to use them as an conditional input\n",
    "data_cvae['disorder'] = data_cvae['disorder'].replace({'mdd': 0})\n",
    "data_cvae['disorder'] = data_cvae['disorder'].replace({'pd' : 1})\n",
    "data_cvae['disorder'] = data_cvae['disorder'].replace({'con': 2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82bb0103-1f46-46ec-86dd-1a78c5cbbb25",
   "metadata": {},
   "outputs": [],
   "source": [
    "scale_list = ['HAMD', 'HAMA', 'PDSS', 'ASI', 'APPQ', 'PSWQ', 'SPI', 'PSS', 'BIS', 'SSI']\n",
    "etc_list = ['sub', 'VISIT', 'disorder_mdd']\n",
    "demo_list = ['age', 'gender', 'disorder']\n",
    "drop_list = scale_list + etc_list + demo_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc9ef456-4692-4992-8cf6-900f097323e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## x: input, y: output, c: conditional inputs\n",
    "x = data_cvae.drop(drop_list, axis=1)\n",
    "x = x.fillna(x.mean())\n",
    "y = data_cvae.disorder\n",
    "c = data_cvae.loc[:, ('age', 'gender', 'disorder')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64ac578c-a68a-4815-bbd0-d37c1557c856",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_x = x.copy()\n",
    "data_x[:] = (scaler.fit_transform(data_x[:])).round(decimals=6)\n",
    "###################\n",
    "label = y.copy()\n",
    "data_y = to_categorical(label, 3) ## into the format of one-hot encoding\n",
    "###################\n",
    "data_c = c.copy()\n",
    "data_c[:] = (scaler.fit_transform(data_c[:])).round(decimals=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "518b262b-66df-4686-87cf-2422fb53b796",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The size of x dataset is:\", data_x.shape)\n",
    "print(\"The size of y dataset is:\", data_y.shape)\n",
    "print(\"The size of c dataset is:\", data_c.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78067da8-db50-4a35-b7f1-88bcb5867291",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a4584f46-9dbc-41bb-9b51-4e8dbcae0010",
   "metadata": {},
   "source": [
    "> CVAE model preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3b5dfbd-6c87-42e2-9d55-f7ab6b71b804",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CVAE:\n",
    "    def __init__(self, input_dim, condition_dim, latent_dim):\n",
    "        ## initializing model\n",
    "        self.input_dim = input_dim\n",
    "        self.condition_dim = condition_dim\n",
    "        self.latent_dim = latent_dim\n",
    "        \n",
    "        ## generating encoder and decoder section\n",
    "        self.encoder = self.build_encoder()\n",
    "        self.decoder = self.build_decoder()\n",
    "        self.cvae = self.build_cvae()\n",
    "    \n",
    "    ## defining encoder function\n",
    "    def build_encoder(self):\n",
    "        x_input = layers.Input(shape=(self.input_dim,), name='input')\n",
    "        c_input = layers.Input(shape=(self.condition_dim,), name='condition')\n",
    "        \n",
    "        ## defining input layer: put x and condition c together\n",
    "        combined_input = layers.Concatenate()([x_input, c_input])\n",
    "        \n",
    "        # encoder layers defining\n",
    "        h = layers.Dense(64, activation=None)(combined_input)\n",
    "        h = layers.BatchNormalization()(h)\n",
    "        h = layers.Activation('relu')(h)\n",
    "        h = layers.Dropout(0.3)(h)\n",
    "        \n",
    "        h = layers.Dense(32, activation=None)(h)\n",
    "        h = layers.BatchNormalization()(h)\n",
    "        h = layers.Activation('relu')(h)\n",
    "        h = layers.Dropout(0.3)(h)\n",
    "        \n",
    "        z_mean = layers.Dense(self.latent_dim, name='z_mean')(h)\n",
    "        z_log_var = layers.Dense(self.latent_dim, name='z_log_var')(h)\n",
    "        \n",
    "        ## sampling (reparameterization)\n",
    "        def sampling(args):\n",
    "            z_mean, z_log_var = args\n",
    "            batch = K.shape(z_mean)[0]\n",
    "            dim = K.int_shape(z_mean)[1]\n",
    "            epsilon = K.random_normal(shape=(batch, dim))\n",
    "            return z_mean + K.exp(0.5 * z_log_var) * epsilon\n",
    "        \n",
    "        z = layers.Lambda(sampling, output_shape=(self.latent_dim,), name='z')([z_mean, z_log_var])\n",
    "        \n",
    "        return Model([x_input, c_input], [z_mean, z_log_var, z], name='encoder')\n",
    "    \n",
    "    ## defining decoder function\n",
    "    def build_decoder(self):\n",
    "        z_input = layers.Input(shape=(self.latent_dim,), name='z_sampling')\n",
    "        c_input = layers.Input(shape=(self.condition_dim,), name='condition')\n",
    "        \n",
    "        ## decoder input defining: put latent space input and conditional c together\n",
    "        combined_input = layers.Concatenate()([z_input, c_input])\n",
    "\n",
    "        # decoder layers defining\n",
    "        h = layers.Dense(32, activation=None)(combined_input)\n",
    "        h = layers.BatchNormalization()(h)\n",
    "        h = layers.Activation('relu')(h)\n",
    "        h = layers.Dropout(0.3)(h)  # Dropout with 30% rate\n",
    "        \n",
    "        h = layers.Dense(64, activation=None)(h)\n",
    "        h = layers.BatchNormalization()(h)\n",
    "        h = layers.Activation('relu')(h)\n",
    "        h = layers.Dropout(0.3)(h)  # Dropout with 30% rate\n",
    "        \n",
    "        x_decoded = layers.Dense(self.input_dim, activation='sigmoid', name='output')(h)\n",
    "        \n",
    "        return Model([z_input, c_input], x_decoded, name='decoder')\n",
    "    \n",
    "    ## build and compile the CVAE model\n",
    "    def build_cvae(self):\n",
    "        x_input = layers.Input(shape=(self.input_dim,), name='input')\n",
    "        c_input = layers.Input(shape=(self.condition_dim,), name='condition')\n",
    "        \n",
    "        z_mean, z_log_var, z = self.encoder([x_input, c_input])\n",
    "        x_decoded = self.decoder([z, c_input])\n",
    "        \n",
    "        cvae = Model([x_input, c_input], x_decoded, name='cvae')\n",
    "        \n",
    "        reconstruction_loss = mse(x_input, x_decoded)\n",
    "        reconstruction_loss *= self.input_dim\n",
    "        \n",
    "        kl_loss = 1 + z_log_var - K.square(z_mean) - K.exp(z_log_var)\n",
    "        kl_loss = K.sum(kl_loss, axis=-1)\n",
    "        kl_loss *= -0.5\n",
    "        \n",
    "        cvae_loss = K.mean(reconstruction_loss + kl_loss)\n",
    "        cvae.add_loss(cvae_loss)\n",
    "        cvae.compile(optimizer='adam')\n",
    "        \n",
    "        return cvae\n",
    "    \n",
    "    def encode(self, data, condition):\n",
    "        z_mean, z_log_var, z = self.encoder.predict([data, condition])\n",
    "        return z_mean, z_log_var, z\n",
    "\n",
    "    def decode(self, latent, condition):\n",
    "        return self.decoder.predict([latent, condition])\n",
    "    \n",
    "    ## model training\n",
    "    def train(self, x_train, c_train, epochs, batch_size, validation_split=None):\n",
    "        self.cvae.fit([x_train, c_train], epochs=epochs, batch_size=batch_size, validation_split=validation_split)\n",
    "    \n",
    "    ## synthetic data generation (for data augmentation)\n",
    "    def generate_synthetic_data(self, condition, n_samples):\n",
    "        z_samples = np.random.normal(size=(n_samples, self.latent_dim))\n",
    "        synthetic_data = self.decoder.predict([z_samples, condition])\n",
    "        return synthetic_data\n",
    "\n",
    "\n",
    "    def visualize_latent_space(self, x_data, c_data, labels, n_samples):\n",
    "        c_data = np.array(data_c)\n",
    "        n_samples = min(n_samples, len(x_data), len(c_data))\n",
    "        indices = np.random.choice(len(x_data), n_samples, replace=False) ## data sampling for n\n",
    "        x_sample = x_data.iloc[indices]\n",
    "        c_sample = c_data[indices]\n",
    "        z_mean, _, _ = self.encoder.predict([x_sample, c_sample]) ## calculating latent vector z\n",
    "        tsne = TSNE(n_components=2, random_state=710674) #tsne visualization\n",
    "        z_tsne = tsne.fit_transform(z_mean)\n",
    "\n",
    "        ## visualization\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        if labels is not None:\n",
    "            plt.scatter(z_tsne[:, 0], z_tsne[:, 1], c=labels[indices], cmap='viridis')\n",
    "            plt.colorbar()\n",
    "        else:\n",
    "            plt.scatter(z_tsne[:, 0], z_tsne[:, 1])\n",
    "        plt.title('t-SNE visualization of the latent space')\n",
    "        plt.xlabel('t-SNE 1')\n",
    "        plt.ylabel('t-SNE 2')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb698af1-02a1-42f9-99b2-10b84c29e61f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cvae = CVAE(input_dim = data_x.shape[1], condition_dim = data_c.shape[1], latent_dim=args_cvae.latent_dim)\n",
    "cvae.train(data_x, data_c, epochs=args_cvae.epochs, batch_size=args_cvae.bs, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fb68103-ec3e-4bbb-97e9-111b287134d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2b307b6f-6507-4b5c-9a48-5189c76de85d",
   "metadata": {},
   "source": [
    "> Latent space visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2a88eb1-3c0a-4ed7-a960-b4f28db3d315",
   "metadata": {},
   "outputs": [],
   "source": [
    "cvae.visualize_latent_space(data_x, data_c, label, n_samples=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a89d066-5ef1-43e6-9d62-3721bc8b15d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60811c06-abb8-4ae6-8ffc-3a1d1c034c3c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "250d704d-a4bc-466d-923b-3ba46eb6adf2",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e28d859-6da8-4689-9015-64a6ed57f6e6",
   "metadata": {},
   "source": [
    "> Synthetic data generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a4c22a4-2c6b-4fd8-8a2d-4777c2ea060e",
   "metadata": {},
   "outputs": [],
   "source": [
    "label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bdd3c54-22b0-451a-b700-7f72ea906575",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "81a859cc-609e-4221-ba57-a36c67cae09e",
   "metadata": {},
   "source": [
    "#### Using single CVAE model (integrated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9327c748-b69d-48f8-bbf9-b17b8a6fdcf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_class_synthetic_data(cvae_model, c_data, n_samples_per_class, labels, method):\n",
    "    synthetic_data = {}\n",
    "    new_conditions = {}\n",
    "\n",
    "    for class_label, n_samples in n_samples_per_class.items():\n",
    "        ## filtering the condition for each class\n",
    "        class_indices = labels == class_label\n",
    "        class_conditions = c_data[class_indices]\n",
    "        \n",
    "        if class_conditions.empty:\n",
    "            print(f\"Warning: No data found for class label {class_label}. Skipping this class.\")\n",
    "            continue\n",
    "        \n",
    "        ## generating new condition for conditional VAE data augmentation\n",
    "        ## randomly sampling from the original condition dataset\n",
    "        if method == 'random':\n",
    "            class_new_conditions = class_conditions.sample(n=n_samples, replace=True).values\n",
    "        ## calculate mean and variance from original condition dataset to sampling\n",
    "        elif method == 'gaussian':\n",
    "            mean = class_conditions.mean(axis=0).values\n",
    "            std = class_conditions.std(axis=0).values\n",
    "            class_new_conditions = np.random.normal(loc=mean, scale=std, size=(n_samples, class_conditions.shape[1]))\n",
    "        \n",
    "        ## generate synthetic dataset for each class with new conditions\n",
    "        class_synthetic_data = cvae_model.generate_synthetic_data(class_new_conditions, n_samples=n_samples)\n",
    "        \n",
    "        ## save the synthesized results\n",
    "        synthetic_data[class_label] = class_synthetic_data\n",
    "        new_conditions[class_label] = class_new_conditions\n",
    "    \n",
    "    return synthetic_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "953103f1-47aa-4fcc-9149-3741d58ae38b",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples_per_class = {0:164, 1:151, 2: 106}\n",
    "## synthetic data generation (augmentation)\n",
    "# synthetic_data = generate_class_synthetic_data(cvae, data_c, n_samples_per_class, label, method='random')\n",
    "synthetic_data = generate_class_synthetic_data(cvae, data_c, n_samples_per_class, label, method='gaussian')\n",
    "\n",
    "# print(\"\\n=====================================\")\n",
    "# print(\"Class 0(MDD) - Generated Synthetic Data: \")\n",
    "# print(synthetic_data[0])\n",
    "# print(\"\\n=====================================\")\n",
    "# print(\"\\nClass 1(PD) - Generated Synthetic Data:\")\n",
    "# print(synthetic_data[1])\n",
    "# print(\"\\n=====================================\")\n",
    "# print(\"\\nClass 1(CON) - Generated Synthetic Data:\")\n",
    "# print(synthetic_data[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7a0ccfc-39f5-4aac-b8d9-bb2d77da638a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## transform into the dataframe format\n",
    "gen_mdd = pd.DataFrame(synthetic_data[0], columns=data_x.columns)\n",
    "gen_pd = pd.DataFrame(synthetic_data[1], columns=data_x.columns)\n",
    "gen_con = pd.DataFrame(synthetic_data[2], columns=data_x.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac9597c3-20d3-4d2f-92d9-906a63768324",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f5ae357a-e499-4c63-b960-127dc31cc4be",
   "metadata": {},
   "source": [
    "====================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea79db0e-193b-49f1-903d-efb16df100a7",
   "metadata": {},
   "source": [
    "#### Using individual CVAE model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71c11fdb-1e09-4d8f-bf39-b719c207c08c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## we should train individual CVAE model for each class\n",
    "cvae_models = {}\n",
    "\n",
    "for class_label in np.unique(label):\n",
    "    ## data filtering to find dataset with that class label\n",
    "    class_indices = np.where(label == class_label)[0]\n",
    "    class_data = data_x.iloc[class_indices]\n",
    "    \n",
    "    ## initialize and train CVAE model\n",
    "    cvae = CVAE(input_dim=data_x.shape[1], latent_dim=args_cvae.latent_dim, condition_dim=data_y.shape[1])\n",
    "    cvae.train(class_data, data_y[class_indices], epochs=args_cvae.epochs, batch_size=args_cvae.bs, validation_split=0.2)\n",
    "    \n",
    "    ## save the trained model\n",
    "    cvae_models[class_label] = cvae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02a008b0-8826-4d9a-8644-106754f472f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_class_synthetic_data_seperately(cvae_models, c_data, n_samples_per_class, labels, method):\n",
    "    synthetic_data = {}\n",
    "    new_conditions = {}\n",
    "\n",
    "    for class_label, n_samples in n_samples_per_class.items():\n",
    "        ## loading trained CVAE model for each class\n",
    "        cvae_model = cvae_models[class_label]\n",
    "        \n",
    "        ## filtering the condition for the class\n",
    "        class_indices = labels == class_label\n",
    "        class_conditions = c_data[class_indices]\n",
    "\n",
    "        ## generating new condition for conditional VAE data augmentation\n",
    "        ## randomly sampling from the original condition dataset\n",
    "        if method == 'random':\n",
    "            class_new_conditions = class_conditions.sample(n=n_samples, replace=True).values\n",
    "        ## calculate mean and variance from origianl condition dataset to sampling\n",
    "        elif method == 'gaussian':\n",
    "            mean = class_conditions.mean(axis=0).values\n",
    "            std = class_conditions.std(axis=0).values\n",
    "            class_new_conditions = np.random.normal(loc=mean, scale=std, size=(n_samples, class_conditions.shape[1]))\n",
    "        \n",
    "        ## generate synthetic dataset for each class with new conditions\n",
    "        class_synthetic_data = cvae_model.generate_synthetic_data(class_new_conditions, n_samples=n_samples)\n",
    "        \n",
    "        ## save the synthesized results\n",
    "        synthetic_data[class_label] = class_synthetic_data\n",
    "        new_conditions[class_label] = class_new_conditions\n",
    "    \n",
    "    # return synthetic_data, new_conditions\n",
    "    return synthetic_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61f21353-7556-4997-8e54-caa1a82657fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples_per_class = {0:164, 1:151, 2: 106}\n",
    "\n",
    "synthetic_data = generate_class_synthetic_data_seperately(cvae_models, data_c, n_samples_per_class, label, method=\"random\")\n",
    "# synthetic_data = generate_class_synthetic_data_seperately(cvae_models, data_c, n_samples_per_class, label, method=\"gaussian\")\n",
    "\n",
    "# print(\"\\n=====================================\")\n",
    "# print(\"Class 0(MDD) - Generated Synthetic Data: \")\n",
    "# print(synthetic_data[0])\n",
    "# print(\"\\n=====================================\")\n",
    "# print(\"\\nClass 1(PD) - Generated Synthetic Data:\")\n",
    "# print(synthetic_data[1])\n",
    "# print(\"\\n=====================================\")\n",
    "# print(\"\\nClass 1(CON) - Generated Synthetic Data:\")\n",
    "# print(synthetic_data[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be256307-b7a2-46f4-b9dc-f802cabed7cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "## transform into the dataframe format\n",
    "gen_mdd = pd.DataFrame(synthetic_data[0], columns=data_x.columns)\n",
    "gen_pd = pd.DataFrame(synthetic_data[1], columns=data_x.columns)\n",
    "gen_con = pd.DataFrame(synthetic_data[2], columns=data_x.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "915af965-9fdb-4cd5-9c15-3f35767e8b61",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bcc6eb8f-52e9-4376-83f1-078ccd4f12f9",
   "metadata": {},
   "source": [
    "-=-=-=-=-=-="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9674ff09-5db3-4fed-bc2a-73e3e52014c5",
   "metadata": {},
   "source": [
    "> Reconstruct original dataset using trained model to adopt augmented trainig dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfb69f6e-c4a0-40b0-a1d3-28a848beb20b",
   "metadata": {},
   "outputs": [],
   "source": [
    "z_mean, z_log_var, z_latent = cvae.encode(data_x, data_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26ff0d62-6fc1-49f3-a942-4de6e40a1a0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "reconstructed_data = cvae.decode(z_latent, data_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e3ad27b-0745-49aa-aa0a-321622529aea",
   "metadata": {},
   "outputs": [],
   "source": [
    "reconstructed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a81749b-fbbc-427d-aa50-42597c245810",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68159035-db8f-414b-a9d2-d322c21044b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_mdd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8491406-0098-4a01-bfe1-68caacbaefb3",
   "metadata": {},
   "source": [
    "-=-=-=-=-=-="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72f9b6ef-3771-49a3-b4a5-df9c25e7bb04",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4c356d3-bcaa-4389-a583-4c5fab1dce89",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8264f9bb-bc66-40a9-90c9-0bb4bdc25965",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c2aad34-7583-4996-aaee-cd00c2241feb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e50635f7-443e-45af-8a07-b55c9ced68cf",
   "metadata": {},
   "source": [
    "----------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd232e5c-c1a7-4d8f-8144-14dc2bf64f50",
   "metadata": {},
   "source": [
    "-----------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95a8736b-d296-4c8d-aace-9dd5d109a0cb",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Latent Diffusion Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0788b712-d306-4b80-9017-b89025cd26cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Args_diffusion:\n",
    "    # arugments\n",
    "    epochs=80\n",
    "    bs=32\n",
    "    lr=0.0001\n",
    "    momentum=0.9\n",
    "    num_classes= 3\n",
    "    latent_dim = 4\n",
    "    seed=710674\n",
    "\n",
    "args_diffusion = Args_diffusion()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db2e0517-bac5-41f1-9ea5-574aa3a05e4a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "* preparing x, y dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb51d8f6-f44c-4a88-bda9-5f174523aa2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_diffusion = data_ori.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "234de504-6572-4337-8ecc-ac194e367ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_CON = data_diffusion[data_diffusion['disorder']==\"con\"]\n",
    "data_PD = data_diffusion[data_diffusion['disorder']==\"pd\"]\n",
    "data_MDD = data_diffusion[data_diffusion['disorder']==\"mdd\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d55cb8e-fc72-4bd4-bf13-c6ef1f5e3976",
   "metadata": {},
   "outputs": [],
   "source": [
    "scale_list = ['HAMD', 'HAMA', 'PDSS', 'ASI', 'APPQ', 'PSWQ', 'SPI', 'PSS', 'BIS', 'SSI']\n",
    "etc_list = ['sub', 'VISIT', 'disorder_mdd']\n",
    "demo_list = ['age', 'gender', 'disorder']\n",
    "drop_list = scale_list + etc_list + demo_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd0577fb-4861-4013-ae60-d300183aa2d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = data_diffusion.drop((drop_list), axis=1)\n",
    "x = x.fillna(x.mean())\n",
    "y = data_diffusion.disorder# mdd / pd / con"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a043a2b4-d4de-4aad-b1ab-3e114940842e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_x = x.copy()\n",
    "data_x[:] = (scaler.fit_transform(data_x[:])).round(decimals=6) ## scaling x values\n",
    "\n",
    "label = y.copy()\n",
    "label = label.replace({'mdd': 0})\n",
    "label = label.replace({'pd': 1})\n",
    "label = label.replace({'con' : 2})\n",
    "data_y = to_categorical(label, 3) ## into the format of one-hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d61450ab-71aa-4ac2-99f1-43d3520a5288",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The size of x dataset is:\", data_x.shape)\n",
    "print(\"The size of y dataset is:\", data_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "901ed243-4f13-448b-9c57-3d834db8bc5b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6323d725-767c-4267-81df-536e5ded49a1",
   "metadata": {},
   "source": [
    "* 1 Dimensional latent diffusion model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ad250c5-f929-4c28-bb6f-57c3c603bd62",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LatentDiffusionVAE:\n",
    "    def __init__(self, input_shape, latent_dim):\n",
    "        self.input_shape = input_shape\n",
    "        self.latent_dim = latent_dim\n",
    "        self.encoder = self.build_encoder()\n",
    "        self.decoder = self.build_decoder()\n",
    "        self.vae = self.build_vae()\n",
    "        \n",
    "    ## sampling - reparameterization\n",
    "    def sampling(self, repara):\n",
    "        z_mean, z_log_var = repara\n",
    "        batch = tf.shape(z_mean)[0]\n",
    "        dim = tf.shape(z_mean)[1]\n",
    "        epsilon = K.random_normal(shape=(batch, dim))\n",
    "        return z_mean + tf.exp(0.5 * z_log_var) * epsilon\n",
    "\n",
    "    def build_encoder(self):\n",
    "        inputs = Input(shape=self.input_shape)\n",
    "        x = layers.Conv1D(32, 3, activation='relu', padding='same')(inputs)\n",
    "        x = layers.Flatten()(x)\n",
    "        x = layers.Dense(128, activation='relu')(x)\n",
    "        z_mean = layers.Dense(self.latent_dim)(x)\n",
    "        z_log_var = layers.Dense(self.latent_dim)(x)\n",
    "        return Model(inputs, [z_mean, z_log_var], name='encoder')\n",
    "\n",
    "    def build_decoder(self):\n",
    "        latent_inputs = Input(shape=(self.latent_dim,))\n",
    "        x = layers.Dense(128, activation='relu')(latent_inputs)\n",
    "        x = layers.Dense(np.prod(self.input_shape), activation='relu')(x)\n",
    "        x = layers.Reshape(self.input_shape)(x)\n",
    "        outputs = layers.Conv1D(1, 3, activation='sigmoid', padding='same')(x)\n",
    "        return Model(latent_inputs, outputs, name='decoder')\n",
    "\n",
    "    def build_vae(self):\n",
    "        inputs = Input(shape=self.input_shape)\n",
    "        z_mean, z_log_var = self.encoder(inputs)\n",
    "        z = layers.Lambda(self.sampling, output_shape=(self.latent_dim,))([z_mean, z_log_var])\n",
    "        outputs = self.decoder(z)\n",
    "\n",
    "        vae = Model(inputs, outputs, name='vae')\n",
    "\n",
    "        # Define the VAE loss\n",
    "        reconstruction_loss = MeanSquaredError()(inputs, outputs)\n",
    "        kl_loss = -0.5 * tf.reduce_mean(\n",
    "            z_log_var - tf.square(z_mean) - tf.exp(z_log_var) + 1)\n",
    "        vae_loss = reconstruction_loss + kl_loss\n",
    "        vae.add_loss(vae_loss)\n",
    "        vae.compile(optimizer='adam')\n",
    "\n",
    "        return vae\n",
    "\n",
    "    def train(self, data_x, epochs, batch_size, validation_split=0.2, verbose=2):\n",
    "        self.vae.fit(data_x, epochs=epochs, validation_split=validation_split, batch_size=batch_size, verbose=verbose)\n",
    "\n",
    "    def generate(self, latent_sample):\n",
    "        return self.decoder.predict(latent_sample)\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "# Assuming data_x and args_diffusion are already defined\n",
    "\n",
    "input_shape = (data_x.shape[1], 1)\n",
    "latent_dim = args_diffusion.latent_dim\n",
    "\n",
    "vae_model = LatentDiffusionVAE(input_shape, latent_dim)\n",
    "vae_model.train(data_x, epochs=args_diffusion.epochs, batch_size=args_diffusion.bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f749719a-3384-4aa1-8339-1c6e0f6b98c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b49bee9-771d-45ae-80be-214694620a79",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "21e4ec70-9398-4957-9e9f-3afcf76cf4c7",
   "metadata": {},
   "source": [
    "--- working code (start) --- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eefe80ac-7856-4761-aa36-e580cf9e024d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sampling function for the latent space\n",
    "def sampling(repara):\n",
    "    z_mean, z_log_var = repara\n",
    "    batch = tf.shape(z_mean)[0]\n",
    "    dim = tf.shape(z_mean)[1]\n",
    "    epsilon = K.random_normal(shape=(batch, dim))\n",
    "    return z_mean + tf.exp(0.5 * z_log_var) * epsilon\n",
    "\n",
    "# Define encoder\n",
    "def build_encoder(input_shape, latent_dim):\n",
    "    inputs = Input(shape=input_shape)\n",
    "    x = Conv1D(32, 3, activation='relu', padding='same')(inputs)\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(128, activation='relu')(x)\n",
    "    z_mean = Dense(latent_dim)(x)\n",
    "    z_log_var = Dense(latent_dim)(x)\n",
    "    return Model(inputs, [z_mean, z_log_var], name='encoder')\n",
    "\n",
    "# Define decoder\n",
    "def build_decoder(output_shape, latent_dim):\n",
    "    latent_inputs = Input(shape=(latent_dim,))\n",
    "    x = Dense(128, activation='relu')(latent_inputs)\n",
    "    x = Dense(np.prod(output_shape), activation='relu')(x)\n",
    "    x = Reshape(output_shape)(x)\n",
    "    outputs = Conv1D(1, 3, activation='sigmoid', padding='same')(x)\n",
    "    return Model(latent_inputs, outputs, name='decoder')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "407dba56-edca-46c7-a855-1d38223010ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (data_x.shape[1], 1)  # Example input shape\n",
    "latent_dim = args_diffusion.latent_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b75b2e74-1c33-412d-8922-6172b7923bfb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Define the VAE\n",
    "encoder = build_encoder(input_shape, latent_dim)\n",
    "decoder = build_decoder(input_shape, latent_dim)\n",
    "\n",
    "inputs = Input(shape=input_shape)\n",
    "z_mean, z_log_var = encoder(inputs)\n",
    "z = Lambda(sampling, output_shape=(latent_dim,))([z_mean, z_log_var])\n",
    "outputs = decoder(z)\n",
    "\n",
    "vae = Model(inputs, outputs, name='vae')\n",
    "\n",
    "# Define the VAE loss\n",
    "reconstruction_loss = MeanSquaredError()(inputs, outputs)\n",
    "kl_loss = -0.5 * tf.reduce_mean(\n",
    "    z_log_var - tf.square(z_mean) - tf.exp(z_log_var) + 1)\n",
    "vae_loss = reconstruction_loss + kl_loss\n",
    "vae.add_loss(vae_loss)\n",
    "vae.compile(optimizer='adam')\n",
    "\n",
    "# vae.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "526dc914-b23c-427a-b90f-cc5e3a0dfc3d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0cb65314-efc8-4b76-b8a9-780e86f5123a",
   "metadata": {},
   "source": [
    "* model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "612e2eab-5606-4188-9d1b-23fdad6c2c8b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Train the VAE\n",
    "vae.fit(data_x, epochs=args_diffusion.epochs, validation_split=0.2, batch_size=args_diffusion.bs, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22559155-2211-4879-ad88-819bc3a56e34",
   "metadata": {},
   "source": [
    "--- working code (end) ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c56313a0-e1e4-41c3-8043-3083af56d4bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e75487eb-4981-48dc-8057-21a92f2f7285",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c5a3418-2b88-4a91-95b8-52c1292ab49c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5905fb40-d68d-4a01-b73d-60acfbd944bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2ff6241-7e4b-4827-a1f6-44ba65133932",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fb965bcb-a722-454f-b3ad-498d54d08094",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e981c57e-13b4-4b5e-aa19-c6cfe91c989a",
   "metadata": {},
   "source": [
    "---------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b774b0d-996a-492a-8930-56b8498703c4",
   "metadata": {},
   "source": [
    "-----------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2d74df3-ad0e-4d1e-903f-ba88f4613b8e",
   "metadata": {},
   "source": [
    "# Classification performance check"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf3ea892-6b25-42dc-a749-143b32efbea8",
   "metadata": {},
   "source": [
    "## Original dataset only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "8a32baa1-3aad-4685-adcd-06aebe9b98e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dnn = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "01b9f402-32ba-4a8f-a71e-7be2a1d3f529",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "main_dx\n",
       "MDDs    325\n",
       "MDDr    277\n",
       "PDD     119\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dnn.main_dx.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "446bccde-1de6-4baa-a4f0-2a887d2c3a94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(721, 35)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dnn.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "5c75d1a4-fdbc-412a-803e-4803caeb9f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dnn['psi'] = pd.to_numeric(data_dnn['psi'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "d2c3899c-0c1f-4ac2-8fc2-a0ce231a6163",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x = data_dnn.drop(drop_list, axis=1)\n",
    "x = x.fillna(x.mean())\n",
    "y = data_dnn.main_dx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "e7b9444a-0bf5-40c5-bbcb-104390b10e8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['sdnn', 'psi', 'tp', 'vlf', 'lf', 'hf', 'lfnorm', 'hfnorm', 'lf_hf',\n",
       "       'rmssd', 'apen', 'srd', 'tsrd', 'tp_ln', 'vlf_ln', 'lf_ln', 'hf_ln'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "bf43146e-8e4b-40e8-8e2a-d2af107cc8c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "main_dx\n",
       "MDDs    325\n",
       "MDDr    277\n",
       "PDD     119\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "71fb11a2-17f9-4bec-9ec3-c1a82325f094",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_x = x.copy()\n",
    "data_x[:] = (scaler.fit_transform(data_x[:])).round(decimals=6) ## scaling x values\n",
    "\n",
    "label, uniques = pd.factorize(y)  # y를 숫자로 변환\n",
    "data_y = to_categorical(label, len(uniques))  # 원-핫 인코딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "96e78f59-c643-476e-9f0c-37c3fec6b47e",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(data_x, data_y, test_size = 0.2, random_state = 710674)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "1ce8c93e-3b36-44db-be80-ba7b082b58f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## definition for computing class weight (to solve class imbalance issue)\n",
    "def compute_class_weights(y):\n",
    "    class_counts = np.bincount(y) ## calculating data point for each class\n",
    "    total_samples = len(y) ## total data points\n",
    "    ## computing each class weight\n",
    "    class_weights = {i: total_samples / (len(class_counts) * class_count) \n",
    "                     for i, class_count in enumerate(class_counts)}\n",
    "    \n",
    "    return class_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "a385e133-6da1-4443-936c-c26a81b9c3d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 2.019607843137255, 1: 0.8676293622141997, 2: 0.7394871794871795}\n"
     ]
    }
   ],
   "source": [
    "class_weight = compute_class_weights(label)\n",
    "print(class_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3eec954-0f97-458b-8f38-38f0c1430dd8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fa41a9dd-4361-49e2-bd64-ea3cb5c71d67",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eaaf7d3-f1da-4632-bb89-c31e45e79ee4",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Augmented dataset add"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23165eff-832d-482a-b4eb-7915a4c29b26",
   "metadata": {},
   "source": [
    "> we generate synthesized dataset using VAE from above. \\\n",
    "> adopted original datset: data_mdd, data_bpi, data_bpii \\\n",
    "> synthesized into: gen_mdd, gen_bpi, gen_bpii \\\n",
    "> gen_control is not generated since \"control group\" has biggest number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6daafef-9b75-4899-8111-f44278b6cf0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class synthetic_data_preparation:\n",
    "    def __init__(self, original_data, gen_data, label_col, id_cols=None, drop_cols=None):\n",
    "        \"\"\"\n",
    "        original_data (pandas.DataFrame): original dataset\n",
    "        gen_data (dict): data dictionary for synthetic dataset (ex: {0: gen_A, 1: gen_B})\n",
    "        label_col (str): label column (target variable)\n",
    "        id_cols (list): column list to drop (예: ['Unnamed: 32', 'id'])\n",
    "        drop_cols (list): column list to drop from original dataset\n",
    "        \"\"\"\n",
    "        self.original_data = original_data\n",
    "        self.gen_data = gen_data\n",
    "        self.label_col = label_col\n",
    "        self.id_cols = id_cols if id_cols is not None else []\n",
    "        self.drop_cols = drop_cols if drop_cols is not None else []\n",
    "        \n",
    "    def prepare_data(self):\n",
    "        ## preprocessing original dataset\n",
    "        data_dnn = self.original_data.copy()\n",
    "        for col in self.id_cols:\n",
    "            if col in data_dnn.columns:\n",
    "                data_dnn = data_dnn.drop(col, axis=1)\n",
    "        \n",
    "        data_dnn = data_dnn.drop(self.drop_cols, axis=1)\n",
    "        data_classes = {label: data_dnn[data_dnn[self.label_col] == label] for label in data_dnn[self.label_col].unique()}\n",
    "        \n",
    "        ## preprocessing synthetic generated dataset\n",
    "        for label, df in self.gen_data.items():\n",
    "            df[self.label_col] = label\n",
    "            if self.drop_cols:\n",
    "                df = df.drop(self.drop_cols, axis=1)\n",
    "            self.gen_data[label] = df\n",
    "        \n",
    "        ## concat original dataset and generated dataset\n",
    "        ori_df_concat = pd.concat(list(data_classes.values()), ignore_index=True)\n",
    "        gen_df_concat = pd.concat(list(self.gen_data.values()), ignore_index=True)\n",
    "        \n",
    "        ## separating feature and label(target)\n",
    "        ori_x = ori_df_concat.drop([self.label_col], axis=1)\n",
    "        ori_y = ori_df_concat[[self.label_col]]\n",
    "        \n",
    "        gen_x = gen_df_concat.drop([self.label_col], axis=1)\n",
    "        gen_y = gen_df_concat[[self.label_col]]\n",
    "        \n",
    "        ## filling missing values and scaling\n",
    "        ori_x = ori_x.fillna(ori_x.mean())\n",
    "        ori_x[:] = (scaler.fit_transform(ori_x[:])).round(decimals=6) ## scaling x values\n",
    "        \n",
    "        # 레이블 인코딩 및 원-핫 인코딩\n",
    "        ori_y = ori_y.replace({self.label_col: {label: idx for idx, label in enumerate(ori_y[self.label_col].unique())}})\n",
    "        y_ori = to_categorical(ori_y, num_classes=len(ori_y[self.label_col].unique()))\n",
    "        \n",
    "        gen_y = gen_y.replace({self.label_col: {label: idx for idx, label in enumerate(gen_y[self.label_col].unique())}})\n",
    "        y_gen = to_categorical(gen_y, num_classes=len(gen_y[self.label_col].unique()))\n",
    "        \n",
    "        ## separating training and test dataset\n",
    "        x_trainset, x_test, y_trainset, y_test = train_test_split(ori_x, y_ori, test_size=0.35, random_state=710674)\n",
    "        \n",
    "        ## add generated dataset to training dataset\n",
    "        x_train_concat = pd.concat([x_trainset, gen_x], ignore_index=True)\n",
    "        y_train_concat = np.concatenate([y_trainset, y_gen])\n",
    "        \n",
    "        ## separating training dataset and validation dataset\n",
    "        x_train, x_vali, y_train, y_vali = train_test_split(x_train_concat, y_train_concat, test_size=0.2, random_state=710674)\n",
    "        \n",
    "        return x_train, x_vali, x_test, y_train, y_vali, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9528204-5e13-47a1-9266-dd4488568e12",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_ori.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0215632f-f314-4022-84a0-1d6769e779ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "scale_list_ = ['HAMD', 'HAMA', 'PDSS', 'ASI', 'APPQ', 'PSWQ', 'SPI', 'PSS', 'BIS', 'SSI']\n",
    "etc_list_ = ['sub', 'VISIT', 'disorder_mdd']\n",
    "demo_list_ = ['age', 'gender']\n",
    "drop_list_ = scale_list_ + etc_list_ + demo_list_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b7f4218-b67d-46d3-86ed-47cc98ac34df",
   "metadata": {},
   "outputs": [],
   "source": [
    "## make a dictionary for generated dataset\n",
    "gen_data = {\"mdd\":gen_mdd, \"pd\":gen_pd, \"con\":gen_con}\n",
    "\n",
    "## data_preparation class initialize and data prepare\n",
    "data_prep = synthetic_data_preparation(data_ori, gen_data, label_col='disorder', id_cols=drop_list_)\n",
    "x_train, x_vali, x_test, y_train, y_vali, y_test = data_prep.prepare_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cbc9bd3-3c49-4f07-ac1a-6689570947fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d9ddb173-633a-43d0-9f51-32ae7cb6fec5",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f39c2ee7-3221-4217-8794-c19a904f91d5",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcd2bfda-069a-47e9-9ce5-d579238f3abd",
   "metadata": {},
   "source": [
    "## Simple DNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "eaedc655-0b50-4bc7-b3d6-0832d939efd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "cla = len(uniques)\n",
    "class Args_dnn:\n",
    "    # arugments\n",
    "    epochs=250\n",
    "    bs=16\n",
    "    lr=0.001\n",
    "    momentum=0.9\n",
    "    num_classes= cla\n",
    "    seed=710674\n",
    "\n",
    "args_dnn = Args_dnn()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86bade4d-02ae-4a3b-ae78-3441f5c033b7",
   "metadata": {},
   "source": [
    "* DNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "c859ec14-825f-4665-8dcc-4c4054076f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleDNN:\n",
    "    def __init__(self, input_dim, layer_configs, output_units, output_activation='softmax'):\n",
    "        self.input_dim = input_dim ## input data dimensionality (# variables)\n",
    "        self.layer_configs = layer_configs ## hidden layer/sequential layer lists (units, activation, batch_norm, dropout_rate)\n",
    "        self.output_units = output_units ## output unit no.\n",
    "        self.output_activation = output_activation ## activation function for output layer\n",
    "        self.model = self.build_model()\n",
    "        self.callbacks = []\n",
    "\n",
    "    def build_model(self):\n",
    "        model = models.Sequential()\n",
    "        ## add first hidden layer\n",
    "        model.add(layers.Dense(units=self.layer_configs[0]['units'], activation=self.layer_configs[0]['activation'], input_shape=(self.input_dim,)))\n",
    "        \n",
    "        ## batch normalization and dropout for first layer\n",
    "        if self.layer_configs[0].get('batch_norm', False):\n",
    "            model.add(layers.BatchNormalization())\n",
    "        if self.layer_configs[0].get('dropout_rate', None) is not None:\n",
    "            model.add(layers.Dropout(rate=self.layer_configs[0]['dropout_rate']))\n",
    "        \n",
    "        ## do same for rest hidden layers (except for the last)\n",
    "        for config in self.layer_configs[1:]:\n",
    "            model.add(layers.Dense(units=config['units'], activation=config['activation']))\n",
    "            \n",
    "            if config.get('batch_norm', False):\n",
    "                model.add(layers.BatchNormalization())\n",
    "            \n",
    "            if config.get('dropout_rate', None) is not None:\n",
    "                model.add(layers.Dropout(rate=config['dropout_rate']))\n",
    "        \n",
    "        ## add output layer\n",
    "        model.add(layers.Dense(units=self.output_units, activation=self.output_activation))\n",
    "        \n",
    "        return model\n",
    "\n",
    "    def compile_model(self, optimizer, loss='categorical_crossentropy', metrics=['accuracy'], lr_scheduler=None):\n",
    "        if lr_scheduler:\n",
    "            ## AddLearningRateScheduler callback\n",
    "            self.callbacks.append(LearningRateScheduler(lr_scheduler))\n",
    "        \n",
    "        self.model.compile(optimizer, loss, metrics)\n",
    "\n",
    "    def fit_model(self, x_train, y_train, epochs, batch_size, validation_split=None, class_weight=None, validation_data=None):\n",
    "        return self.model.fit(x_train, y_train, epochs=epochs, batch_size=batch_size, validation_split=validation_split,\n",
    "                             class_weight=class_weight, validation_data = validation_data, callbacks=self.callbacks)\n",
    "\n",
    "    def evaluate_model(self, x_test, y_test):\n",
    "        return self.model.evaluate(x_test, y_test)\n",
    "\n",
    "    def predict(self, x):\n",
    "        return self.model.predict(x)\n",
    "\n",
    "    def summary(self):\n",
    "        self.model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af8723a2-895c-43b4-b031-c869d0f2af3b",
   "metadata": {},
   "source": [
    "* optimization function, model compile, and model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "28545248-f087-4bc1-9a84-7262b9179abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dynamic_learning_rate(epoch, mode='cyclic', base_lr=0.001, max_lr=0.006, step_size=2000, gamma=0.99994):\n",
    "    cycle = np.floor(1 + epoch / (2 * step_size))\n",
    "    x = np.abs(epoch / step_size - 2 * cycle + 1)\n",
    "    \n",
    "    if mode == 'cyclic' or mode == 'triangular':\n",
    "        lr = base_lr + (max_lr - base_lr) * max(0, (1 - x))\n",
    "    elif mode == 'triangular2':\n",
    "        lr = base_lr + (max_lr - base_lr) * max(0, (1 - x)) / (2 ** (cycle - 1))\n",
    "    elif mode == 'exp_range':\n",
    "        lr = base_lr + (max_lr - base_lr) * max(0, (1 - x)) * (gamma ** epoch)\n",
    "    else:\n",
    "        raise ValueError(\"Invalid mode. Choose from 'cyclic', 'triangular', 'triangular2', or 'exp_range'.\")\n",
    "    \n",
    "    return lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "7705bb04-1f9d-49d7-8d45-fd99ca74ef68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lr = dynamic_learning_rate(epoch=1000, mode='cyclic')\n",
    "# lr = dynamic_learning_rate(epoch=1000, mode='triangular')\n",
    "# lr = dynamic_learning_rate(epoch=1000, mode='triangular2')\n",
    "# lr = dynamic_learning_rate(epoch=1000, mode='exp_range', gamma=0.99994)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "3d8cd8b1-69c5-47e7-8b08-568f635887f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(721, 17)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "64a13af6-6827-4fae-adcf-d37f47ae7304",
   "metadata": {},
   "outputs": [],
   "source": [
    "## model initialization with hidden layer list below\n",
    "layer_configs = [\n",
    "    {'units': 64, 'activation': 'relu', 'batch_norm': True, 'dropout_rate': 0.3},\n",
    "    {'units': 32, 'activation': 'relu', 'batch_norm': True},\n",
    "    {'units': 32, 'activation': 'relu', 'batch_norm': True, 'dropout_rate': 0.3},\n",
    "    {'units': 16, 'activation': 'relu', 'batch_norm': True},\n",
    "    {'units': 8, 'activation': 'relu', 'batch_norm':True}\n",
    "]\n",
    "\n",
    "model = SimpleDNN(output_units=args_dnn.num_classes, input_dim=x_train.shape[1], layer_configs=layer_configs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "dadfa22a-1667-4b9e-b0c2-691d71236332",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_15 (Dense)            (None, 64)                1152      \n",
      "                                                                 \n",
      " batch_normalization_11 (Bat  (None, 64)               256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_16 (Dense)            (None, 32)                2080      \n",
      "                                                                 \n",
      " batch_normalization_12 (Bat  (None, 32)               128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_17 (Dense)            (None, 32)                1056      \n",
      "                                                                 \n",
      " batch_normalization_13 (Bat  (None, 32)               128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_6 (Dropout)         (None, 32)                0         \n",
      "                                                                 \n",
      " dense_18 (Dense)            (None, 16)                528       \n",
      "                                                                 \n",
      " batch_normalization_14 (Bat  (None, 16)               64        \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_19 (Dense)            (None, 8)                 136       \n",
      "                                                                 \n",
      " batch_normalization_15 (Bat  (None, 8)                32        \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_20 (Dense)            (None, 3)                 27        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5,587\n",
      "Trainable params: 5,283\n",
      "Non-trainable params: 304\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "## compile our model\n",
    "opt = keras.optimizers.SGD(learning_rate = 0.001, decay = 1e-5, momentum = 0.9)\n",
    "scheduler = lambda epoch: dynamic_learning_rate(epoch, mode='exp_range', base_lr=0.001, max_lr=0.02, step_size=50)\n",
    "model.compile_model(optimizer = opt, lr_scheduler=scheduler)\n",
    "\n",
    "## model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "d975db5d-b42e-4329-9f11-7f9b70e426ea",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/250\n",
      "29/29 [==============================] - 1s 19ms/step - loss: 1.7244 - accuracy: 0.3174 - val_loss: 1.0930 - val_accuracy: 0.3966 - lr: 0.0010\n",
      "Epoch 2/250\n",
      "29/29 [==============================] - 0s 12ms/step - loss: 1.4468 - accuracy: 0.3326 - val_loss: 1.0906 - val_accuracy: 0.3879 - lr: 0.0014\n",
      "Epoch 3/250\n",
      "29/29 [==============================] - 0s 14ms/step - loss: 1.2606 - accuracy: 0.3826 - val_loss: 1.1127 - val_accuracy: 0.3534 - lr: 0.0018\n",
      "Epoch 4/250\n",
      "29/29 [==============================] - 0s 12ms/step - loss: 1.2182 - accuracy: 0.3478 - val_loss: 1.0891 - val_accuracy: 0.3534 - lr: 0.0021\n",
      "Epoch 5/250\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 1.2038 - accuracy: 0.3522 - val_loss: 1.0799 - val_accuracy: 0.3276 - lr: 0.0025\n",
      "Epoch 6/250\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 1.1688 - accuracy: 0.3565 - val_loss: 1.0818 - val_accuracy: 0.3621 - lr: 0.0029\n",
      "Epoch 7/250\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 1.1386 - accuracy: 0.3609 - val_loss: 1.0720 - val_accuracy: 0.4052 - lr: 0.0033\n",
      "Epoch 8/250\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 1.1157 - accuracy: 0.3457 - val_loss: 1.0782 - val_accuracy: 0.4138 - lr: 0.0037\n",
      "Epoch 9/250\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 1.1119 - accuracy: 0.3848 - val_loss: 1.0930 - val_accuracy: 0.3966 - lr: 0.0040\n",
      "Epoch 10/250\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 1.1052 - accuracy: 0.3957 - val_loss: 1.0953 - val_accuracy: 0.3448 - lr: 0.0044\n",
      "Epoch 11/250\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 1.1149 - accuracy: 0.3739 - val_loss: 1.0946 - val_accuracy: 0.3362 - lr: 0.0048\n",
      "Epoch 12/250\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 1.1324 - accuracy: 0.3196 - val_loss: 1.0737 - val_accuracy: 0.3793 - lr: 0.0052\n",
      "Epoch 13/250\n",
      "29/29 [==============================] - 0s 13ms/step - loss: 1.1057 - accuracy: 0.3761 - val_loss: 1.0524 - val_accuracy: 0.4569 - lr: 0.0056\n",
      "Epoch 14/250\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 1.1236 - accuracy: 0.3565 - val_loss: 1.0671 - val_accuracy: 0.3879 - lr: 0.0059\n",
      "Epoch 15/250\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 1.1163 - accuracy: 0.3370 - val_loss: 1.0846 - val_accuracy: 0.3793 - lr: 0.0063\n",
      "Epoch 16/250\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 1.1249 - accuracy: 0.3261 - val_loss: 1.0986 - val_accuracy: 0.3534 - lr: 0.0067\n",
      "Epoch 17/250\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 1.1180 - accuracy: 0.3413 - val_loss: 1.1174 - val_accuracy: 0.3103 - lr: 0.0071\n",
      "Epoch 18/250\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 1.1074 - accuracy: 0.3457 - val_loss: 1.1389 - val_accuracy: 0.2931 - lr: 0.0075\n",
      "Epoch 19/250\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 1.1102 - accuracy: 0.3152 - val_loss: 1.1250 - val_accuracy: 0.3103 - lr: 0.0078\n",
      "Epoch 20/250\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 1.1058 - accuracy: 0.4087 - val_loss: 1.1042 - val_accuracy: 0.3362 - lr: 0.0082\n",
      "Epoch 21/250\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 1.1149 - accuracy: 0.3565 - val_loss: 1.1117 - val_accuracy: 0.3190 - lr: 0.0086\n",
      "Epoch 22/250\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 1.1008 - accuracy: 0.3435 - val_loss: 1.1377 - val_accuracy: 0.3017 - lr: 0.0090\n",
      "Epoch 23/250\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 1.1053 - accuracy: 0.3609 - val_loss: 1.1550 - val_accuracy: 0.2672 - lr: 0.0093\n",
      "Epoch 24/250\n",
      "29/29 [==============================] - 0s 14ms/step - loss: 1.1050 - accuracy: 0.3522 - val_loss: 1.1982 - val_accuracy: 0.2241 - lr: 0.0097\n",
      "Epoch 25/250\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 1.1060 - accuracy: 0.3783 - val_loss: 1.1500 - val_accuracy: 0.3362 - lr: 0.0101\n",
      "Epoch 26/250\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 1.0880 - accuracy: 0.3978 - val_loss: 1.1487 - val_accuracy: 0.2845 - lr: 0.0105\n",
      "Epoch 27/250\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 1.0990 - accuracy: 0.3435 - val_loss: 1.1235 - val_accuracy: 0.3190 - lr: 0.0109\n",
      "Epoch 28/250\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 1.0932 - accuracy: 0.3348 - val_loss: 1.1211 - val_accuracy: 0.3534 - lr: 0.0112\n",
      "Epoch 29/250\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 1.1067 - accuracy: 0.3522 - val_loss: 1.2138 - val_accuracy: 0.2328 - lr: 0.0116\n",
      "Epoch 30/250\n",
      "29/29 [==============================] - 0s 12ms/step - loss: 1.0936 - accuracy: 0.3326 - val_loss: 1.1294 - val_accuracy: 0.3103 - lr: 0.0120\n",
      "Epoch 31/250\n",
      "29/29 [==============================] - 0s 12ms/step - loss: 1.0890 - accuracy: 0.3587 - val_loss: 1.1447 - val_accuracy: 0.3017 - lr: 0.0124\n",
      "Epoch 32/250\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 1.1104 - accuracy: 0.3326 - val_loss: 1.1233 - val_accuracy: 0.2931 - lr: 0.0128\n",
      "Epoch 33/250\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 1.1055 - accuracy: 0.3630 - val_loss: 1.1218 - val_accuracy: 0.3276 - lr: 0.0131\n",
      "Epoch 34/250\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 1.1021 - accuracy: 0.3848 - val_loss: 1.1504 - val_accuracy: 0.2931 - lr: 0.0135\n",
      "Epoch 35/250\n",
      "29/29 [==============================] - 0s 13ms/step - loss: 1.0690 - accuracy: 0.3674 - val_loss: 1.1670 - val_accuracy: 0.3190 - lr: 0.0139\n",
      "Epoch 36/250\n",
      "29/29 [==============================] - 0s 12ms/step - loss: 1.0942 - accuracy: 0.3978 - val_loss: 1.1578 - val_accuracy: 0.3017 - lr: 0.0143\n",
      "Epoch 37/250\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 1.0934 - accuracy: 0.3848 - val_loss: 1.1515 - val_accuracy: 0.3103 - lr: 0.0147\n",
      "Epoch 38/250\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 1.1119 - accuracy: 0.3717 - val_loss: 1.0957 - val_accuracy: 0.3621 - lr: 0.0150\n",
      "Epoch 39/250\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 1.1074 - accuracy: 0.3565 - val_loss: 1.1112 - val_accuracy: 0.3448 - lr: 0.0154\n",
      "Epoch 40/250\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 1.0953 - accuracy: 0.3239 - val_loss: 1.1191 - val_accuracy: 0.3707 - lr: 0.0158\n",
      "Epoch 41/250\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 1.0878 - accuracy: 0.3826 - val_loss: 1.1931 - val_accuracy: 0.2931 - lr: 0.0162\n",
      "Epoch 42/250\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 1.0956 - accuracy: 0.4152 - val_loss: 1.1228 - val_accuracy: 0.3534 - lr: 0.0165\n",
      "Epoch 43/250\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 1.1110 - accuracy: 0.3065 - val_loss: 1.1396 - val_accuracy: 0.2931 - lr: 0.0169\n",
      "Epoch 44/250\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 1.1008 - accuracy: 0.3565 - val_loss: 1.1208 - val_accuracy: 0.2931 - lr: 0.0173\n",
      "Epoch 45/250\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 1.1178 - accuracy: 0.3043 - val_loss: 1.1492 - val_accuracy: 0.2155 - lr: 0.0177\n",
      "Epoch 46/250\n",
      "29/29 [==============================] - 0s 14ms/step - loss: 1.0953 - accuracy: 0.3652 - val_loss: 1.1682 - val_accuracy: 0.2155 - lr: 0.0181\n",
      "Epoch 47/250\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 1.1137 - accuracy: 0.3587 - val_loss: 1.1689 - val_accuracy: 0.2241 - lr: 0.0184\n",
      "Epoch 48/250\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 1.1009 - accuracy: 0.3435 - val_loss: 1.1551 - val_accuracy: 0.2069 - lr: 0.0188\n",
      "Epoch 49/250\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 1.1050 - accuracy: 0.4196 - val_loss: 1.1292 - val_accuracy: 0.3190 - lr: 0.0192\n",
      "Epoch 50/250\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 1.0889 - accuracy: 0.3913 - val_loss: 1.2093 - val_accuracy: 0.2586 - lr: 0.0196\n",
      "Epoch 51/250\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 1.0908 - accuracy: 0.3283 - val_loss: 1.1676 - val_accuracy: 0.2328 - lr: 0.0199\n",
      "Epoch 52/250\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 1.1062 - accuracy: 0.4000 - val_loss: 1.1571 - val_accuracy: 0.2500 - lr: 0.0196\n",
      "Epoch 53/250\n",
      "29/29 [==============================] - 0s 12ms/step - loss: 1.1004 - accuracy: 0.3435 - val_loss: 1.1526 - val_accuracy: 0.2672 - lr: 0.0192\n",
      "Epoch 54/250\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 1.0712 - accuracy: 0.4087 - val_loss: 1.1107 - val_accuracy: 0.3362 - lr: 0.0188\n",
      "Epoch 55/250\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 1.0878 - accuracy: 0.3891 - val_loss: 1.1035 - val_accuracy: 0.3362 - lr: 0.0184\n",
      "Epoch 56/250\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 1.0775 - accuracy: 0.4043 - val_loss: 1.1361 - val_accuracy: 0.3276 - lr: 0.0180\n",
      "Epoch 57/250\n",
      "29/29 [==============================] - 0s 15ms/step - loss: 1.0908 - accuracy: 0.3891 - val_loss: 1.1583 - val_accuracy: 0.3017 - lr: 0.0177\n",
      "Epoch 58/250\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 1.1127 - accuracy: 0.2978 - val_loss: 1.1162 - val_accuracy: 0.3448 - lr: 0.0173\n",
      "Epoch 59/250\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 1.0882 - accuracy: 0.4217 - val_loss: 1.1155 - val_accuracy: 0.3190 - lr: 0.0169\n",
      "Epoch 60/250\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 1.0874 - accuracy: 0.3522 - val_loss: 1.1507 - val_accuracy: 0.2586 - lr: 0.0165\n",
      "Epoch 61/250\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 1.1000 - accuracy: 0.3717 - val_loss: 1.1350 - val_accuracy: 0.2845 - lr: 0.0161\n",
      "Epoch 62/250\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 1.0857 - accuracy: 0.3696 - val_loss: 1.1359 - val_accuracy: 0.3276 - lr: 0.0158\n",
      "Epoch 63/250\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 1.1001 - accuracy: 0.3435 - val_loss: 1.1376 - val_accuracy: 0.2931 - lr: 0.0154\n",
      "Epoch 64/250\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 1.0961 - accuracy: 0.3543 - val_loss: 1.1345 - val_accuracy: 0.2931 - lr: 0.0150\n",
      "Epoch 65/250\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 1.0727 - accuracy: 0.3804 - val_loss: 1.1548 - val_accuracy: 0.2931 - lr: 0.0146\n",
      "Epoch 66/250\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 1.0724 - accuracy: 0.3826 - val_loss: 1.1592 - val_accuracy: 0.3017 - lr: 0.0142\n",
      "Epoch 67/250\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 1.0779 - accuracy: 0.3783 - val_loss: 1.1467 - val_accuracy: 0.2931 - lr: 0.0139\n",
      "Epoch 68/250\n",
      "29/29 [==============================] - 0s 15ms/step - loss: 1.0747 - accuracy: 0.3783 - val_loss: 1.1967 - val_accuracy: 0.2500 - lr: 0.0135\n",
      "Epoch 69/250\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 1.0645 - accuracy: 0.3804 - val_loss: 1.1690 - val_accuracy: 0.3103 - lr: 0.0131\n",
      "Epoch 70/250\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 1.0782 - accuracy: 0.3870 - val_loss: 1.1687 - val_accuracy: 0.2845 - lr: 0.0127\n",
      "Epoch 71/250\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 1.1038 - accuracy: 0.3478 - val_loss: 1.1583 - val_accuracy: 0.2672 - lr: 0.0124\n",
      "Epoch 72/250\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 1.0661 - accuracy: 0.3913 - val_loss: 1.1529 - val_accuracy: 0.2328 - lr: 0.0120\n",
      "Epoch 73/250\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 1.0703 - accuracy: 0.3587 - val_loss: 1.1474 - val_accuracy: 0.2672 - lr: 0.0116\n",
      "Epoch 74/250\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 1.0776 - accuracy: 0.3848 - val_loss: 1.1118 - val_accuracy: 0.3017 - lr: 0.0112\n",
      "Epoch 75/250\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 1.0568 - accuracy: 0.3804 - val_loss: 1.1384 - val_accuracy: 0.3017 - lr: 0.0108\n",
      "Epoch 76/250\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 1.0609 - accuracy: 0.3935 - val_loss: 1.1596 - val_accuracy: 0.2931 - lr: 0.0105\n",
      "Epoch 77/250\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 1.0807 - accuracy: 0.3239 - val_loss: 1.1562 - val_accuracy: 0.2759 - lr: 0.0101\n",
      "Epoch 78/250\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 1.0607 - accuracy: 0.3783 - val_loss: 1.1449 - val_accuracy: 0.2931 - lr: 0.0097\n",
      "Epoch 79/250\n",
      "29/29 [==============================] - 0s 15ms/step - loss: 1.0596 - accuracy: 0.3652 - val_loss: 1.1493 - val_accuracy: 0.2500 - lr: 0.0093\n",
      "Epoch 80/250\n",
      "29/29 [==============================] - 0s 12ms/step - loss: 1.0905 - accuracy: 0.3609 - val_loss: 1.1478 - val_accuracy: 0.2931 - lr: 0.0089\n",
      "Epoch 81/250\n",
      "29/29 [==============================] - 0s 12ms/step - loss: 1.0589 - accuracy: 0.4022 - val_loss: 1.1523 - val_accuracy: 0.2672 - lr: 0.0086\n",
      "Epoch 82/250\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 1.0698 - accuracy: 0.3870 - val_loss: 1.1634 - val_accuracy: 0.2328 - lr: 0.0082\n",
      "Epoch 83/250\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 1.0432 - accuracy: 0.4413 - val_loss: 1.1684 - val_accuracy: 0.2328 - lr: 0.0078\n",
      "Epoch 84/250\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 1.0490 - accuracy: 0.4109 - val_loss: 1.1901 - val_accuracy: 0.2586 - lr: 0.0074\n",
      "Epoch 85/250\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 1.0331 - accuracy: 0.4087 - val_loss: 1.1911 - val_accuracy: 0.2500 - lr: 0.0070\n",
      "Epoch 86/250\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 1.0755 - accuracy: 0.4000 - val_loss: 1.1853 - val_accuracy: 0.2328 - lr: 0.0067\n",
      "Epoch 87/250\n",
      "29/29 [==============================] - 0s 12ms/step - loss: 1.0521 - accuracy: 0.3957 - val_loss: 1.1747 - val_accuracy: 0.2586 - lr: 0.0063\n",
      "Epoch 88/250\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 1.0624 - accuracy: 0.3978 - val_loss: 1.1975 - val_accuracy: 0.2500 - lr: 0.0059\n",
      "Epoch 89/250\n",
      "29/29 [==============================] - 0s 14ms/step - loss: 1.0492 - accuracy: 0.4217 - val_loss: 1.1845 - val_accuracy: 0.1897 - lr: 0.0055\n",
      "Epoch 90/250\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 1.0655 - accuracy: 0.3739 - val_loss: 1.2014 - val_accuracy: 0.2414 - lr: 0.0052\n",
      "Epoch 91/250\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 1.0531 - accuracy: 0.3891 - val_loss: 1.1897 - val_accuracy: 0.2328 - lr: 0.0048\n",
      "Epoch 92/250\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 1.0600 - accuracy: 0.3804 - val_loss: 1.1536 - val_accuracy: 0.3103 - lr: 0.0044\n",
      "Epoch 93/250\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 1.0534 - accuracy: 0.4000 - val_loss: 1.1440 - val_accuracy: 0.3103 - lr: 0.0040\n",
      "Epoch 94/250\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 1.0392 - accuracy: 0.3826 - val_loss: 1.1465 - val_accuracy: 0.2759 - lr: 0.0036\n",
      "Epoch 95/250\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 1.0440 - accuracy: 0.4174 - val_loss: 1.1511 - val_accuracy: 0.2759 - lr: 0.0033\n",
      "Epoch 96/250\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 1.0420 - accuracy: 0.3957 - val_loss: 1.1527 - val_accuracy: 0.2586 - lr: 0.0029\n",
      "Epoch 97/250\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 1.0646 - accuracy: 0.3870 - val_loss: 1.1546 - val_accuracy: 0.2845 - lr: 0.0025\n",
      "Epoch 98/250\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 1.0571 - accuracy: 0.4022 - val_loss: 1.1630 - val_accuracy: 0.2500 - lr: 0.0021\n",
      "Epoch 99/250\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 1.0335 - accuracy: 0.4152 - val_loss: 1.1701 - val_accuracy: 0.2414 - lr: 0.0018\n",
      "Epoch 100/250\n",
      "29/29 [==============================] - 0s 14ms/step - loss: 1.0488 - accuracy: 0.4022 - val_loss: 1.1717 - val_accuracy: 0.2500 - lr: 0.0014\n",
      "Epoch 101/250\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 1.0708 - accuracy: 0.3978 - val_loss: 1.1595 - val_accuracy: 0.2672 - lr: 0.0010\n",
      "Epoch 102/250\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 1.0519 - accuracy: 0.4609 - val_loss: 1.1559 - val_accuracy: 0.2759 - lr: 0.0014\n",
      "Epoch 103/250\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 1.0527 - accuracy: 0.3826 - val_loss: 1.1603 - val_accuracy: 0.2845 - lr: 0.0018\n",
      "Epoch 104/250\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 1.0695 - accuracy: 0.3826 - val_loss: 1.1674 - val_accuracy: 0.2759 - lr: 0.0021\n",
      "Epoch 105/250\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 1.0409 - accuracy: 0.4109 - val_loss: 1.1705 - val_accuracy: 0.2500 - lr: 0.0025\n",
      "Epoch 106/250\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 1.0517 - accuracy: 0.3630 - val_loss: 1.1695 - val_accuracy: 0.2414 - lr: 0.0029\n",
      "Epoch 107/250\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 1.0461 - accuracy: 0.3957 - val_loss: 1.1658 - val_accuracy: 0.2672 - lr: 0.0033\n",
      "Epoch 108/250\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 1.0858 - accuracy: 0.3630 - val_loss: 1.1652 - val_accuracy: 0.2328 - lr: 0.0036\n",
      "Epoch 109/250\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 1.0612 - accuracy: 0.3739 - val_loss: 1.1576 - val_accuracy: 0.2672 - lr: 0.0040\n",
      "Epoch 110/250\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 1.0412 - accuracy: 0.3870 - val_loss: 1.1672 - val_accuracy: 0.2931 - lr: 0.0044\n",
      "Epoch 111/250\n",
      "29/29 [==============================] - 0s 15ms/step - loss: 1.0650 - accuracy: 0.3739 - val_loss: 1.1494 - val_accuracy: 0.2672 - lr: 0.0048\n",
      "Epoch 112/250\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 1.0328 - accuracy: 0.4065 - val_loss: 1.1479 - val_accuracy: 0.2672 - lr: 0.0052\n",
      "Epoch 113/250\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 1.0720 - accuracy: 0.3696 - val_loss: 1.1509 - val_accuracy: 0.2586 - lr: 0.0055\n",
      "Epoch 114/250\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 1.0621 - accuracy: 0.3761 - val_loss: 1.1387 - val_accuracy: 0.2759 - lr: 0.0059\n",
      "Epoch 115/250\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 1.0110 - accuracy: 0.4391 - val_loss: 1.1338 - val_accuracy: 0.3276 - lr: 0.0063\n",
      "Epoch 116/250\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 1.0550 - accuracy: 0.4130 - val_loss: 1.1240 - val_accuracy: 0.3190 - lr: 0.0067\n",
      "Epoch 117/250\n",
      "29/29 [==============================] - 0s 12ms/step - loss: 1.0453 - accuracy: 0.4087 - val_loss: 1.1452 - val_accuracy: 0.2845 - lr: 0.0070\n",
      "Epoch 118/250\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 1.1044 - accuracy: 0.3761 - val_loss: 1.1458 - val_accuracy: 0.2672 - lr: 0.0074\n",
      "Epoch 119/250\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 1.0626 - accuracy: 0.4174 - val_loss: 1.1402 - val_accuracy: 0.2586 - lr: 0.0078\n",
      "Epoch 120/250\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 1.0494 - accuracy: 0.3935 - val_loss: 1.1510 - val_accuracy: 0.2845 - lr: 0.0082\n",
      "Epoch 121/250\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 1.0524 - accuracy: 0.4152 - val_loss: 1.1463 - val_accuracy: 0.2845 - lr: 0.0085\n",
      "Epoch 122/250\n",
      "29/29 [==============================] - 0s 15ms/step - loss: 1.0556 - accuracy: 0.4022 - val_loss: 1.1467 - val_accuracy: 0.2931 - lr: 0.0089\n",
      "Epoch 123/250\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 1.0683 - accuracy: 0.3870 - val_loss: 1.1479 - val_accuracy: 0.2845 - lr: 0.0093\n",
      "Epoch 124/250\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 1.0448 - accuracy: 0.3935 - val_loss: 1.1634 - val_accuracy: 0.2328 - lr: 0.0097\n",
      "Epoch 125/250\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 1.0485 - accuracy: 0.3913 - val_loss: 1.1706 - val_accuracy: 0.2759 - lr: 0.0101\n",
      "Epoch 126/250\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 1.0843 - accuracy: 0.3630 - val_loss: 1.1797 - val_accuracy: 0.2845 - lr: 0.0104\n",
      "Epoch 127/250\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 1.0489 - accuracy: 0.4087 - val_loss: 1.1696 - val_accuracy: 0.3103 - lr: 0.0108\n",
      "Epoch 128/250\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 1.0491 - accuracy: 0.3804 - val_loss: 1.1744 - val_accuracy: 0.2759 - lr: 0.0112\n",
      "Epoch 129/250\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 1.0313 - accuracy: 0.3609 - val_loss: 1.1587 - val_accuracy: 0.3017 - lr: 0.0116\n",
      "Epoch 130/250\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 1.0587 - accuracy: 0.3935 - val_loss: 1.1694 - val_accuracy: 0.3190 - lr: 0.0119\n",
      "Epoch 131/250\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 1.0639 - accuracy: 0.3957 - val_loss: 1.1649 - val_accuracy: 0.2328 - lr: 0.0123\n",
      "Epoch 132/250\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 1.0302 - accuracy: 0.4065 - val_loss: 1.1750 - val_accuracy: 0.3017 - lr: 0.0127\n",
      "Epoch 133/250\n",
      "29/29 [==============================] - 0s 15ms/step - loss: 1.0821 - accuracy: 0.3804 - val_loss: 1.2271 - val_accuracy: 0.2414 - lr: 0.0131\n",
      "Epoch 134/250\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 1.0718 - accuracy: 0.3848 - val_loss: 1.1011 - val_accuracy: 0.3103 - lr: 0.0134\n",
      "Epoch 135/250\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 1.0608 - accuracy: 0.3761 - val_loss: 1.1407 - val_accuracy: 0.2931 - lr: 0.0138\n",
      "Epoch 136/250\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 1.0591 - accuracy: 0.3848 - val_loss: 1.1422 - val_accuracy: 0.2500 - lr: 0.0142\n",
      "Epoch 137/250\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 1.0573 - accuracy: 0.3804 - val_loss: 1.1727 - val_accuracy: 0.2155 - lr: 0.0146\n",
      "Epoch 138/250\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 1.0469 - accuracy: 0.3957 - val_loss: 1.1215 - val_accuracy: 0.3534 - lr: 0.0149\n",
      "Epoch 139/250\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 1.0625 - accuracy: 0.3891 - val_loss: 1.1249 - val_accuracy: 0.3534 - lr: 0.0153\n",
      "Epoch 140/250\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 1.0559 - accuracy: 0.3609 - val_loss: 1.1602 - val_accuracy: 0.2931 - lr: 0.0157\n",
      "Epoch 141/250\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 1.0834 - accuracy: 0.3870 - val_loss: 1.1260 - val_accuracy: 0.2586 - lr: 0.0161\n",
      "Epoch 142/250\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 1.0530 - accuracy: 0.3739 - val_loss: 1.1110 - val_accuracy: 0.2845 - lr: 0.0164\n",
      "Epoch 143/250\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 1.0376 - accuracy: 0.3783 - val_loss: 1.1451 - val_accuracy: 0.3879 - lr: 0.0168\n",
      "Epoch 144/250\n",
      "29/29 [==============================] - 0s 14ms/step - loss: 1.0438 - accuracy: 0.4304 - val_loss: 1.1431 - val_accuracy: 0.3448 - lr: 0.0172\n",
      "Epoch 145/250\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 1.1025 - accuracy: 0.3630 - val_loss: 1.1970 - val_accuracy: 0.2500 - lr: 0.0176\n",
      "Epoch 146/250\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 1.0839 - accuracy: 0.3783 - val_loss: 1.1394 - val_accuracy: 0.3276 - lr: 0.0180\n",
      "Epoch 147/250\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 1.0772 - accuracy: 0.3587 - val_loss: 1.1260 - val_accuracy: 0.3966 - lr: 0.0183\n",
      "Epoch 148/250\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 1.0683 - accuracy: 0.4130 - val_loss: 1.1315 - val_accuracy: 0.3879 - lr: 0.0187\n",
      "Epoch 149/250\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 1.0678 - accuracy: 0.3935 - val_loss: 1.1458 - val_accuracy: 0.3448 - lr: 0.0191\n",
      "Epoch 150/250\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 1.0795 - accuracy: 0.3848 - val_loss: 1.2044 - val_accuracy: 0.2328 - lr: 0.0195\n",
      "Epoch 151/250\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 1.0541 - accuracy: 0.3913 - val_loss: 1.2260 - val_accuracy: 0.2759 - lr: 0.0198\n",
      "Epoch 152/250\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 1.0675 - accuracy: 0.3978 - val_loss: 1.1797 - val_accuracy: 0.3190 - lr: 0.0195\n",
      "Epoch 153/250\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 1.0482 - accuracy: 0.4065 - val_loss: 1.1645 - val_accuracy: 0.3448 - lr: 0.0191\n",
      "Epoch 154/250\n",
      "29/29 [==============================] - 0s 14ms/step - loss: 1.0354 - accuracy: 0.4217 - val_loss: 1.1925 - val_accuracy: 0.2931 - lr: 0.0187\n",
      "Epoch 155/250\n",
      "29/29 [==============================] - 0s 12ms/step - loss: 1.0837 - accuracy: 0.3674 - val_loss: 1.1106 - val_accuracy: 0.3276 - lr: 0.0183\n",
      "Epoch 156/250\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 1.0676 - accuracy: 0.3739 - val_loss: 1.1642 - val_accuracy: 0.2586 - lr: 0.0179\n",
      "Epoch 157/250\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 1.0461 - accuracy: 0.3913 - val_loss: 1.2207 - val_accuracy: 0.2155 - lr: 0.0176\n",
      "Epoch 158/250\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 1.0520 - accuracy: 0.4174 - val_loss: 1.2447 - val_accuracy: 0.2241 - lr: 0.0172\n",
      "Epoch 159/250\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 1.0974 - accuracy: 0.3826 - val_loss: 1.2347 - val_accuracy: 0.1724 - lr: 0.0168\n",
      "Epoch 160/250\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 1.0433 - accuracy: 0.4109 - val_loss: 1.1718 - val_accuracy: 0.3534 - lr: 0.0164\n",
      "Epoch 161/250\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 1.0263 - accuracy: 0.4391 - val_loss: 1.1559 - val_accuracy: 0.3190 - lr: 0.0161\n",
      "Epoch 162/250\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 1.0900 - accuracy: 0.3652 - val_loss: 1.1123 - val_accuracy: 0.3190 - lr: 0.0157\n",
      "Epoch 163/250\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 1.0484 - accuracy: 0.4065 - val_loss: 1.1196 - val_accuracy: 0.2931 - lr: 0.0153\n",
      "Epoch 164/250\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 1.0463 - accuracy: 0.3739 - val_loss: 1.1973 - val_accuracy: 0.2672 - lr: 0.0149\n",
      "Epoch 165/250\n",
      "29/29 [==============================] - 0s 14ms/step - loss: 1.0338 - accuracy: 0.3717 - val_loss: 1.1853 - val_accuracy: 0.3017 - lr: 0.0145\n",
      "Epoch 166/250\n",
      "29/29 [==============================] - 0s 12ms/step - loss: 1.0604 - accuracy: 0.3978 - val_loss: 1.1751 - val_accuracy: 0.2586 - lr: 0.0142\n",
      "Epoch 167/250\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 1.0395 - accuracy: 0.4087 - val_loss: 1.1816 - val_accuracy: 0.3017 - lr: 0.0138\n",
      "Epoch 168/250\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 1.0608 - accuracy: 0.3565 - val_loss: 1.1753 - val_accuracy: 0.2759 - lr: 0.0134\n",
      "Epoch 169/250\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 1.0368 - accuracy: 0.4304 - val_loss: 1.1719 - val_accuracy: 0.2414 - lr: 0.0130\n",
      "Epoch 170/250\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 1.0682 - accuracy: 0.3804 - val_loss: 1.2327 - val_accuracy: 0.2155 - lr: 0.0127\n",
      "Epoch 171/250\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 1.0836 - accuracy: 0.3565 - val_loss: 1.1607 - val_accuracy: 0.2759 - lr: 0.0123\n",
      "Epoch 172/250\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 1.0418 - accuracy: 0.3761 - val_loss: 1.1517 - val_accuracy: 0.3017 - lr: 0.0119\n",
      "Epoch 173/250\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 1.0579 - accuracy: 0.3761 - val_loss: 1.1244 - val_accuracy: 0.3190 - lr: 0.0115\n",
      "Epoch 174/250\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 1.0559 - accuracy: 0.3674 - val_loss: 1.1301 - val_accuracy: 0.3190 - lr: 0.0112\n",
      "Epoch 175/250\n",
      "29/29 [==============================] - 0s 13ms/step - loss: 1.0570 - accuracy: 0.4065 - val_loss: 1.1306 - val_accuracy: 0.2759 - lr: 0.0108\n",
      "Epoch 176/250\n",
      "29/29 [==============================] - 0s 13ms/step - loss: 1.0541 - accuracy: 0.3739 - val_loss: 1.1431 - val_accuracy: 0.2500 - lr: 0.0104\n",
      "Epoch 177/250\n",
      "29/29 [==============================] - 0s 12ms/step - loss: 1.0541 - accuracy: 0.3891 - val_loss: 1.1182 - val_accuracy: 0.3017 - lr: 0.0100\n",
      "Epoch 178/250\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 1.0388 - accuracy: 0.3717 - val_loss: 1.1497 - val_accuracy: 0.2845 - lr: 0.0096\n",
      "Epoch 179/250\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 1.0539 - accuracy: 0.4043 - val_loss: 1.1476 - val_accuracy: 0.2586 - lr: 0.0093\n",
      "Epoch 180/250\n",
      "29/29 [==============================] - 0s 12ms/step - loss: 1.0639 - accuracy: 0.3804 - val_loss: 1.1441 - val_accuracy: 0.2931 - lr: 0.0089\n",
      "Epoch 181/250\n",
      "29/29 [==============================] - 0s 12ms/step - loss: 1.0268 - accuracy: 0.4283 - val_loss: 1.1570 - val_accuracy: 0.3017 - lr: 0.0085\n",
      "Epoch 182/250\n",
      "29/29 [==============================] - 0s 12ms/step - loss: 1.0522 - accuracy: 0.4261 - val_loss: 1.1649 - val_accuracy: 0.2845 - lr: 0.0081\n",
      "Epoch 183/250\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 1.0612 - accuracy: 0.3891 - val_loss: 1.1669 - val_accuracy: 0.2672 - lr: 0.0078\n",
      "Epoch 184/250\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 1.0424 - accuracy: 0.3826 - val_loss: 1.1573 - val_accuracy: 0.2500 - lr: 0.0074\n",
      "Epoch 185/250\n",
      "29/29 [==============================] - 0s 14ms/step - loss: 1.0251 - accuracy: 0.4087 - val_loss: 1.1460 - val_accuracy: 0.2931 - lr: 0.0070\n",
      "Epoch 186/250\n",
      "29/29 [==============================] - 0s 12ms/step - loss: 1.0336 - accuracy: 0.3978 - val_loss: 1.1193 - val_accuracy: 0.3103 - lr: 0.0066\n",
      "Epoch 187/250\n",
      "29/29 [==============================] - 0s 12ms/step - loss: 1.0251 - accuracy: 0.4304 - val_loss: 1.1251 - val_accuracy: 0.2845 - lr: 0.0063\n",
      "Epoch 188/250\n",
      "29/29 [==============================] - 0s 12ms/step - loss: 1.0371 - accuracy: 0.4370 - val_loss: 1.1369 - val_accuracy: 0.2759 - lr: 0.0059\n",
      "Epoch 189/250\n",
      "29/29 [==============================] - 0s 12ms/step - loss: 1.0558 - accuracy: 0.3935 - val_loss: 1.1381 - val_accuracy: 0.2500 - lr: 0.0055\n",
      "Epoch 190/250\n",
      "29/29 [==============================] - 0s 12ms/step - loss: 1.0557 - accuracy: 0.3717 - val_loss: 1.1191 - val_accuracy: 0.2931 - lr: 0.0051\n",
      "Epoch 191/250\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 1.0293 - accuracy: 0.4283 - val_loss: 1.1521 - val_accuracy: 0.3017 - lr: 0.0048\n",
      "Epoch 192/250\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 1.0253 - accuracy: 0.4130 - val_loss: 1.1513 - val_accuracy: 0.2845 - lr: 0.0044\n",
      "Epoch 193/250\n",
      "29/29 [==============================] - 0s 12ms/step - loss: 1.0612 - accuracy: 0.4217 - val_loss: 1.1343 - val_accuracy: 0.3190 - lr: 0.0040\n",
      "Epoch 194/250\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 1.0328 - accuracy: 0.4087 - val_loss: 1.1558 - val_accuracy: 0.3017 - lr: 0.0036\n",
      "Epoch 195/250\n",
      "29/29 [==============================] - 0s 16ms/step - loss: 1.0167 - accuracy: 0.4239 - val_loss: 1.1699 - val_accuracy: 0.2759 - lr: 0.0033\n",
      "Epoch 196/250\n",
      "29/29 [==============================] - 0s 16ms/step - loss: 1.0551 - accuracy: 0.3891 - val_loss: 1.1635 - val_accuracy: 0.2845 - lr: 0.0029\n",
      "Epoch 197/250\n",
      "29/29 [==============================] - 0s 15ms/step - loss: 1.0353 - accuracy: 0.4022 - val_loss: 1.1647 - val_accuracy: 0.2845 - lr: 0.0025\n",
      "Epoch 198/250\n",
      "29/29 [==============================] - 0s 16ms/step - loss: 1.0344 - accuracy: 0.4065 - val_loss: 1.1522 - val_accuracy: 0.2759 - lr: 0.0021\n",
      "Epoch 199/250\n",
      "29/29 [==============================] - 0s 14ms/step - loss: 1.0280 - accuracy: 0.4326 - val_loss: 1.1495 - val_accuracy: 0.2931 - lr: 0.0018\n",
      "Epoch 200/250\n",
      "29/29 [==============================] - 0s 15ms/step - loss: 1.0217 - accuracy: 0.4348 - val_loss: 1.1503 - val_accuracy: 0.2845 - lr: 0.0014\n",
      "Epoch 201/250\n",
      "29/29 [==============================] - 0s 13ms/step - loss: 1.0267 - accuracy: 0.4022 - val_loss: 1.1478 - val_accuracy: 0.3103 - lr: 0.0010\n",
      "Epoch 202/250\n",
      "29/29 [==============================] - 0s 12ms/step - loss: 1.0245 - accuracy: 0.4174 - val_loss: 1.1543 - val_accuracy: 0.2931 - lr: 0.0014\n",
      "Epoch 203/250\n",
      "29/29 [==============================] - 0s 12ms/step - loss: 1.0232 - accuracy: 0.4326 - val_loss: 1.1604 - val_accuracy: 0.2845 - lr: 0.0018\n",
      "Epoch 204/250\n",
      "29/29 [==============================] - 0s 15ms/step - loss: 1.0503 - accuracy: 0.4326 - val_loss: 1.1582 - val_accuracy: 0.2845 - lr: 0.0021\n",
      "Epoch 205/250\n",
      "29/29 [==============================] - 0s 12ms/step - loss: 1.0280 - accuracy: 0.4152 - val_loss: 1.1643 - val_accuracy: 0.2931 - lr: 0.0025\n",
      "Epoch 206/250\n",
      "29/29 [==============================] - 0s 16ms/step - loss: 1.0190 - accuracy: 0.4304 - val_loss: 1.1517 - val_accuracy: 0.3017 - lr: 0.0029\n",
      "Epoch 207/250\n",
      "29/29 [==============================] - 0s 15ms/step - loss: 1.0343 - accuracy: 0.4174 - val_loss: 1.1418 - val_accuracy: 0.3190 - lr: 0.0033\n",
      "Epoch 208/250\n",
      "29/29 [==============================] - 0s 15ms/step - loss: 1.0254 - accuracy: 0.4500 - val_loss: 1.1486 - val_accuracy: 0.3017 - lr: 0.0036\n",
      "Epoch 209/250\n",
      "29/29 [==============================] - 0s 14ms/step - loss: 1.0482 - accuracy: 0.3913 - val_loss: 1.1438 - val_accuracy: 0.3103 - lr: 0.0040\n",
      "Epoch 210/250\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 1.0254 - accuracy: 0.4326 - val_loss: 1.1293 - val_accuracy: 0.2931 - lr: 0.0044\n",
      "Epoch 211/250\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 1.0374 - accuracy: 0.4283 - val_loss: 1.1565 - val_accuracy: 0.2759 - lr: 0.0048\n",
      "Epoch 212/250\n",
      "29/29 [==============================] - 0s 13ms/step - loss: 1.0319 - accuracy: 0.4065 - val_loss: 1.1305 - val_accuracy: 0.3707 - lr: 0.0051\n",
      "Epoch 213/250\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 1.0044 - accuracy: 0.4109 - val_loss: 1.1144 - val_accuracy: 0.3621 - lr: 0.0055\n",
      "Epoch 214/250\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 1.0386 - accuracy: 0.3870 - val_loss: 1.0909 - val_accuracy: 0.3190 - lr: 0.0059\n",
      "Epoch 215/250\n",
      "29/29 [==============================] - 0s 13ms/step - loss: 1.0390 - accuracy: 0.4348 - val_loss: 1.1805 - val_accuracy: 0.2931 - lr: 0.0063\n",
      "Epoch 216/250\n",
      "29/29 [==============================] - 0s 13ms/step - loss: 1.0475 - accuracy: 0.4022 - val_loss: 1.1850 - val_accuracy: 0.2672 - lr: 0.0066\n",
      "Epoch 217/250\n",
      "29/29 [==============================] - 0s 14ms/step - loss: 1.0432 - accuracy: 0.4174 - val_loss: 1.1756 - val_accuracy: 0.2500 - lr: 0.0070\n",
      "Epoch 218/250\n",
      "29/29 [==============================] - 0s 12ms/step - loss: 1.0100 - accuracy: 0.4587 - val_loss: 1.1505 - val_accuracy: 0.2759 - lr: 0.0074\n",
      "Epoch 219/250\n",
      "29/29 [==============================] - 0s 15ms/step - loss: 1.0320 - accuracy: 0.4196 - val_loss: 1.1394 - val_accuracy: 0.2931 - lr: 0.0078\n",
      "Epoch 220/250\n",
      "29/29 [==============================] - 0s 15ms/step - loss: 1.0697 - accuracy: 0.4217 - val_loss: 1.1758 - val_accuracy: 0.2586 - lr: 0.0081\n",
      "Epoch 221/250\n",
      "29/29 [==============================] - 0s 12ms/step - loss: 1.0339 - accuracy: 0.4065 - val_loss: 1.1593 - val_accuracy: 0.3017 - lr: 0.0085\n",
      "Epoch 222/250\n",
      "29/29 [==============================] - 0s 14ms/step - loss: 1.0347 - accuracy: 0.4239 - val_loss: 1.1651 - val_accuracy: 0.2500 - lr: 0.0089\n",
      "Epoch 223/250\n",
      "29/29 [==============================] - 0s 13ms/step - loss: 1.0277 - accuracy: 0.4152 - val_loss: 1.1920 - val_accuracy: 0.2500 - lr: 0.0092\n",
      "Epoch 224/250\n",
      "29/29 [==============================] - 0s 13ms/step - loss: 1.0439 - accuracy: 0.3891 - val_loss: 1.1653 - val_accuracy: 0.2672 - lr: 0.0096\n",
      "Epoch 225/250\n",
      "29/29 [==============================] - 0s 15ms/step - loss: 1.0539 - accuracy: 0.3717 - val_loss: 1.1279 - val_accuracy: 0.3276 - lr: 0.0100\n",
      "Epoch 226/250\n",
      "29/29 [==============================] - 0s 13ms/step - loss: 1.0507 - accuracy: 0.4239 - val_loss: 1.1042 - val_accuracy: 0.3448 - lr: 0.0104\n",
      "Epoch 227/250\n",
      "29/29 [==============================] - 0s 14ms/step - loss: 1.0488 - accuracy: 0.4174 - val_loss: 1.1289 - val_accuracy: 0.3276 - lr: 0.0107\n",
      "Epoch 228/250\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 1.0457 - accuracy: 0.4348 - val_loss: 1.1047 - val_accuracy: 0.3190 - lr: 0.0111\n",
      "Epoch 229/250\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 1.0572 - accuracy: 0.4196 - val_loss: 1.1010 - val_accuracy: 0.3362 - lr: 0.0115\n",
      "Epoch 230/250\n",
      "29/29 [==============================] - 0s 13ms/step - loss: 1.0597 - accuracy: 0.3761 - val_loss: 1.1151 - val_accuracy: 0.3534 - lr: 0.0119\n",
      "Epoch 231/250\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 1.0260 - accuracy: 0.4239 - val_loss: 1.1568 - val_accuracy: 0.3017 - lr: 0.0122\n",
      "Epoch 232/250\n",
      "29/29 [==============================] - 0s 13ms/step - loss: 1.0337 - accuracy: 0.4217 - val_loss: 1.1686 - val_accuracy: 0.2759 - lr: 0.0126\n",
      "Epoch 233/250\n",
      "29/29 [==============================] - 0s 14ms/step - loss: 1.0129 - accuracy: 0.4413 - val_loss: 1.1875 - val_accuracy: 0.2586 - lr: 0.0130\n",
      "Epoch 234/250\n",
      "29/29 [==============================] - 0s 12ms/step - loss: 1.0513 - accuracy: 0.3783 - val_loss: 1.1581 - val_accuracy: 0.2586 - lr: 0.0134\n",
      "Epoch 235/250\n",
      "29/29 [==============================] - 0s 13ms/step - loss: 1.0663 - accuracy: 0.4261 - val_loss: 1.1869 - val_accuracy: 0.2586 - lr: 0.0137\n",
      "Epoch 236/250\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 1.0636 - accuracy: 0.3696 - val_loss: 1.2313 - val_accuracy: 0.2241 - lr: 0.0141\n",
      "Epoch 237/250\n",
      "29/29 [==============================] - 0s 12ms/step - loss: 1.0512 - accuracy: 0.3891 - val_loss: 1.1141 - val_accuracy: 0.2845 - lr: 0.0145\n",
      "Epoch 238/250\n",
      "29/29 [==============================] - 0s 14ms/step - loss: 1.0183 - accuracy: 0.4261 - val_loss: 1.1671 - val_accuracy: 0.2759 - lr: 0.0149\n",
      "Epoch 239/250\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 1.0563 - accuracy: 0.4022 - val_loss: 1.1054 - val_accuracy: 0.3879 - lr: 0.0152\n",
      "Epoch 240/250\n",
      "29/29 [==============================] - 0s 12ms/step - loss: 1.0354 - accuracy: 0.3935 - val_loss: 1.1418 - val_accuracy: 0.3621 - lr: 0.0156\n",
      "Epoch 241/250\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 1.0688 - accuracy: 0.3696 - val_loss: 1.1653 - val_accuracy: 0.2845 - lr: 0.0160\n",
      "Epoch 242/250\n",
      "29/29 [==============================] - 0s 10ms/step - loss: 1.0862 - accuracy: 0.3630 - val_loss: 1.1704 - val_accuracy: 0.2672 - lr: 0.0164\n",
      "Epoch 243/250\n",
      "29/29 [==============================] - 0s 13ms/step - loss: 1.0661 - accuracy: 0.3935 - val_loss: 1.1550 - val_accuracy: 0.2759 - lr: 0.0167\n",
      "Epoch 244/250\n",
      "29/29 [==============================] - 0s 13ms/step - loss: 1.0590 - accuracy: 0.3870 - val_loss: 1.1614 - val_accuracy: 0.3103 - lr: 0.0171\n",
      "Epoch 245/250\n",
      "29/29 [==============================] - 0s 12ms/step - loss: 1.0350 - accuracy: 0.4174 - val_loss: 1.2626 - val_accuracy: 0.2241 - lr: 0.0175\n",
      "Epoch 246/250\n",
      "29/29 [==============================] - 0s 15ms/step - loss: 1.0478 - accuracy: 0.4283 - val_loss: 1.1889 - val_accuracy: 0.2328 - lr: 0.0179\n",
      "Epoch 247/250\n",
      "29/29 [==============================] - 0s 13ms/step - loss: 1.0283 - accuracy: 0.4196 - val_loss: 1.2394 - val_accuracy: 0.2672 - lr: 0.0182\n",
      "Epoch 248/250\n",
      "29/29 [==============================] - 0s 17ms/step - loss: 1.0319 - accuracy: 0.4130 - val_loss: 1.1820 - val_accuracy: 0.2931 - lr: 0.0186\n",
      "Epoch 249/250\n",
      "29/29 [==============================] - 0s 16ms/step - loss: 1.0442 - accuracy: 0.4087 - val_loss: 1.1906 - val_accuracy: 0.2931 - lr: 0.0190\n",
      "Epoch 250/250\n",
      "29/29 [==============================] - 0s 17ms/step - loss: 1.0742 - accuracy: 0.3783 - val_loss: 1.1234 - val_accuracy: 0.3017 - lr: 0.0193\n"
     ]
    }
   ],
   "source": [
    "### model training on training dataset\n",
    "# history = model.fit_model(x_train, y_train, epochs=args_dnn.epochs, batch_size=args_dnn.bs, validation_split=0.2)\n",
    "history = model.fit_model(x_train, y_train, epochs=args_dnn.epochs, batch_size=args_dnn.bs, class_weight = class_weight, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4d7961f-5799-4074-9760-5f0b6508982a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bba6c6d9-4109-460b-974e-991c3d3e4b0b",
   "metadata": {},
   "source": [
    "* Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "7a2dfb7a-0f46-41e4-9776-e5a11cef658d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model_performance(model, x_test, y_test):\n",
    "\n",
    "    ## predict on model\n",
    "    y_predict = model.predict(x_test)\n",
    "    y_predict_classes = np.argmax(y_predict, axis=1)\n",
    "    y_test_classes = np.argmax(y_test, axis=1)\n",
    "    \n",
    "    ## calculate confusion matrix and visualize\n",
    "    cm = confusion_matrix(y_test_classes, y_predict_classes, normalize='pred')\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    sns.heatmap(cm, annot=True, cmap=plt.cm.Blues, fmt='.2f')\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.show()\n",
    "    \n",
    "    ## evaluation metrics\n",
    "    accuracy = accuracy_score(y_test_classes, y_predict_classes)\n",
    "    precision = precision_score(y_test_classes, y_predict_classes, average='macro')\n",
    "    recall = recall_score(y_test_classes, y_predict_classes, average='micro')\n",
    "    f1 = f1_score(y_test_classes, y_predict_classes, average='weighted')\n",
    "    auc = roc_auc_score(y_test, y_predict, multi_class='ovr')\n",
    "    \n",
    "    ## Results\n",
    "    print(\"=============================================\")\n",
    "    print(f\"The overall accuracy is: {accuracy:.4f}\")\n",
    "    print(f\"The precision score is: {precision:.4f}\")\n",
    "    print(f\"The recall score is: {recall:.4f}\")\n",
    "    print(f\"The F1 score is: {f1:.4f}\")\n",
    "    print(f\"The AUC score is: {auc:.4f}\")\n",
    "    print(\"=============================================\")\n",
    "    \n",
    "    ## Print out the classification report\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(y_test_classes, y_predict_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "2ee306ab-7e58-4dbe-ae53-81288849ea4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=============================================\n",
      "The overall accuracy is: 0.3448\n",
      "The precision score is: 0.3287\n",
      "The recall score is: 0.3448\n",
      "The F1 score is: 0.3502\n",
      "The AUC score is: 0.5305\n",
      "=============================================\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.18      0.50      0.27        20\n",
      "           1       0.30      0.17      0.21        48\n",
      "           2       0.51      0.42      0.46        77\n",
      "\n",
      "    accuracy                           0.34       145\n",
      "   macro avg       0.33      0.36      0.31       145\n",
      "weighted avg       0.39      0.34      0.35       145\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluate_model_performance(model, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "671d88a1-b1b6-4386-a3c8-9bdde0cef008",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4c45e383-4895-4dda-813c-ead039ec9009",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c91ad0f-2d8f-49a7-8b97-85cd38696300",
   "metadata": {},
   "source": [
    "## K-fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea3f292e-fbce-486e-8e2f-9b87e479afbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Args_kfold:\n",
    "    # arugments\n",
    "    epochs=70\n",
    "    bs=32\n",
    "    lr=0.0001\n",
    "    momentum=0.9\n",
    "    num_classes= 3\n",
    "    split=5\n",
    "    seed=710674\n",
    "\n",
    "args_kfold = Args_kfold()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a9e25cb-fbad-4575-8461-d42ce17af307",
   "metadata": {},
   "outputs": [],
   "source": [
    "class kfoldMLP:\n",
    "    def __init__(self, input_dim, layer_configs, output_units, output_activation='softmax'):\n",
    "        self.input_dim = input_dim\n",
    "        self.layer_configs = layer_configs\n",
    "        self.output_units = output_units\n",
    "        self.output_activation = output_activation\n",
    "        self.callbacks = []\n",
    "        self.model = None\n",
    "        \n",
    "    def build_model(self):\n",
    "        model = models.Sequential()\n",
    "        \n",
    "        ## add first hidden layer\n",
    "        model.add(layers.Dense(units=self.layer_configs[0]['units'], \n",
    "                               activation=self.layer_configs[0]['activation'], \n",
    "                               input_shape=(self.input_dim,)))\n",
    "        \n",
    "        ## batch normalization and dropout for first layer\n",
    "        if self.layer_configs[0].get('batch_norm', False):\n",
    "            model.add(layers.BatchNormalization())\n",
    "        \n",
    "        if self.layer_configs[0].get('dropout_rate', None) is not None:\n",
    "            model.add(layers.Dropout(rate=self.layer_configs[0]['dropout_rate']))\n",
    "        \n",
    "        ## do same for rest hidden layers (except for the last)\n",
    "        for config in self.layer_configs[1:]:\n",
    "            model.add(layers.Dense(units=config['units'], activation=config['activation']))\n",
    "            \n",
    "            if config.get('batch_norm', False):\n",
    "                model.add(layers.BatchNormalization())\n",
    "            \n",
    "            if config.get('dropout_rate', None) is not None:\n",
    "                model.add(layers.Dropout(rate=config['dropout_rate']))\n",
    "        \n",
    "        ## add output layer\n",
    "        model.add(layers.Dense(units=self.output_units, activation=self.output_activation))\n",
    "        self.model = model\n",
    "\n",
    "    ## model compile\n",
    "    def compile_model(self, optimizer, loss='categorical_crossentropy', metrics=['accuracy'], lr_scheduler=None):\n",
    "        if lr_scheduler:\n",
    "            self.callbacks.append(tf.keras.callbacks.LearningRateScheduler(lr_scheduler))\n",
    "\n",
    "        self.model.compile(optimizer=optimizer, loss=loss, metrics=metrics)\n",
    "\n",
    "    def fit_model(self, x_train, y_train, epochs, batch_size, validation_data=None, class_weight=None, verbose=0):\n",
    "        return self.model.fit(\n",
    "            x_train, y_train, \n",
    "            epochs=epochs, \n",
    "            batch_size=batch_size, \n",
    "            validation_data=validation_data, \n",
    "            callbacks=self.callbacks, \n",
    "            class_weight=class_weight,\n",
    "            verbose=verbose\n",
    "        )\n",
    "\n",
    "    def evaluate_model(self, x_test, y_test):\n",
    "        return self.model.evaluate(x_test, y_test)\n",
    "\n",
    "    def predict(self, x):\n",
    "        y_pred = self.model.predict(x)\n",
    "        return np.array(y_pred)\n",
    "\n",
    "    def summary(self):\n",
    "        self.model.summary()\n",
    "\n",
    "    def cross_validate(self, x_data, y_data, n_splits, epochs, batch_size, optimizer=None, class_weight=None):\n",
    "        x_data = np.array(x_data)\n",
    "        y_data = np.array(y_data)\n",
    "        kf = KFold(n_splits=n_splits, shuffle=True) ##set fold split and shuffle\n",
    "        fold_metrics = []\n",
    "\n",
    "        for fold, (train_index, val_index) in enumerate(kf.split(x_data), 1):\n",
    "            x_train, x_val = x_data[train_index], x_data[val_index]\n",
    "            y_train, y_val = y_data[train_index], y_data[val_index]\n",
    "\n",
    "            ## build new model\n",
    "            self.build_model()\n",
    "            self.compile_model(optimizer=optimizer)\n",
    "            \n",
    "            ## model training\n",
    "            self.fit_model(x_train, y_train, epochs=epochs, batch_size=batch_size, validation_data=(x_val, y_val), class_weight=class_weight, verbose=0)\n",
    "            \n",
    "            ## evaluate the model\n",
    "            y_val_pred = self.predict(x_val)\n",
    "            if isinstance(y_val_pred, list):\n",
    "                y_val_pred = np.array(y_val_pred)\n",
    "            y_val_pred = np.argmax(y_val_pred, axis=1)\n",
    "            y_val_true = np.argmax(y_val, axis=1)\n",
    "            \n",
    "            accuracy = accuracy_score(y_val_true, y_val_pred)\n",
    "            precision = precision_score(y_val_true, y_val_pred, average='macro')\n",
    "            recall = recall_score(y_val_true, y_val_pred, average='macro')\n",
    "            f1 = f1_score(y_val_true, y_val_pred, average='weighted')\n",
    "            auc = roc_auc_score(y_val, self.predict(x_val), multi_class='ovr')\n",
    "            \n",
    "            fold_metrics.append({\n",
    "                'accuracy': accuracy,\n",
    "                'precision': precision,\n",
    "                'recall': recall,\n",
    "                'f1_score': f1,\n",
    "                'auc': auc\n",
    "            })\n",
    "\n",
    "            print(f\"Fold metrics: Accuracy={accuracy:.4f}, Precision={precision:.4f}, Recall={recall:.4f}, F1 Score={f1:.4f}, AUC={auc:.4f}\")\n",
    "        \n",
    "        avg_metrics = {key: np.mean([m[key] for m in fold_metrics]) for key in fold_metrics[0].keys()}\n",
    "        \n",
    "        print(\"\\nAverage metrics across all folds:\")\n",
    "        for metric, value in avg_metrics.items():\n",
    "            print(f\"{metric.capitalize()}: {value:.4f}\")\n",
    "\n",
    "        return fold_metrics, avg_metrics\n",
    "\n",
    "    ## evaluation on test dataset (for performance check)\n",
    "    def evaluate_test_data(self, x_test, y_test):\n",
    "        y_pred = self.predict(x_test)\n",
    "        y_pred_labels = np.argmax(y_pred, axis=1)\n",
    "        y_true_labels = np.argmax(y_test, axis=1)\n",
    "\n",
    "        # Confusion Matrix\n",
    "        cm = confusion_matrix(y_true_labels, y_pred_labels, normalize='pred')\n",
    "        plt.figure(figsize=(6, 4))\n",
    "        sns.heatmap(cm, annot=True, fmt='.2f', cmap='Blues')\n",
    "        plt.title('Confusion Matrix')\n",
    "        plt.ylabel('True Label')\n",
    "        plt.xlabel('Predicted Label')\n",
    "        plt.show()\n",
    "        print(\"=============================================\")\n",
    "\n",
    "        # Classification Report\n",
    "        class_report = classification_report(y_true_labels, y_pred_labels, target_names=[f'Class {i}' for i in range(self.output_units)])\n",
    "        print(\"Classification Report:\\n\", class_report)\n",
    "\n",
    "        return cm, class_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "348e0691-d62b-481a-86f0-58486dc577b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## model initialization with hidden layer list below\n",
    "layer_configs = [\n",
    "    {'units': 64, 'activation': 'relu', 'batch_norm': True, 'dropout_rate': 0.5},\n",
    "    {'units': 32, 'activation': 'relu', 'batch_norm': False, 'dropout_rate': 0.3},\n",
    "    {'units': 16, 'activation': 'relu', 'batch_norm': True, 'dropout_rate': 0.2}\n",
    "]\n",
    "\n",
    "kfold = kfoldMLP(output_units=args_kfold.num_classes, input_dim=x_train.shape[1], layer_configs=layer_configs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdcc1dce-e3a0-4b02-a443-8e1c8651136b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## compile our model\n",
    "opt = keras.optimizers.SGD(learning_rate = 0.001, decay = 1e-5, momentum = 0.9)\n",
    "scheduler = lambda epoch: dynamic_learning_rate(epoch, mode='triangular2', base_lr=0.001, max_lr=0.009, step_size=25)\n",
    "\n",
    "## model summary\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67247754-33e6-4083-b5b3-a1bd47e88686",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# K-Fold 교차 검증 실행\n",
    "metrics, avg_metrics = kfold.cross_validate(x_train, y_train, n_splits=args_kfold.split, optimizer=opt, epochs=args_kfold.epochs, batch_size=args_kfold.bs)\n",
    "\n",
    "# # 각 폴드의 성능 지표 출력\n",
    "# for i, metric in enumerate(metrics):\n",
    "#     print(f\"Fold {i+1}: {metric}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ee90fdf-5b26-4e4c-935f-3780eb5fe944",
   "metadata": {},
   "source": [
    "* Evaluation on test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3bde173-0483-46c3-9640-62c675a5c392",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm, class_report = kfold.evaluate_test_data(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb1e8976-a689-4a0c-b744-0732f1808cc3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cefa5011-78f0-4c2c-b4de-6df4c4bf26d1",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e9453da-c2ef-4fb0-9817-68321d13236c",
   "metadata": {},
   "source": [
    "## 1D-Conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "34654d7e-8592-45af-a55c-a4af89366dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Args_conv:\n",
    "    # arugments\n",
    "    epochs=70\n",
    "    bs=16\n",
    "    lr=0.0001\n",
    "    momentum=0.9\n",
    "    num_classes= 3\n",
    "    split=5\n",
    "    seed=710674\n",
    "\n",
    "args_conv = Args_conv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4f12e02c-30c4-4729-8086-7c80830eb6ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv1Dmodel:\n",
    "    def __init__(self, input_shape, conv_layers, dense_layers, output_units, output_activation='softmax'):\n",
    "        self.input_shape = input_shape\n",
    "        self.conv_layers = conv_layers\n",
    "        self.dense_layers = dense_layers\n",
    "        self.output_units = output_units\n",
    "        self.output_activation = output_activation\n",
    "        self.model = None\n",
    "        self.callbacks = []\n",
    "\n",
    "    def build_model(self):\n",
    "        model = Sequential()\n",
    "\n",
    "        # Add Conv1D layers\n",
    "        for i, config in enumerate(self.conv_layers):\n",
    "            if i == 0:\n",
    "                model.add(Conv1D(\n",
    "                    filters=config['filters'],\n",
    "                    kernel_size=config['kernel_size'],\n",
    "                    activation=config['activation'],\n",
    "                    input_shape=self.input_shape\n",
    "                ))\n",
    "            else:\n",
    "                model.add(Conv1D(\n",
    "                    filters=config['filters'],\n",
    "                    kernel_size=config['kernel_size'],\n",
    "                    activation=config['activation']\n",
    "                ))\n",
    "\n",
    "            if 'pool_size' in config:\n",
    "                model.add(MaxPooling1D(pool_size=config['pool_size']))\n",
    "\n",
    "        # Add Flatten layer\n",
    "        model.add(Flatten())\n",
    "\n",
    "        # Add Dense layers\n",
    "        for config in self.dense_layers:\n",
    "            model.add(Dense(\n",
    "                units=config['units'],\n",
    "                activation=config['activation']\n",
    "            ))\n",
    "            if config.get('batch_norm', False):\n",
    "                model.add(BatchNormalization())\n",
    "            if config.get('dropout_rate', None) is not None:\n",
    "                model.add(Dropout(rate=config['dropout_rate']))\n",
    "\n",
    "        # Add Output layer\n",
    "        model.add(Dense(self.output_units, activation=self.output_activation))\n",
    "\n",
    "        self.model = model\n",
    "\n",
    "    def compile_model(self, optimizer, loss='categorical_crossentropy', metrics=['accuracy'], lr_scheduler=None):\n",
    "        if lr_scheduler:\n",
    "            self.callbacks.append(LearningRateScheduler(lr_scheduler))\n",
    "\n",
    "        self.model.compile(optimizer=optimizer, loss=loss, metrics=metrics)\n",
    "\n",
    "    def fit_model(self, x_train, y_train, epochs, batch_size, validation_data=None, class_weight=None, verbose=1):\n",
    "\n",
    "        return self.model.fit(\n",
    "            x_train, y_train, \n",
    "            epochs=epochs, \n",
    "            batch_size=batch_size, \n",
    "            validation_data=validation_data, \n",
    "            callbacks=self.callbacks, \n",
    "            class_weight=class_weight,\n",
    "            verbose=verbose\n",
    "        )\n",
    "\n",
    "    def evaluate_model(self, x_test, y_test):\n",
    "        return self.model.evaluate(x_test, y_test)\n",
    "\n",
    "    def predict(self, x):\n",
    "        return self.model.predict(x)\n",
    "\n",
    "    def summary(self):\n",
    "        if self.model:\n",
    "            self.model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "209a2382-f2a9-4246-bd08-a713d8903944",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define layer configurations\n",
    "conv_layers = [\n",
    "    {'filters': 32, 'kernel_size': 5, 'activation': 'relu', 'pool_size': 3},\n",
    "    {'filters': 16, 'kernel_size': 3, 'activation': 'relu', 'pool_size': 3}\n",
    "]\n",
    "\n",
    "dense_layers = [\n",
    "    {'units': 64, 'activation': 'relu', 'batch_norm': True, 'dropout_rate': 0.5},\n",
    "    {'units': 32, 'activation': 'relu'}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1a8af224-a961-46fb-be8c-295610f17ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (x_train.shape[1], 1)\n",
    "conv1d = Conv1Dmodel(input_shape = input_shape, conv_layers=conv_layers, dense_layers=dense_layers, output_units=args_conv.num_classes)\n",
    "conv1d.build_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea4e2a57-f3b5-4406-9308-cb0f6e35c647",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "fa5556c9-5f1d-4341-80de-f616bf8491c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = keras.optimizers.SGD(learning_rate = 0.001, decay = 1e-5, momentum = 0.9)\n",
    "scheduler = lambda epoch: dynamic_learning_rate(epoch, mode='triangular2', base_lr=0.001, max_lr=0.009, step_size=25)\n",
    "\n",
    "conv1d.compile_model(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'], lr_scheduler=scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "21efc81e-f9af-45ef-927a-836cd57750e1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "36/36 - 4s - loss: 1.1592 - accuracy: 0.3351 - lr: 0.0010 - 4s/epoch - 117ms/step\n",
      "Epoch 2/70\n",
      "36/36 - 0s - loss: 1.1350 - accuracy: 0.3420 - lr: 0.0013 - 177ms/epoch - 5ms/step\n",
      "Epoch 3/70\n",
      "36/36 - 0s - loss: 1.1167 - accuracy: 0.3403 - lr: 0.0016 - 258ms/epoch - 7ms/step\n",
      "Epoch 4/70\n",
      "36/36 - 0s - loss: 1.1181 - accuracy: 0.3403 - lr: 0.0020 - 175ms/epoch - 5ms/step\n",
      "Epoch 5/70\n",
      "36/36 - 0s - loss: 1.1111 - accuracy: 0.3750 - lr: 0.0023 - 157ms/epoch - 4ms/step\n",
      "Epoch 6/70\n",
      "36/36 - 0s - loss: 1.1167 - accuracy: 0.3212 - lr: 0.0026 - 152ms/epoch - 4ms/step\n",
      "Epoch 7/70\n",
      "36/36 - 0s - loss: 1.1131 - accuracy: 0.3438 - lr: 0.0029 - 152ms/epoch - 4ms/step\n",
      "Epoch 8/70\n",
      "36/36 - 0s - loss: 1.1010 - accuracy: 0.3385 - lr: 0.0032 - 149ms/epoch - 4ms/step\n",
      "Epoch 9/70\n",
      "36/36 - 0s - loss: 1.1079 - accuracy: 0.3490 - lr: 0.0036 - 155ms/epoch - 4ms/step\n",
      "Epoch 10/70\n",
      "36/36 - 0s - loss: 1.0937 - accuracy: 0.3507 - lr: 0.0039 - 148ms/epoch - 4ms/step\n",
      "Epoch 11/70\n",
      "36/36 - 0s - loss: 1.0953 - accuracy: 0.3438 - lr: 0.0042 - 144ms/epoch - 4ms/step\n",
      "Epoch 12/70\n",
      "36/36 - 0s - loss: 1.1000 - accuracy: 0.4045 - lr: 0.0045 - 149ms/epoch - 4ms/step\n",
      "Epoch 13/70\n",
      "36/36 - 0s - loss: 1.1143 - accuracy: 0.3281 - lr: 0.0048 - 148ms/epoch - 4ms/step\n",
      "Epoch 14/70\n",
      "36/36 - 0s - loss: 1.1039 - accuracy: 0.3385 - lr: 0.0052 - 148ms/epoch - 4ms/step\n",
      "Epoch 15/70\n",
      "36/36 - 0s - loss: 1.0917 - accuracy: 0.3750 - lr: 0.0055 - 152ms/epoch - 4ms/step\n",
      "Epoch 16/70\n",
      "36/36 - 0s - loss: 1.1082 - accuracy: 0.3524 - lr: 0.0058 - 247ms/epoch - 7ms/step\n",
      "Epoch 17/70\n",
      "36/36 - 0s - loss: 1.0861 - accuracy: 0.4080 - lr: 0.0061 - 148ms/epoch - 4ms/step\n",
      "Epoch 18/70\n",
      "36/36 - 0s - loss: 1.0979 - accuracy: 0.3976 - lr: 0.0064 - 148ms/epoch - 4ms/step\n",
      "Epoch 19/70\n",
      "36/36 - 0s - loss: 1.1080 - accuracy: 0.3438 - lr: 0.0068 - 168ms/epoch - 5ms/step\n",
      "Epoch 20/70\n",
      "36/36 - 0s - loss: 1.1022 - accuracy: 0.3628 - lr: 0.0071 - 152ms/epoch - 4ms/step\n",
      "Epoch 21/70\n",
      "36/36 - 0s - loss: 1.0989 - accuracy: 0.3455 - lr: 0.0074 - 143ms/epoch - 4ms/step\n",
      "Epoch 22/70\n",
      "36/36 - 0s - loss: 1.0848 - accuracy: 0.3924 - lr: 0.0077 - 159ms/epoch - 4ms/step\n",
      "Epoch 23/70\n",
      "36/36 - 0s - loss: 1.1000 - accuracy: 0.3559 - lr: 0.0080 - 152ms/epoch - 4ms/step\n",
      "Epoch 24/70\n",
      "36/36 - 0s - loss: 1.0913 - accuracy: 0.3594 - lr: 0.0084 - 145ms/epoch - 4ms/step\n",
      "Epoch 25/70\n",
      "36/36 - 0s - loss: 1.0968 - accuracy: 0.3472 - lr: 0.0087 - 168ms/epoch - 5ms/step\n",
      "Epoch 26/70\n",
      "36/36 - 0s - loss: 1.0802 - accuracy: 0.3854 - lr: 0.0090 - 154ms/epoch - 4ms/step\n",
      "Epoch 27/70\n",
      "36/36 - 0s - loss: 1.0759 - accuracy: 0.4028 - lr: 0.0087 - 139ms/epoch - 4ms/step\n",
      "Epoch 28/70\n",
      "36/36 - 0s - loss: 1.0794 - accuracy: 0.3819 - lr: 0.0084 - 157ms/epoch - 4ms/step\n",
      "Epoch 29/70\n",
      "36/36 - 0s - loss: 1.1101 - accuracy: 0.3663 - lr: 0.0080 - 148ms/epoch - 4ms/step\n",
      "Epoch 30/70\n",
      "36/36 - 0s - loss: 1.0752 - accuracy: 0.3576 - lr: 0.0077 - 145ms/epoch - 4ms/step\n",
      "Epoch 31/70\n",
      "36/36 - 0s - loss: 1.1015 - accuracy: 0.3628 - lr: 0.0074 - 158ms/epoch - 4ms/step\n",
      "Epoch 32/70\n",
      "36/36 - 0s - loss: 1.0669 - accuracy: 0.4010 - lr: 0.0071 - 158ms/epoch - 4ms/step\n",
      "Epoch 33/70\n",
      "36/36 - 0s - loss: 1.0625 - accuracy: 0.3837 - lr: 0.0068 - 148ms/epoch - 4ms/step\n",
      "Epoch 34/70\n",
      "36/36 - 0s - loss: 1.0772 - accuracy: 0.3906 - lr: 0.0064 - 141ms/epoch - 4ms/step\n",
      "Epoch 35/70\n",
      "36/36 - 0s - loss: 1.0649 - accuracy: 0.3889 - lr: 0.0061 - 154ms/epoch - 4ms/step\n",
      "Epoch 36/70\n",
      "36/36 - 0s - loss: 1.0714 - accuracy: 0.3819 - lr: 0.0058 - 148ms/epoch - 4ms/step\n",
      "Epoch 37/70\n",
      "36/36 - 0s - loss: 1.0625 - accuracy: 0.3872 - lr: 0.0055 - 139ms/epoch - 4ms/step\n",
      "Epoch 38/70\n",
      "36/36 - 0s - loss: 1.0623 - accuracy: 0.4045 - lr: 0.0052 - 254ms/epoch - 7ms/step\n",
      "Epoch 39/70\n",
      "36/36 - 0s - loss: 1.0512 - accuracy: 0.4427 - lr: 0.0048 - 151ms/epoch - 4ms/step\n",
      "Epoch 40/70\n",
      "36/36 - 0s - loss: 1.0522 - accuracy: 0.4132 - lr: 0.0045 - 147ms/epoch - 4ms/step\n",
      "Epoch 41/70\n",
      "36/36 - 0s - loss: 1.0224 - accuracy: 0.4566 - lr: 0.0042 - 150ms/epoch - 4ms/step\n",
      "Epoch 42/70\n",
      "36/36 - 0s - loss: 1.0292 - accuracy: 0.4479 - lr: 0.0039 - 152ms/epoch - 4ms/step\n",
      "Epoch 43/70\n",
      "36/36 - 0s - loss: 1.0403 - accuracy: 0.4219 - lr: 0.0036 - 150ms/epoch - 4ms/step\n",
      "Epoch 44/70\n",
      "36/36 - 0s - loss: 1.0170 - accuracy: 0.4740 - lr: 0.0032 - 149ms/epoch - 4ms/step\n",
      "Epoch 45/70\n",
      "36/36 - 0s - loss: 1.0300 - accuracy: 0.4410 - lr: 0.0029 - 151ms/epoch - 4ms/step\n",
      "Epoch 46/70\n",
      "36/36 - 0s - loss: 1.0467 - accuracy: 0.4306 - lr: 0.0026 - 144ms/epoch - 4ms/step\n",
      "Epoch 47/70\n",
      "36/36 - 0s - loss: 1.0172 - accuracy: 0.4045 - lr: 0.0023 - 168ms/epoch - 5ms/step\n",
      "Epoch 48/70\n",
      "36/36 - 0s - loss: 1.0214 - accuracy: 0.4549 - lr: 0.0020 - 151ms/epoch - 4ms/step\n",
      "Epoch 49/70\n",
      "36/36 - 0s - loss: 1.0243 - accuracy: 0.4635 - lr: 0.0016 - 150ms/epoch - 4ms/step\n",
      "Epoch 50/70\n",
      "36/36 - 0s - loss: 1.0143 - accuracy: 0.4358 - lr: 0.0013 - 150ms/epoch - 4ms/step\n",
      "Epoch 51/70\n",
      "36/36 - 0s - loss: 1.0133 - accuracy: 0.4375 - lr: 0.0010 - 148ms/epoch - 4ms/step\n",
      "Epoch 52/70\n",
      "36/36 - 0s - loss: 1.0033 - accuracy: 0.4792 - lr: 0.0012 - 153ms/epoch - 4ms/step\n",
      "Epoch 53/70\n",
      "36/36 - 0s - loss: 1.0243 - accuracy: 0.4167 - lr: 0.0013 - 144ms/epoch - 4ms/step\n",
      "Epoch 54/70\n",
      "36/36 - 0s - loss: 1.0181 - accuracy: 0.4427 - lr: 0.0015 - 142ms/epoch - 4ms/step\n",
      "Epoch 55/70\n",
      "36/36 - 0s - loss: 1.0079 - accuracy: 0.4462 - lr: 0.0016 - 152ms/epoch - 4ms/step\n",
      "Epoch 56/70\n",
      "36/36 - 0s - loss: 0.9999 - accuracy: 0.4774 - lr: 0.0018 - 146ms/epoch - 4ms/step\n",
      "Epoch 57/70\n",
      "36/36 - 0s - loss: 1.0164 - accuracy: 0.4497 - lr: 0.0020 - 156ms/epoch - 4ms/step\n",
      "Epoch 58/70\n",
      "36/36 - 0s - loss: 1.0030 - accuracy: 0.4236 - lr: 0.0021 - 160ms/epoch - 4ms/step\n",
      "Epoch 59/70\n",
      "36/36 - 0s - loss: 1.0099 - accuracy: 0.4740 - lr: 0.0023 - 156ms/epoch - 4ms/step\n",
      "Epoch 60/70\n",
      "36/36 - 0s - loss: 0.9907 - accuracy: 0.4878 - lr: 0.0024 - 157ms/epoch - 4ms/step\n",
      "Epoch 61/70\n",
      "36/36 - 0s - loss: 1.0219 - accuracy: 0.4531 - lr: 0.0026 - 148ms/epoch - 4ms/step\n",
      "Epoch 62/70\n",
      "36/36 - 0s - loss: 0.9867 - accuracy: 0.4861 - lr: 0.0028 - 143ms/epoch - 4ms/step\n",
      "Epoch 63/70\n",
      "36/36 - 0s - loss: 1.0035 - accuracy: 0.4618 - lr: 0.0029 - 163ms/epoch - 5ms/step\n",
      "Epoch 64/70\n",
      "36/36 - 0s - loss: 1.0064 - accuracy: 0.4462 - lr: 0.0031 - 150ms/epoch - 4ms/step\n",
      "Epoch 65/70\n",
      "36/36 - 0s - loss: 1.0070 - accuracy: 0.4688 - lr: 0.0032 - 141ms/epoch - 4ms/step\n",
      "Epoch 66/70\n",
      "36/36 - 0s - loss: 1.0005 - accuracy: 0.4635 - lr: 0.0034 - 160ms/epoch - 4ms/step\n",
      "Epoch 67/70\n",
      "36/36 - 0s - loss: 1.0464 - accuracy: 0.4549 - lr: 0.0036 - 144ms/epoch - 4ms/step\n",
      "Epoch 68/70\n",
      "36/36 - 0s - loss: 0.9837 - accuracy: 0.4722 - lr: 0.0037 - 139ms/epoch - 4ms/step\n",
      "Epoch 69/70\n",
      "36/36 - 0s - loss: 1.0026 - accuracy: 0.4722 - lr: 0.0039 - 161ms/epoch - 4ms/step\n",
      "Epoch 70/70\n",
      "36/36 - 0s - loss: 1.0000 - accuracy: 0.4688 - lr: 0.0040 - 158ms/epoch - 4ms/step\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "history = conv1d.fit_model(x_train, y_train, epochs=args_conv.epochs, batch_size=args_conv.bs, class_weight=class_weight, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cff654a-1dbd-4148-8946-83b311ba8db7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "faa0c856-324b-4e49-aebe-6ce91e9f333e",
   "metadata": {},
   "source": [
    "* Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "656bf5a0-c722-4a58-b03b-9b745f4f0ff9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 6ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=============================================\n",
      "The overall accuracy is: 0.3034\n",
      "The precision score is: 0.3585\n",
      "The recall score is: 0.3034\n",
      "The F1 score is: 0.3211\n",
      "The AUC score is: 0.5038\n",
      "=============================================\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.15      0.50      0.23        20\n",
      "           1       0.35      0.33      0.34        48\n",
      "           2       0.58      0.23      0.33        77\n",
      "\n",
      "    accuracy                           0.30       145\n",
      "   macro avg       0.36      0.36      0.30       145\n",
      "weighted avg       0.44      0.30      0.32       145\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluate_model_performance(conv1d, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ca50a3f-9437-472b-aa31-f2aec5fcaf75",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40d42755-d708-49c3-9a73-802f899ed220",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f34a41bc-3458-49be-b41e-f65006482740",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3d908ff-13e6-4cca-988a-7c03231a5f36",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93c55d39-853c-4c83-b58c-62a1fce5669a",
   "metadata": {},
   "source": [
    "## Sub-networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a7bd663-8112-4d7e-a58f-08d50c8a1af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Args_multi:\n",
    "    # arugments\n",
    "    epochs=80\n",
    "    enc_epochs = 50\n",
    "    bs=32\n",
    "    enc_bs = 16\n",
    "    lr=0.0001\n",
    "    momentum=0.9\n",
    "    num_classes= 3\n",
    "    seed=710674\n",
    "\n",
    "args_multi = Args_multi()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52b0647e-a851-4618-9a38-31d17d8791a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_x_, data_y_ = data_x.copy(), data_y.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "315e8d60-457a-4031-a650-8589268462a4",
   "metadata": {},
   "source": [
    "* preprocessing the partial dataframes for subnetwork training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cffa61aa-aba6-4194-9305-81f001fd746b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class subnetwork_preprocess:\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "        self.data_dict = {}\n",
    "\n",
    "    def select_columns(self, prefixes):\n",
    "        self.data_dict = {prefix: self.data.loc[:, self.data.columns.str.startswith(f'{prefix}_')] \n",
    "                          for prefix in prefixes}\n",
    "        return self.data_dict\n",
    "\n",
    "    def create_inputs(self):\n",
    "        self.inputs = {name: Input(shape=(data.shape[1],)) for name, data in self.data_dict.items()}\n",
    "        return self.inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b08f473c-0761-4ad6-99b2-826df3bda8fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "## defining prefixies (criteria for variable selection)\n",
    "prefixes = ['b1', 's', 'b2', 'r', 'b3', 'c']\n",
    "\n",
    "## pass dataframe to generate class instance\n",
    "processor = subnetwork_preprocess(data_x_)\n",
    "\n",
    "## data columns selection based on the prefix\n",
    "data_dict = processor.select_columns(prefixes)\n",
    "\n",
    "## create input layers(for keras) with selected prefix inputs\n",
    "inputs = processor.create_inputs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8124feef-173c-4f67-9bb1-17adf42ee38e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 각 입력 레이어에 접근\n",
    "input_b1, input_s, input_b2, input_r, input_b3, input_c = inputs['b1'], inputs['s'], inputs['b2'], inputs['r'], inputs['b3'], inputs['c']\n",
    "\n",
    "## 각 변수별 데이터셋 추출\n",
    "data_b1, data_s, data_b2, data_r, data_b3, data_c = data_dict['b1'], data_dict['s'], data_dict['b2'], data_dict['r'], data_dict['b3'], data_dict['c']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0219b3b-8f85-4cd0-bca0-ce19fbc527c7",
   "metadata": {},
   "source": [
    "* Creating commonly using sub-network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ca303e5-5fd9-4051-b1f2-60968c6b5d00",
   "metadata": {},
   "outputs": [],
   "source": [
    "class subnetModel:\n",
    "    def __init__(self, input_layers):\n",
    "        self.input_layers = input_layers\n",
    "    \n",
    "    ## subnetwork(AE structure) for each variable group\n",
    "    def create_subnetworks(self, input_layer):\n",
    "        x = Dense(32, activation='relu')(input_layer)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Dense(16, activation='relu')(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        # x = Dropout(0.3)(x)\n",
    "        x = Dense(8, activation='relu')(x)\n",
    "        return x\n",
    "\n",
    "    def build_subnetworks(self):\n",
    "        return {name: self.create_subnetworks(layer) for name, layer in self.input_layers.items()}\n",
    "\n",
    "    ## combined network: subnetworks + fully-connected layers\n",
    "    def build_combined(self, subnetworks):\n",
    "        combined = Concatenate()(list(subnetworks.values()))\n",
    "        x = Dense(64, activation='relu')(combined)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Dropout(0.3)(x)\n",
    "        x = Dense(32, activation='relu')(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Dropout(0.3)(x)\n",
    "        x = Dense(16, activation='relu')(x)\n",
    "        x = Dense(8, activation='relu')(x)\n",
    "        return x\n",
    "\n",
    "    def build_final_output(self, combined_x, num_classes):\n",
    "        return Dense(num_classes, activation='softmax')(combined_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47dea061-fd48-4380-955f-27fdbcc4d5dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 사용 예시:\n",
    "input_layers = {\n",
    "    'b1': input_b1,\n",
    "    's': input_s,\n",
    "    'b2': input_b2,\n",
    "    'r': input_r,\n",
    "    'b3': input_b3,\n",
    "    'c': input_c\n",
    "}\n",
    "\n",
    "model_builder = subnetModel(input_layers)\n",
    "subnetworks = model_builder.build_subnetworks()\n",
    "combined_x = model_builder.build_combined(subnetworks)\n",
    "\n",
    "# 최종 출력 레이어 정의 (4-class 분류, args_multi.num_classes 사용)\n",
    "final_output = model_builder.build_final_output(combined_x, args_multi.num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a708f99d-3805-45eb-a0a1-1ce5ff361806",
   "metadata": {},
   "outputs": [],
   "source": [
    "subnetworks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcd93910-0132-43b6-9d91-1d62416580e7",
   "metadata": {},
   "source": [
    "* Train-test dataset split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8404b181-9eb5-47e5-9bef-6ed4f97b3f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## preparing training dataset and test dataset\n",
    "b1_train, b1_test, s_train, s_test, b2_train, b2_test, r_train, r_test, b3_train, b3_test, c_train, c_test, y_train, y_test = train_test_split(\n",
    "    data_b1, data_s, data_b2, data_r, data_b3, data_c, data_y_, test_size=0.2, random_state=710674)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cf4fabf-9aa0-49c5-bbbd-94ce6be46311",
   "metadata": {},
   "source": [
    "* Optimization function and learning rate scheduler settings, model compile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93018846-c282-4d97-96cc-dd965c0aa29b",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_scheduler = dynamic_learning_rate(args_multi.epochs, mode='cyclic')\n",
    "opt = keras.optimizers.SGD(learning_rate = args_multi.lr, decay = 1e-6, momentum = args_multi.momentum)\n",
    "\n",
    "model = Model(inputs=[input_b1, input_s, input_b2, input_r, input_b3, input_c], outputs=final_output)\n",
    "model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c091a37-6cca-4e05-8c6d-8f4c1ce35366",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.fit([b1_train, s_train, b2_train, r_train, b3_train, c_train], y_train, \n",
    "          epochs=args_multi.epochs, batch_size=args_multi.bs, \n",
    "          validation_split=0.2, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bee81e24-7aec-4f05-af84-4116dee53148",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "981cab1a-51e9-4094-a57e-4b056719afde",
   "metadata": {},
   "source": [
    "* Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a774cf0-562f-4ba3-a1eb-8c0d20d19cfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_model_performance(model, [b1_test, s_test, b2_test, r_test, b3_test, c_test], y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29dd1831-ae0c-4038-b217-788fb383295a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b132d0d4-f53c-4b36-a37a-8fdd8213fdae",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c860653a-0fb4-4e00-a68f-d9dbd78bdc8c",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bae9db2f-857c-4987-b499-181a10e7775a",
   "metadata": {},
   "source": [
    "## Using VAE/AE as a dimensionality reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4851c3fd-5bbb-4112-b86e-714312bb0e97",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = data_x\n",
    "y = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67f5ab25-a6c5-4f49-85df-8f53b1b7787f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Args:\n",
    "    # arugments\n",
    "    epochs=200\n",
    "    enc_epochs = 50\n",
    "    bs=32\n",
    "    enc_bs = 16\n",
    "    lr=0.001\n",
    "    momentum=0.9\n",
    "    encoding_dim = 16\n",
    "    num_classes= 2\n",
    "    verbose='store_true'\n",
    "    seed=710674\n",
    "\n",
    "args = Args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a5e194c-cc97-4dc6-b308-891b91b85917",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a3fb1ae9-612e-4890-92d3-1c031a05acb2",
   "metadata": {},
   "source": [
    "### Autoencoder for dim reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51fc9659-d907-4e33-a8bd-31967db5c7a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input dataset layer\n",
    "input_layer = Input(shape=(x.shape[1],))\n",
    "\n",
    "# encoder layers\n",
    "encoder = Dense(64, activation='relu')(input_layer)\n",
    "encoder = Dense(32, activation='relu')(encoder)\n",
    "encoder_out = Dense(args.encoding_dim, activation='relu')(encoder)\n",
    "\n",
    "# decoder layers\n",
    "decoder = Dense(32, activation='relu')(encoder_out)\n",
    "decoder = Dense(64, activation='relu')(decoder)\n",
    "decoder_out = Dense(x.shape[1], activation='sigmoid')(decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d60d75fa-94bf-4ab7-ae14-dfc0697e16e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AE model\n",
    "autoencoder = Model(inputs=input_layer, outputs=decoder_out)\n",
    "\n",
    "# Encoder model (convert input dataset into latent space)\n",
    "encoder_model = Model(inputs=input_layer, outputs=encoder_out)\n",
    "\n",
    "# Decoder model (recover latent space/vector into original dataset format)\n",
    "encoded_input = Input(shape=(args.encoding_dim,))\n",
    "decoder_layer = autoencoder.layers[-3](encoded_input)\n",
    "decoder_layer = autoencoder.layers[-2](decoder_layer)\n",
    "decoder_out = autoencoder.layers[-1](decoder_layer)\n",
    "decoder_model = Model(inputs=encoded_input, outputs=decoder_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "930e4df0-f1fe-49d7-88ec-5d4743aa6e2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model compile\n",
    "autoencoder.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# Checking each model\n",
    "autoencoder.summary()\n",
    "# encoder_model.summary()\n",
    "# decoder_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1b6f004-27f3-4a19-ba75-d8735ae82c4c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Model training\n",
    "autoencoder.fit(x, x, epochs = args.enc_epochs, batch_size = args.enc_bs, shuffle=True, validation_split=0.2, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2d73949-5fdf-457e-b1f5-4d174ad54b6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_data = encoder_model.predict(x)\n",
    "decoded_data = decoder_model.predict(encoded_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76de485d-9b8c-4dbd-b4e3-4cecf71b62b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12df8ac2-ebe6-47a1-8759-afbe05c3d62a",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoded_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16f95697-d1d9-4861-a1ce-5b0d46132998",
   "metadata": {},
   "outputs": [],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f63bc96-65f7-431d-a581-d9f8e51e9086",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoded_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cb603d7-37a9-4af7-8ae9-9e3cc4613ea4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b31eb85-686a-4948-a775-160528f4794d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Args:\n",
    "    # arugments\n",
    "    epochs=200\n",
    "    bs=32\n",
    "    lr=0.001\n",
    "    momentum=0.9\n",
    "    num_classes= 2\n",
    "    verbose='store_true'\n",
    "    seed=710674\n",
    "\n",
    "args = Args()\n",
    "\n",
    "# np.random.seed(args.seed)\n",
    "# random.seed(args.seed)\n",
    "# torch.manual_seed(args.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f2bbad8-7456-4f91-a531-c7c38e9a4801",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_trainset, x_test, y_trainset, y_test = train_test_split(decoded_data, y, test_size = 0.1, random_state = 710674)\n",
    "x_train, x_vali, y_train, y_vali = train_test_split(x_trainset, y_trainset, test_size = 0.2, random_state = 710674)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eda29a3-3701-47b3-888c-adab1c263fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = np.concatenate((x_train, x_vali), axis = 0)\n",
    "targets = np.concatenate((y_train, y_vali), axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "033e9ade-fab5-48c0-861e-82dd1621e0b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "fold_num = 1\n",
    "split_num = 5\n",
    "opt = keras.optimizers.SGD(learning_rate = args.lr, decay = 1e-6, momentum = args.momentum)\n",
    "kfold = KFold(n_splits = split_num, shuffle = True)\n",
    "# kfold = StratifiedKFold(n_splits = split_num, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee4d5391-c090-41d2-bf12-62d4c5b9808f",
   "metadata": {},
   "outputs": [],
   "source": [
    "############## FOR FOUR-GROUP CLASSIFICATION ###############\n",
    "class_weight = {0:1, 1: 1.68}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5713989-8eab-4d96-afb3-f7ad9197c1e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_per_fold = []\n",
    "loss_per_fold = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dafbb424-a9f9-4318-9ab1-3a85bc98e716",
   "metadata": {},
   "outputs": [],
   "source": [
    "for train, test in kfold.split(inputs, targets):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(128, input_dim = x_train.shape[1], activation = 'relu'))\n",
    "    model.add(Dense(64, activation = 'relu'))\n",
    "    model.add(Dropout(0.5)) #drop out\n",
    "    model.add(Dense(32, activation = 'relu'))\n",
    "    model.add(Dense(args.num_classes, activation = 'softmax'))\n",
    "    \n",
    "    ## model compile\n",
    "    model.compile(loss = 'categorical_crossentropy', optimizer = opt, metrics = ['accuracy'])\n",
    "    \n",
    "    print('----------------------------------------')\n",
    "    print(f'Training or fold {fold_num} ... ')\n",
    "    \n",
    "    ## fit data to model\n",
    "    history = model.fit(inputs[train], targets[train], batch_size = args.bs, epochs = args.epochs, verbose = 0, class_weight = class_weight)\n",
    "    \n",
    "    ## generate generalization metrics\n",
    "    scores = model.evaluate(inputs[test], targets[test])\n",
    "    print(f'Score for fold {fold_num}: {model.metrics_names[0]} of {scores[0]}; {model.metrics_names[1]} of {scores[1]*100}%')\n",
    "    print(\"%s: %.2f%%\" %(model.metrics_names[1], scores[1]*100))\n",
    "    acc_per_fold.append(scores[1] * 100)\n",
    "    loss_per_fold.append(scores[0])\n",
    "    \n",
    "    ## increasing fold number\n",
    "    fold_num = fold_num + 1\n",
    "    \n",
    "    \n",
    "    \n",
    "## Summarizing the results\n",
    "print('------------------------------------------------------------------------')\n",
    "print('Score per fold')\n",
    "for i in range(0, len(acc_per_fold)):\n",
    "    print('------------------------------------------------------------------------')\n",
    "    print(f'>> Fold {i+1} - Loss: {loss_per_fold[i]} - Accuracy: {acc_per_fold[i]}%')\n",
    "print('------------------------------------------------------------------------')\n",
    "print('Average scores for all folds:')\n",
    "print(f'>>> Accuracy: {np.mean(acc_per_fold)} (+- {np.std(acc_per_fold)})')\n",
    "print(f'>>> Loss: {np.mean(loss_per_fold)}')\n",
    "print('------------------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dab7d67c-2c9d-4320-84b8-9f451d9b4063",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict = model.predict(x_test)\n",
    "y_predict = np.argmax(y_predict, axis = 1)\n",
    "y_test = np.argmax(y_test, axis = 1)\n",
    "\n",
    "result = confusion_matrix(y_test, y_predict, normalize = 'pred')\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66ca930a-2f73-4fc8-a7c8-d908c8b8b3e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "figure = plt.figure(figsize=(6, 4))\n",
    "sns.heatmap(result, annot=True,cmap=plt.cm.Blues)\n",
    "plt.tight_layout()\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9962116a-e761-4059-adbf-e613c02a6053",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = metrics.accuracy_score(y_test, y_predict)\n",
    "precision = metrics.precision_score(y_test, y_predict, average = 'macro')\n",
    "recall = metrics.recall_score(y_test, y_predict, average = 'micro')\n",
    "f1 = metrics.f1_score(y_test, y_predict, average = 'weighted')\n",
    "auc = roc_auc_score(y_test, model.predict(x_test, verbose=0), multi_class='ovr')\n",
    "\n",
    "print(\"=============================================\")\n",
    "print(\"The overall accuracy is:\", round(accuracy, 4))\n",
    "print(\"The precision score is:\", round(precision, 4))\n",
    "print(\"The recall score is:\", round(recall, 4))\n",
    "print(\"The f1 score is:\", round(f1, 4))\n",
    "print(\"The AUC score is:\", round(auc, 4))\n",
    "print(\"=============================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f57e63ff-ce5a-4d03-94ad-e6c7fb4ded06",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29aeef4b-07fc-409b-a6e0-d37ee522f463",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47edc141-29ab-4439-9a08-f1fb51cf4a8d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "602e460b-655c-42a7-a42d-11f6e9d0425b",
   "metadata": {},
   "source": [
    "## EV input & MV output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac7db1f0-6786-4f26-a693-02fa2067e79c",
   "metadata": {},
   "source": [
    "> What if we use external variables(ex. demographics) as input variables and set the DNN model to find Medical Variables as an output variables?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2881bf1a-9503-4099-84cc-07f498c298b9",
   "metadata": {},
   "source": [
    "### data setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbf12b17-199f-4269-bf53-9a513cfa7f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_evinput = data_ori.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77471e0f-d6c4-4da3-931f-38c50212af5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_evinput['disorder'] = data_evinput['disorder'].replace({\"mdd\": 0})\n",
    "data_evinput['disorder'] = data_evinput['disorder'].replace({\"pd\": 1})\n",
    "data_evinput['disorder'] = data_evinput['disorder'].replace({\"con\": 2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df0605cd-07ce-481a-9e46-3a3e05c04210",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_evinput.head()\n",
    "# data_evinput.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eca3bbce-f059-4138-9696-f474598a3ddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "scale_list = ['HAMD', 'HAMA', 'PDSS', 'ASI', 'APPQ', 'PSWQ', 'SPI', 'PSS', 'BIS', 'SSI']\n",
    "etc_list = ['sub', 'VISIT', 'disorder_mdd']\n",
    "demo_list = ['age', 'gender', 'disorder']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66c88bcb-8b08-471e-bbba-0c657b2d3b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ev_input = data_evinput.loc[:, ('disorder', 'age', 'gender')]\n",
    "ev_output = data_evinput.drop((scale_list + etc_list + demo_list), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e1f8eba-34d6-4295-84d6-1aebffd7db4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler() #set the scaler (between 0 and 1)\n",
    "\n",
    "ev_input[:] = (scaler.fit_transform(ev_input[:])).round(decimals=6)\n",
    "ev_output[:] = (scaler.fit_transform(ev_output[:])).round(decimals=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03e1b374-cb9d-45c0-8c38-7ca63d19cb96",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1262e1a5-4d6c-4164-a776-8424effcfbad",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20630384-6f8a-4c46-a35b-fc4be1a592d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = ev_input.shape[1]\n",
    "output_dim = ev_output.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0462676-74d5-4870-ac0b-45fe11aca1a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 구조 정의\n",
    "ev_model = Sequential([\n",
    "    Dense(16, input_dim=input_dim, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(32, activation='relu'), \n",
    "    Dropout(0.5),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(output_dim)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eb3b00b-9c03-434e-bfd7-b91755d06939",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 컴파일\n",
    "ev_model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "# 모델 요약 출력\n",
    "ev_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df3e2ee0-dce6-4392-9924-7ebd16348525",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 학습 예시 (X_train은 인구학적 변수, Y_train은 생체신호 변수)\n",
    "ev_model.fit(ev_input, ev_output, epochs=100, batch_size=32, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af0bd49b-ce63-457c-928e-75d78badf076",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cd2601d3-7482-4454-870a-55bc404cd1fc",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4ad863e-95a0-4be2-8595-e5c86ab9654b",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "466281fa-f244-4cb0-9639-c7c0a27fa4ff",
   "metadata": {},
   "source": [
    "# Class generic/specific feature"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a73be785-5af4-4a10-8fd4-df5cf027f7c1",
   "metadata": {},
   "source": [
    "> Concept: generate seperate class(var) generic feature and class specific feature extraction models. \\\n",
    "> Maybe implement individual autoencoder model and train the subset datasets. \\\n",
    "> Then concatenate the extracted features, and adopt the feature vector for classifier's input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ff7fabe-ea26-4124-a31e-db338881556b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data_ori.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65ed5402-ad24-49db-adef-53c06b0a48c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "270acd80-6de5-4a42-aeb3-550ab63b3f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "non_hrv = ['sub', 'VISIT', 'age', 'gender', 'HAMD', 'HAMA', 'PDSS', 'ASI', 'APPQ', 'PSWQ', 'SPI', 'PSS', 'BIS', 'SSI', 'disorder_mdd']\n",
    "target = ['disorder']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8be2ee7f-5f8c-457b-a048-117a9a050750",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "332b3962-6b53-4b3f-a755-b11e571f106e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c70f51f7-7012-4b88-af6c-8d4d8d2e94ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cf7daf7-d601-41ac-8c3b-9dc0d780b7f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8afbce32-6c1d-42d1-865e-9997fac5b058",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "905cb706-86e5-4af9-a5a5-031c83bad917",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "786723db-9c5a-4bc3-971e-43ef7ecc4833",
   "metadata": {},
   "source": [
    "## Class-generic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e7fab1a-f0a5-48f4-8b4c-d45693e1a492",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_generic = data.drop(non_hrv, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c5de72a-499c-450b-af9f-ecebfc8c130e",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data_generic.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb6355b8-977a-4b4d-995a-94ca48d15a29",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.gender.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "823072b8-871a-405d-85cf-8ccaf3d31160",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8acb063c-fe44-456f-8eea-8c61b42a7b96",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e40edd2-482a-4e23-b184-0e7db8cfc787",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87b688f2-cb01-4b00-8999-04c4cbeb6a06",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7ecbf690-f09b-4125-b27f-76b1fa408da8",
   "metadata": {},
   "source": [
    "## Class-specific"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e68e3722-c5d9-4d6c-b44a-51b7ced0e522",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_spe_M = data_ori[data_ori['gender']==1]\n",
    "data_spe_F = data_ori[data_ori['gender']==2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0727b8f5-2248-4504-977d-113660e10bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_specific = data_spe_M.drop(non_hrv, axis=1)\n",
    "# data_specific = data_spe_F.drop(non_hrv, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d0b4a87-54ac-47fe-80f7-36abb9ddb8a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = data_specific.drop('disorder', axis=1)\n",
    "y = data_specific.disorder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9cd4b55-2c6c-4805-8ba0-6c82f654fac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_x = x.copy()\n",
    "data_x[:] = (scaler.fit_transform(data_x[:])).round(decimals=6) ## scaling x values\n",
    "\n",
    "label = y.copy()\n",
    "label = label.replace({'mdd': 0})\n",
    "label = label.replace({'pd': 1})\n",
    "label = label.replace({'con' : 2})\n",
    "data_y = to_categorical(label, 3) ## into the format of one-hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e649c705-c75d-4dba-8ec0-af97b247ddca",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The size of x dataset is:\", data_x.shape)\n",
    "print(\"The size of y dataset is:\", data_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "492606f3-e9dd-4bbd-9d7b-200553ec8e37",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eef602e1-7783-4457-8189-c4d5e3387a46",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5be793bd-87ff-45e5-8236-2e5cb5d78571",
   "metadata": {},
   "outputs": [],
   "source": [
    "class specific_AE:\n",
    "    def __init__(self, input_dim, encoding_dim, hidden_layers=None, batch_norm=False, dropout_rate=0.0):\n",
    "        self.input_dim = input_dim\n",
    "        self.encoding_dim = encoding_dim\n",
    "        self.hidden_layers = hidden_layers if hidden_layers is not None else []\n",
    "        self.batch_norm = batch_norm\n",
    "        self.dropout_rate = dropout_rate\n",
    "\n",
    "        self.encoder = None\n",
    "        self.decoder = None\n",
    "        self.autoencoder = None\n",
    "\n",
    "        self._build()\n",
    "\n",
    "    def _build(self):\n",
    "        ## building encoder part\n",
    "        input_layer = layers.Input(shape=(self.input_dim,))\n",
    "        x = input_layer\n",
    "\n",
    "        for units in self.hidden_layers:\n",
    "            x = layers.Dense(units, activation='relu')(x)\n",
    "            if self.batch_norm:\n",
    "                x = layers.BatchNormalization()(x)\n",
    "            if self.dropout_rate > 0.0:\n",
    "                x = layers.Dropout(self.dropout_rate)(x)\n",
    "\n",
    "        encoded = layers.Dense(self.encoding_dim, activation='relu')(x)\n",
    "\n",
    "        ## building decodeer part\n",
    "        x = encoded\n",
    "        for units in reversed(self.hidden_layers):\n",
    "            x = layers.Dense(units, activation='relu')(x)\n",
    "            if self.batch_norm:\n",
    "                x = layers.BatchNormalization()(x)\n",
    "            if self.dropout_rate > 0.0:\n",
    "                x = layers.Dropout(self.dropout_rate)(x)\n",
    "\n",
    "        decoded = layers.Dense(self.input_dim, activation='softmax')(x)\n",
    "\n",
    "        # 인코더, 디코더, 오토인코더 모델\n",
    "        self.encoder = models.Model(input_layer, encoded, name='encoder')\n",
    "        self.decoder = models.Model(encoded, decoded, name='decoder')\n",
    "        self.autoencoder = models.Model(input_layer, self.decoder(self.encoder(input_layer)), name='autoencoder')\n",
    "\n",
    "        self.autoencoder.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "    def summary(self):\n",
    "        self.autoencoder.summary()\n",
    "\n",
    "    def train(self, X_train, X_val=None, epochs=50, batch_size=256):\n",
    "        return self.autoencoder.fit(X_train, X_train, \n",
    "                                    validation_data=(X_val, X_val) if X_val is not None else None,\n",
    "                                    epochs=epochs, batch_size=batch_size)\n",
    "\n",
    "    def encode(self, X):\n",
    "        return self.encoder.predict(X)\n",
    "\n",
    "    def decode(self, encoded_data):\n",
    "        return self.decoder.predict(encoded_data)\n",
    "\n",
    "    def reconstruct(self, X):\n",
    "        return self.autoencoder.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daf402a0-aa64-4764-88f6-5644727d0b37",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45065102-09a4-41e4-b764-a427df6b48da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 사용 예시\n",
    "input_dim = data_x.shape[1]\n",
    "encoding_dim = 8\n",
    "hidden_layers = [64, 32, 16]\n",
    "\n",
    "autoencoder = specific_AE(input_dim, encoding_dim, hidden_layers, batch_norm=True, dropout_rate=0.2)\n",
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f49415e-66f9-4e52-a42c-5758150fde16",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "autoencoder.train(data_x, data_x, epochs=100, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fc2469d-55b2-4413-903f-7f9aa71466a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc15aac4-d6e6-4a28-968e-4527e92b45ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1033019-48d2-4259-ade2-566e6d9a6e41",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7444b8d4-ae07-403a-b85b-cf694d8be151",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d26a630f-a949-46c8-841b-fcf46ca83e17",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "efe88d9d-795f-4918-b98e-e8d3bbf3e535",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2611ccce-6c6a-4265-a2ea-a1a4679ef50b",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3375ade6-f619-495f-971d-f0beded5e021",
   "metadata": {},
   "source": [
    "# Code practice"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e414001-bd0c-46a2-a13c-d0caea4d67c8",
   "metadata": {},
   "source": [
    "* Practicing multi-head attention mask for significant feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "dc6516bd-0e74-4c32-a191-00939906d8bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, Model, Input\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import SparseCategoricalCrossentropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "9f17b675-3f08-4644-988a-633a750147f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_prac = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "bef15d10-656b-4886-b695-2f26fa2e5d67",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "main_dx\n",
       "MDDs    325\n",
       "MDDr    277\n",
       "PDD     119\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_prac.main_dx.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "9a856205-1054-4862-866d-466e3de890e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(721, 35)"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_prac.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "011d7eb7-1fa0-485c-9cf3-fe8a8be5a139",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_prac['psi'] = pd.to_numeric(data_prac['psi'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "34994a9d-ea01-4620-8ac0-430529d082af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>auto_activity</th>\n",
       "      <th>auto_balance</th>\n",
       "      <th>stress_resist</th>\n",
       "      <th>stress_index</th>\n",
       "      <th>tired</th>\n",
       "      <th>avg_hr</th>\n",
       "      <th>heart_stable</th>\n",
       "      <th>...</th>\n",
       "      <th>vlf_ln</th>\n",
       "      <th>lf_ln</th>\n",
       "      <th>hf_ln</th>\n",
       "      <th>main_dx</th>\n",
       "      <th>HAMD</th>\n",
       "      <th>HAMA</th>\n",
       "      <th>BDI-II</th>\n",
       "      <th>BAI</th>\n",
       "      <th>MDQ</th>\n",
       "      <th>HCL-32</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>A0006</td>\n",
       "      <td>F</td>\n",
       "      <td>47</td>\n",
       "      <td>81.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>124.0</td>\n",
       "      <td>109.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.808</td>\n",
       "      <td>4.557</td>\n",
       "      <td>3.677</td>\n",
       "      <td>PDD</td>\n",
       "      <td>14.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>10</td>\n",
       "      <td>4.0</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>A0053</td>\n",
       "      <td>M</td>\n",
       "      <td>22</td>\n",
       "      <td>50.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.073</td>\n",
       "      <td>3.720</td>\n",
       "      <td>3.944</td>\n",
       "      <td>MDDr</td>\n",
       "      <td>20.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>13</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>A0055</td>\n",
       "      <td>M</td>\n",
       "      <td>19</td>\n",
       "      <td>75.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>117.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.822</td>\n",
       "      <td>5.550</td>\n",
       "      <td>4.049</td>\n",
       "      <td>MDDs</td>\n",
       "      <td>18.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>11</td>\n",
       "      <td>8.0</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>A0057</td>\n",
       "      <td>M</td>\n",
       "      <td>24</td>\n",
       "      <td>82.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>115.0</td>\n",
       "      <td>119.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.583</td>\n",
       "      <td>5.406</td>\n",
       "      <td>5.271</td>\n",
       "      <td>MDDs</td>\n",
       "      <td>20.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>15</td>\n",
       "      <td>9.0</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>A0065</td>\n",
       "      <td>F</td>\n",
       "      <td>59</td>\n",
       "      <td>50.0</td>\n",
       "      <td>105.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.252</td>\n",
       "      <td>2.377</td>\n",
       "      <td>3.695</td>\n",
       "      <td>MDDr</td>\n",
       "      <td>23.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>14</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   subject gender  age  auto_activity  auto_balance  stress_resist  \\\n",
       "5    A0006      F   47           81.0          53.0           73.0   \n",
       "52   A0053      M   22           50.0          79.0           65.0   \n",
       "54   A0055      M   19           75.0          56.0           93.0   \n",
       "56   A0057      M   24           82.0          54.0           85.0   \n",
       "64   A0065      F   59           50.0         105.0           68.0   \n",
       "\n",
       "    stress_index  tired  avg_hr  heart_stable  ...  vlf_ln  lf_ln  hf_ln  \\\n",
       "5          124.0  109.0    86.0          82.0  ...   4.808  4.557  3.677   \n",
       "52         150.0  150.0    97.0          71.0  ...   4.073  3.720  3.944   \n",
       "54          99.0  117.0    78.0          72.0  ...   4.822  5.550  4.049   \n",
       "56         115.0  119.0    89.0          91.0  ...   5.583  5.406  5.271   \n",
       "64         118.0  150.0    71.0          83.0  ...   4.252  2.377  3.695   \n",
       "\n",
       "    main_dx  HAMD  HAMA  BDI-II  BAI  MDQ  HCL-32  \n",
       "5       PDD  14.0  16.0    21.0   10  4.0    12.0  \n",
       "52     MDDr  20.0  19.0    36.0   13  8.0     8.0  \n",
       "54     MDDs  18.0  13.0    41.0   11  8.0    16.0  \n",
       "56     MDDs  20.0  18.0    39.0   15  9.0    15.0  \n",
       "64     MDDr  23.0  25.0    27.0   14  1.0     2.0  \n",
       "\n",
       "[5 rows x 35 columns]"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_prac.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "008e7409-77b3-4648-939f-f11ff05dd1e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "info_list = ['subject' ,'gender', 'age']\n",
    "scale_list = ['HAMD', 'HAMA', 'BDI-II', 'BAI', 'MDQ', 'HCL-32']\n",
    "target_list = ['main_dx']\n",
    "hr_list = ['auto_activity', 'auto_balance', 'stress_resist', 'stress_index', 'tired', 'avg_hr', 'heart_stable', 'abnormal_hr']\n",
    "\n",
    "# drop_list = info_list + scale_list + target_list\n",
    "drop_list = info_list + scale_list + target_list + hr_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "07c264fb-534d-4451-a734-6a0b62292bce",
   "metadata": {},
   "outputs": [],
   "source": [
    "signals = data_prac.drop(drop_list, axis=1)\n",
    "signals[:] = (scaler.fit_transform(signals[:]).round(decimals=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "40d5a1b4-5eb6-4f11-9442-b825cf2c5478",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "main_dx\n",
       "MDDs    325\n",
       "MDDr    277\n",
       "PDD     119\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_prac.main_dx.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "32be3fa0-5f1f-4edc-ac2f-b4aeb9ade027",
   "metadata": {},
   "outputs": [],
   "source": [
    "genders = data_prac['gender'].map({'M': 0, 'F': 1}).values.reshape(-1, 1)\n",
    "labels = data_prac['main_dx'].map({'MDDs': 0, 'MDDr': 1, 'PDD': 2}).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07fad8d4-fbb9-40e7-af70-21d7e3a57f14",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "efe6d04d-4833-4f42-8913-3f8ab6beb17c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attention 레이어 정의\n",
    "class GenderAttention(layers.Layer):\n",
    "    def __init__(self, attention_dim):\n",
    "        super(GenderAttention, self).__init__()\n",
    "        self.query_dense = layers.Dense(attention_dim)\n",
    "        self.key_dense = layers.Dense(attention_dim)\n",
    "        self.value_dense = layers.Dense(attention_dim)\n",
    "    \n",
    "    def call(self, x, gender):\n",
    "        # 성별과 생체신호 결합\n",
    "        x_concat = layers.Concatenate()([x, gender])\n",
    "\n",
    "        # Query, Key, Value 계산\n",
    "        Q = self.query_dense(x_concat)\n",
    "        K = self.key_dense(x_concat)\n",
    "        V = self.value_dense(x_concat)\n",
    "\n",
    "        # Attention score 계산 (Q * K^T / sqrt(d_k))\n",
    "        attention_scores = tf.matmul(Q, K, transpose_b=True) / tf.sqrt(tf.cast(tf.shape(Q)[-1], tf.float32))\n",
    "\n",
    "        # Attention weight에 softmax 적용\n",
    "        attention_weights = tf.nn.softmax(attention_scores, axis=-1)\n",
    "\n",
    "        # 가중합 (Attention output)\n",
    "        attention_output = tf.matmul(attention_weights, V)\n",
    "\n",
    "        return attention_output, attention_weights\n",
    "\n",
    "# 분류 모델 정의\n",
    "def create_model(input_dim, attention_dim, hidden_dim, output_dim):\n",
    "    # 입력 정의\n",
    "    signal_input = Input(shape=(input_dim,), name='signal_input')  # 생체신호 입력\n",
    "    gender_input = Input(shape=(1,), name='gender_input')  # 성별 입력\n",
    "\n",
    "    # GenderAttention 레이어 적용\n",
    "    attention_output, attention_weights = GenderAttention(attention_dim)(signal_input, gender_input)\n",
    "\n",
    "    # Hidden Layer\n",
    "    x = layers.Dense(hidden_dim, activation='relu')(attention_output)\n",
    "    \n",
    "    # 출력 Layer (질병군 분류)\n",
    "    output = layers.Dense(output_dim, activation='softmax')(x)\n",
    "\n",
    "    # 모델 정의 (Functional API 사용)\n",
    "    model = Model(inputs=[signal_input, gender_input], outputs=[output, attention_output])\n",
    "\n",
    "    # 모델 컴파일\n",
    "    model.compile(optimizer=Adam(),\n",
    "                  loss=SparseCategoricalCrossentropy(),\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "dd88e2f6-f0bf-46b6-a531-0bf0f524a0d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 생성\n",
    "input_dim = len(signals.columns)  # 생체신호 변수의 개수\n",
    "attention_dim = 8  # Attention dimension\n",
    "hidden_dim = 32  # Hidden layer의 뉴런 개수\n",
    "output_dim = 3  # 질병군 클래스 개수 (A, B, C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "c9f4ba3e-46c6-4bbb-b6fe-2884cefb189e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_model(input_dim, attention_dim, hidden_dim, output_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "971a7ef8-c0cd-4da4-a07a-1c4aa72f76ca",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "91/91 [==============================] - 1s 5ms/step - loss: 13.6777 - dense_52_loss: 9.1535 - gender_attention_5_loss: 4.5242 - dense_52_accuracy: 0.3745 - gender_attention_5_accuracy: 0.3454\n",
      "Epoch 2/150\n",
      "91/91 [==============================] - 0s 5ms/step - loss: 8.7625 - dense_52_loss: 4.5381 - gender_attention_5_loss: 4.2244 - dense_52_accuracy: 0.3800 - gender_attention_5_accuracy: 0.3301\n",
      "Epoch 3/150\n",
      "91/91 [==============================] - 1s 6ms/step - loss: 8.4941 - dense_52_loss: 4.2573 - gender_attention_5_loss: 4.2368 - dense_52_accuracy: 0.3870 - gender_attention_5_accuracy: 0.3301\n",
      "Epoch 4/150\n",
      "91/91 [==============================] - 0s 5ms/step - loss: 7.9450 - dense_52_loss: 3.4843 - gender_attention_5_loss: 4.4608 - dense_52_accuracy: 0.3911 - gender_attention_5_accuracy: 0.3592\n",
      "Epoch 5/150\n",
      "91/91 [==============================] - 0s 5ms/step - loss: 7.0943 - dense_52_loss: 2.9265 - gender_attention_5_loss: 4.1678 - dense_52_accuracy: 0.3551 - gender_attention_5_accuracy: 0.3551\n",
      "Epoch 6/150\n",
      "91/91 [==============================] - 0s 5ms/step - loss: 6.6633 - dense_52_loss: 2.4630 - gender_attention_5_loss: 4.2003 - dense_52_accuracy: 0.3856 - gender_attention_5_accuracy: 0.3426\n",
      "Epoch 7/150\n",
      "91/91 [==============================] - 0s 5ms/step - loss: 7.6659 - dense_52_loss: 3.2756 - gender_attention_5_loss: 4.3903 - dense_52_accuracy: 0.3897 - gender_attention_5_accuracy: 0.3273\n",
      "Epoch 8/150\n",
      "91/91 [==============================] - 0s 5ms/step - loss: 6.8445 - dense_52_loss: 2.6314 - gender_attention_5_loss: 4.2131 - dense_52_accuracy: 0.3856 - gender_attention_5_accuracy: 0.3731\n",
      "Epoch 9/150\n",
      "91/91 [==============================] - 0s 5ms/step - loss: 6.8663 - dense_52_loss: 2.5216 - gender_attention_5_loss: 4.3447 - dense_52_accuracy: 0.3883 - gender_attention_5_accuracy: 0.3245\n",
      "Epoch 10/150\n",
      "91/91 [==============================] - 1s 6ms/step - loss: 7.3056 - dense_52_loss: 2.8535 - gender_attention_5_loss: 4.4520 - dense_52_accuracy: 0.3759 - gender_attention_5_accuracy: 0.3398\n",
      "Epoch 11/150\n",
      "91/91 [==============================] - 0s 5ms/step - loss: 6.3991 - dense_52_loss: 2.1345 - gender_attention_5_loss: 4.2647 - dense_52_accuracy: 0.3856 - gender_attention_5_accuracy: 0.3759\n",
      "Epoch 12/150\n",
      "91/91 [==============================] - 0s 5ms/step - loss: 6.9509 - dense_52_loss: 2.3764 - gender_attention_5_loss: 4.5745 - dense_52_accuracy: 0.3717 - gender_attention_5_accuracy: 0.3370\n",
      "Epoch 13/150\n",
      "91/91 [==============================] - 0s 5ms/step - loss: 6.3777 - dense_52_loss: 2.2385 - gender_attention_5_loss: 4.1391 - dense_52_accuracy: 0.4078 - gender_attention_5_accuracy: 0.3606\n",
      "Epoch 14/150\n",
      "91/91 [==============================] - 0s 5ms/step - loss: 7.2817 - dense_52_loss: 2.9545 - gender_attention_5_loss: 4.3272 - dense_52_accuracy: 0.3759 - gender_attention_5_accuracy: 0.3093\n",
      "Epoch 15/150\n",
      "91/91 [==============================] - 0s 5ms/step - loss: 6.8054 - dense_52_loss: 2.3949 - gender_attention_5_loss: 4.4105 - dense_52_accuracy: 0.3606 - gender_attention_5_accuracy: 0.3343\n",
      "Epoch 16/150\n",
      "91/91 [==============================] - 0s 5ms/step - loss: 6.9477 - dense_52_loss: 2.6554 - gender_attention_5_loss: 4.2924 - dense_52_accuracy: 0.3634 - gender_attention_5_accuracy: 0.3564\n",
      "Epoch 17/150\n",
      "91/91 [==============================] - 1s 6ms/step - loss: 7.8873 - dense_52_loss: 3.6969 - gender_attention_5_loss: 4.1904 - dense_52_accuracy: 0.3606 - gender_attention_5_accuracy: 0.3620\n",
      "Epoch 18/150\n",
      "91/91 [==============================] - 0s 5ms/step - loss: 6.3813 - dense_52_loss: 2.1439 - gender_attention_5_loss: 4.2373 - dense_52_accuracy: 0.3883 - gender_attention_5_accuracy: 0.3467\n",
      "Epoch 19/150\n",
      "91/91 [==============================] - 0s 5ms/step - loss: 6.6702 - dense_52_loss: 2.3707 - gender_attention_5_loss: 4.2995 - dense_52_accuracy: 0.3398 - gender_attention_5_accuracy: 0.3551\n",
      "Epoch 20/150\n",
      "91/91 [==============================] - 0s 5ms/step - loss: 6.7514 - dense_52_loss: 2.6505 - gender_attention_5_loss: 4.1009 - dense_52_accuracy: 0.4119 - gender_attention_5_accuracy: 0.3662\n",
      "Epoch 21/150\n",
      "91/91 [==============================] - 0s 5ms/step - loss: 6.2502 - dense_52_loss: 2.2551 - gender_attention_5_loss: 3.9951 - dense_52_accuracy: 0.3648 - gender_attention_5_accuracy: 0.3773\n",
      "Epoch 22/150\n",
      "91/91 [==============================] - 0s 5ms/step - loss: 6.2063 - dense_52_loss: 2.1094 - gender_attention_5_loss: 4.0970 - dense_52_accuracy: 0.3939 - gender_attention_5_accuracy: 0.3842\n",
      "Epoch 23/150\n",
      "91/91 [==============================] - 0s 5ms/step - loss: 6.4875 - dense_52_loss: 2.2869 - gender_attention_5_loss: 4.2006 - dense_52_accuracy: 0.3592 - gender_attention_5_accuracy: 0.3759\n",
      "Epoch 24/150\n",
      "91/91 [==============================] - 0s 5ms/step - loss: 6.5432 - dense_52_loss: 2.3996 - gender_attention_5_loss: 4.1436 - dense_52_accuracy: 0.3967 - gender_attention_5_accuracy: 0.3731\n",
      "Epoch 25/150\n",
      "91/91 [==============================] - 0s 5ms/step - loss: 6.2294 - dense_52_loss: 2.2267 - gender_attention_5_loss: 4.0027 - dense_52_accuracy: 0.3911 - gender_attention_5_accuracy: 0.3592\n",
      "Epoch 26/150\n",
      "91/91 [==============================] - 0s 5ms/step - loss: 6.1500 - dense_52_loss: 2.3539 - gender_attention_5_loss: 3.7962 - dense_52_accuracy: 0.3634 - gender_attention_5_accuracy: 0.3592\n",
      "Epoch 27/150\n",
      "91/91 [==============================] - 0s 5ms/step - loss: 5.3079 - dense_52_loss: 1.5641 - gender_attention_5_loss: 3.7438 - dense_52_accuracy: 0.4133 - gender_attention_5_accuracy: 0.3717\n",
      "Epoch 28/150\n",
      "91/91 [==============================] - 0s 5ms/step - loss: 5.5641 - dense_52_loss: 1.7910 - gender_attention_5_loss: 3.7732 - dense_52_accuracy: 0.4008 - gender_attention_5_accuracy: 0.4036\n",
      "Epoch 29/150\n",
      "91/91 [==============================] - 0s 5ms/step - loss: 5.9121 - dense_52_loss: 2.2521 - gender_attention_5_loss: 3.6599 - dense_52_accuracy: 0.3662 - gender_attention_5_accuracy: 0.3870\n",
      "Epoch 30/150\n",
      "91/91 [==============================] - 0s 5ms/step - loss: 5.1188 - dense_52_loss: 1.5678 - gender_attention_5_loss: 3.5510 - dense_52_accuracy: 0.3731 - gender_attention_5_accuracy: 0.4119\n",
      "Epoch 31/150\n",
      "91/91 [==============================] - 1s 6ms/step - loss: 5.7126 - dense_52_loss: 2.0552 - gender_attention_5_loss: 3.6574 - dense_52_accuracy: 0.3925 - gender_attention_5_accuracy: 0.3870\n",
      "Epoch 32/150\n",
      "91/91 [==============================] - 0s 5ms/step - loss: 5.1022 - dense_52_loss: 1.7410 - gender_attention_5_loss: 3.3612 - dense_52_accuracy: 0.3981 - gender_attention_5_accuracy: 0.3967\n",
      "Epoch 33/150\n",
      "91/91 [==============================] - 0s 5ms/step - loss: 5.8941 - dense_52_loss: 2.5774 - gender_attention_5_loss: 3.3168 - dense_52_accuracy: 0.3745 - gender_attention_5_accuracy: 0.4147\n",
      "Epoch 34/150\n",
      "91/91 [==============================] - 0s 5ms/step - loss: 4.5661 - dense_52_loss: 1.3330 - gender_attention_5_loss: 3.2331 - dense_52_accuracy: 0.3828 - gender_attention_5_accuracy: 0.4175\n",
      "Epoch 35/150\n",
      "91/91 [==============================] - 0s 5ms/step - loss: 4.8522 - dense_52_loss: 1.6204 - gender_attention_5_loss: 3.2318 - dense_52_accuracy: 0.3440 - gender_attention_5_accuracy: 0.3828\n",
      "Epoch 36/150\n",
      "91/91 [==============================] - 0s 5ms/step - loss: 5.2340 - dense_52_loss: 1.6529 - gender_attention_5_loss: 3.5811 - dense_52_accuracy: 0.3745 - gender_attention_5_accuracy: 0.3911\n",
      "Epoch 37/150\n",
      "91/91 [==============================] - 0s 5ms/step - loss: 5.0661 - dense_52_loss: 1.7990 - gender_attention_5_loss: 3.2671 - dense_52_accuracy: 0.3564 - gender_attention_5_accuracy: 0.3814\n",
      "Epoch 38/150\n",
      "91/91 [==============================] - 1s 6ms/step - loss: 4.8469 - dense_52_loss: 1.5565 - gender_attention_5_loss: 3.2903 - dense_52_accuracy: 0.3967 - gender_attention_5_accuracy: 0.3814\n",
      "Epoch 39/150\n",
      "91/91 [==============================] - 0s 5ms/step - loss: 4.8186 - dense_52_loss: 1.6138 - gender_attention_5_loss: 3.2048 - dense_52_accuracy: 0.3994 - gender_attention_5_accuracy: 0.3870\n",
      "Epoch 40/150\n",
      "91/91 [==============================] - 0s 5ms/step - loss: 5.2951 - dense_52_loss: 2.0989 - gender_attention_5_loss: 3.1963 - dense_52_accuracy: 0.3883 - gender_attention_5_accuracy: 0.3897\n",
      "Epoch 41/150\n",
      "91/91 [==============================] - 0s 5ms/step - loss: 4.8487 - dense_52_loss: 1.5795 - gender_attention_5_loss: 3.2693 - dense_52_accuracy: 0.3856 - gender_attention_5_accuracy: 0.3883\n",
      "Epoch 42/150\n",
      "91/91 [==============================] - 0s 5ms/step - loss: 4.8504 - dense_52_loss: 1.6215 - gender_attention_5_loss: 3.2288 - dense_52_accuracy: 0.3856 - gender_attention_5_accuracy: 0.3634\n",
      "Epoch 43/150\n",
      "91/91 [==============================] - 0s 5ms/step - loss: 5.0677 - dense_52_loss: 1.8134 - gender_attention_5_loss: 3.2543 - dense_52_accuracy: 0.3745 - gender_attention_5_accuracy: 0.3925\n",
      "Epoch 44/150\n",
      "91/91 [==============================] - 0s 5ms/step - loss: 4.8026 - dense_52_loss: 1.6650 - gender_attention_5_loss: 3.1376 - dense_52_accuracy: 0.3620 - gender_attention_5_accuracy: 0.3953\n",
      "Epoch 45/150\n",
      "91/91 [==============================] - 0s 5ms/step - loss: 4.4928 - dense_52_loss: 1.5009 - gender_attention_5_loss: 2.9919 - dense_52_accuracy: 0.4341 - gender_attention_5_accuracy: 0.3814\n",
      "Epoch 46/150\n",
      "91/91 [==============================] - 0s 5ms/step - loss: 4.8446 - dense_52_loss: 1.6932 - gender_attention_5_loss: 3.1514 - dense_52_accuracy: 0.3689 - gender_attention_5_accuracy: 0.3911\n",
      "Epoch 47/150\n",
      "91/91 [==============================] - 0s 5ms/step - loss: 4.6941 - dense_52_loss: 1.6943 - gender_attention_5_loss: 2.9998 - dense_52_accuracy: 0.3717 - gender_attention_5_accuracy: 0.3773\n",
      "Epoch 48/150\n",
      "91/91 [==============================] - 0s 5ms/step - loss: 4.4131 - dense_52_loss: 1.3369 - gender_attention_5_loss: 3.0762 - dense_52_accuracy: 0.4286 - gender_attention_5_accuracy: 0.3759\n",
      "Epoch 49/150\n",
      "91/91 [==============================] - 0s 5ms/step - loss: 4.8367 - dense_52_loss: 1.6928 - gender_attention_5_loss: 3.1439 - dense_52_accuracy: 0.4022 - gender_attention_5_accuracy: 0.4036\n",
      "Epoch 50/150\n",
      "91/91 [==============================] - 0s 5ms/step - loss: 4.4347 - dense_52_loss: 1.3076 - gender_attention_5_loss: 3.1272 - dense_52_accuracy: 0.4202 - gender_attention_5_accuracy: 0.3814\n",
      "Epoch 51/150\n",
      "91/91 [==============================] - 0s 5ms/step - loss: 4.3546 - dense_52_loss: 1.4692 - gender_attention_5_loss: 2.8854 - dense_52_accuracy: 0.3800 - gender_attention_5_accuracy: 0.3745\n",
      "Epoch 52/150\n",
      "91/91 [==============================] - 1s 6ms/step - loss: 5.3936 - dense_52_loss: 2.3622 - gender_attention_5_loss: 3.0314 - dense_52_accuracy: 0.3495 - gender_attention_5_accuracy: 0.3883\n",
      "Epoch 53/150\n",
      "91/91 [==============================] - 0s 5ms/step - loss: 4.5933 - dense_52_loss: 1.6411 - gender_attention_5_loss: 2.9522 - dense_52_accuracy: 0.3939 - gender_attention_5_accuracy: 0.3814\n",
      "Epoch 54/150\n",
      "91/91 [==============================] - 0s 5ms/step - loss: 4.3859 - dense_52_loss: 1.5246 - gender_attention_5_loss: 2.8613 - dense_52_accuracy: 0.4258 - gender_attention_5_accuracy: 0.3911\n",
      "Epoch 55/150\n",
      "91/91 [==============================] - 0s 5ms/step - loss: 4.4394 - dense_52_loss: 1.4543 - gender_attention_5_loss: 2.9851 - dense_52_accuracy: 0.4050 - gender_attention_5_accuracy: 0.3939\n",
      "Epoch 56/150\n",
      "91/91 [==============================] - 0s 5ms/step - loss: 4.3768 - dense_52_loss: 1.2980 - gender_attention_5_loss: 3.0788 - dense_52_accuracy: 0.4230 - gender_attention_5_accuracy: 0.3883\n",
      "Epoch 57/150\n",
      "91/91 [==============================] - 0s 5ms/step - loss: 4.4670 - dense_52_loss: 1.3079 - gender_attention_5_loss: 3.1591 - dense_52_accuracy: 0.4147 - gender_attention_5_accuracy: 0.3828\n",
      "Epoch 58/150\n",
      "91/91 [==============================] - 1s 6ms/step - loss: 4.5024 - dense_52_loss: 1.3907 - gender_attention_5_loss: 3.1117 - dense_52_accuracy: 0.4008 - gender_attention_5_accuracy: 0.3911\n",
      "Epoch 59/150\n",
      "91/91 [==============================] - 0s 5ms/step - loss: 4.0762 - dense_52_loss: 1.3530 - gender_attention_5_loss: 2.7232 - dense_52_accuracy: 0.4286 - gender_attention_5_accuracy: 0.3828\n",
      "Epoch 60/150\n",
      "91/91 [==============================] - 1s 6ms/step - loss: 4.5795 - dense_52_loss: 1.7153 - gender_attention_5_loss: 2.8642 - dense_52_accuracy: 0.3648 - gender_attention_5_accuracy: 0.3675\n",
      "Epoch 61/150\n",
      "91/91 [==============================] - 0s 5ms/step - loss: 4.2478 - dense_52_loss: 1.5045 - gender_attention_5_loss: 2.7432 - dense_52_accuracy: 0.4147 - gender_attention_5_accuracy: 0.3800\n",
      "Epoch 62/150\n",
      "91/91 [==============================] - 0s 5ms/step - loss: 4.2063 - dense_52_loss: 1.4934 - gender_attention_5_loss: 2.7129 - dense_52_accuracy: 0.3925 - gender_attention_5_accuracy: 0.3620\n",
      "Epoch 63/150\n",
      "91/91 [==============================] - 0s 5ms/step - loss: 4.0210 - dense_52_loss: 1.6594 - gender_attention_5_loss: 2.3617 - dense_52_accuracy: 0.4022 - gender_attention_5_accuracy: 0.3773\n",
      "Epoch 64/150\n",
      "91/91 [==============================] - 1s 6ms/step - loss: 3.9475 - dense_52_loss: 1.4842 - gender_attention_5_loss: 2.4633 - dense_52_accuracy: 0.4258 - gender_attention_5_accuracy: 0.3703\n",
      "Epoch 65/150\n",
      "91/91 [==============================] - 0s 5ms/step - loss: 3.9086 - dense_52_loss: 1.5097 - gender_attention_5_loss: 2.3989 - dense_52_accuracy: 0.3842 - gender_attention_5_accuracy: 0.3759\n",
      "Epoch 66/150\n",
      "91/91 [==============================] - 1s 6ms/step - loss: 3.3843 - dense_52_loss: 1.1680 - gender_attention_5_loss: 2.2163 - dense_52_accuracy: 0.4854 - gender_attention_5_accuracy: 0.3731\n",
      "Epoch 67/150\n",
      "91/91 [==============================] - 0s 5ms/step - loss: 3.8089 - dense_52_loss: 1.5340 - gender_attention_5_loss: 2.2749 - dense_52_accuracy: 0.4078 - gender_attention_5_accuracy: 0.3800\n",
      "Epoch 68/150\n",
      "91/91 [==============================] - 0s 5ms/step - loss: 3.7159 - dense_52_loss: 1.2625 - gender_attention_5_loss: 2.4534 - dense_52_accuracy: 0.4161 - gender_attention_5_accuracy: 0.3967\n",
      "Epoch 69/150\n",
      "91/91 [==============================] - 0s 4ms/step - loss: 3.9996 - dense_52_loss: 1.7678 - gender_attention_5_loss: 2.2319 - dense_52_accuracy: 0.3939 - gender_attention_5_accuracy: 0.3870\n",
      "Epoch 70/150\n",
      "91/91 [==============================] - 0s 5ms/step - loss: 3.7405 - dense_52_loss: 1.3200 - gender_attention_5_loss: 2.4205 - dense_52_accuracy: 0.4050 - gender_attention_5_accuracy: 0.3800\n",
      "Epoch 71/150\n",
      "91/91 [==============================] - 0s 5ms/step - loss: 3.6669 - dense_52_loss: 1.2076 - gender_attention_5_loss: 2.4593 - dense_52_accuracy: 0.4078 - gender_attention_5_accuracy: 0.3745\n",
      "Epoch 72/150\n",
      "91/91 [==============================] - 1s 6ms/step - loss: 3.6394 - dense_52_loss: 1.4162 - gender_attention_5_loss: 2.2232 - dense_52_accuracy: 0.4008 - gender_attention_5_accuracy: 0.3759\n",
      "Epoch 73/150\n",
      "91/91 [==============================] - 0s 5ms/step - loss: 3.8403 - dense_52_loss: 1.5888 - gender_attention_5_loss: 2.2516 - dense_52_accuracy: 0.3981 - gender_attention_5_accuracy: 0.3856\n",
      "Epoch 74/150\n",
      "91/91 [==============================] - 0s 5ms/step - loss: 3.4582 - dense_52_loss: 1.3510 - gender_attention_5_loss: 2.1072 - dense_52_accuracy: 0.3856 - gender_attention_5_accuracy: 0.3662\n",
      "Epoch 75/150\n",
      "91/91 [==============================] - 0s 5ms/step - loss: 4.0393 - dense_52_loss: 1.8224 - gender_attention_5_loss: 2.2169 - dense_52_accuracy: 0.3800 - gender_attention_5_accuracy: 0.3759\n",
      "Epoch 76/150\n",
      "91/91 [==============================] - 0s 5ms/step - loss: 3.2860 - dense_52_loss: 1.4339 - gender_attention_5_loss: 1.8521 - dense_52_accuracy: 0.3883 - gender_attention_5_accuracy: 0.3842\n",
      "Epoch 77/150\n",
      "91/91 [==============================] - 0s 4ms/step - loss: 3.1697 - dense_52_loss: 1.2671 - gender_attention_5_loss: 1.9026 - dense_52_accuracy: 0.4230 - gender_attention_5_accuracy: 0.3731\n",
      "Epoch 78/150\n",
      "91/91 [==============================] - 0s 5ms/step - loss: 3.3826 - dense_52_loss: 1.1592 - gender_attention_5_loss: 2.2234 - dense_52_accuracy: 0.4147 - gender_attention_5_accuracy: 0.3759\n",
      "Epoch 79/150\n",
      "91/91 [==============================] - 0s 5ms/step - loss: 3.2809 - dense_52_loss: 1.1931 - gender_attention_5_loss: 2.0879 - dense_52_accuracy: 0.4161 - gender_attention_5_accuracy: 0.3773\n",
      "Epoch 80/150\n",
      "91/91 [==============================] - 1s 6ms/step - loss: 3.4074 - dense_52_loss: 1.3240 - gender_attention_5_loss: 2.0834 - dense_52_accuracy: 0.3842 - gender_attention_5_accuracy: 0.3689\n",
      "Epoch 81/150\n",
      "91/91 [==============================] - 0s 5ms/step - loss: 3.3132 - dense_52_loss: 1.3730 - gender_attention_5_loss: 1.9402 - dense_52_accuracy: 0.4064 - gender_attention_5_accuracy: 0.3745\n",
      "Epoch 82/150\n",
      "91/91 [==============================] - 0s 5ms/step - loss: 3.3907 - dense_52_loss: 1.3264 - gender_attention_5_loss: 2.0642 - dense_52_accuracy: 0.4008 - gender_attention_5_accuracy: 0.3773\n",
      "Epoch 83/150\n",
      "91/91 [==============================] - 0s 4ms/step - loss: 3.1669 - dense_52_loss: 1.3357 - gender_attention_5_loss: 1.8312 - dense_52_accuracy: 0.3828 - gender_attention_5_accuracy: 0.3689\n",
      "Epoch 84/150\n",
      "91/91 [==============================] - 0s 5ms/step - loss: 3.4100 - dense_52_loss: 1.3984 - gender_attention_5_loss: 2.0116 - dense_52_accuracy: 0.4119 - gender_attention_5_accuracy: 0.3675\n",
      "Epoch 85/150\n",
      "91/91 [==============================] - 0s 4ms/step - loss: 4.7908 - dense_52_loss: 2.8756 - gender_attention_5_loss: 1.9152 - dense_52_accuracy: 0.4008 - gender_attention_5_accuracy: 0.3870\n",
      "Epoch 86/150\n",
      "91/91 [==============================] - 0s 5ms/step - loss: 3.9885 - dense_52_loss: 1.7868 - gender_attention_5_loss: 2.2016 - dense_52_accuracy: 0.4230 - gender_attention_5_accuracy: 0.3648\n",
      "Epoch 87/150\n",
      "91/91 [==============================] - 0s 4ms/step - loss: 3.8053 - dense_52_loss: 1.6770 - gender_attention_5_loss: 2.1284 - dense_52_accuracy: 0.3786 - gender_attention_5_accuracy: 0.3717\n",
      "Epoch 88/150\n",
      "91/91 [==============================] - 0s 5ms/step - loss: 3.1934 - dense_52_loss: 1.4573 - gender_attention_5_loss: 1.7362 - dense_52_accuracy: 0.4119 - gender_attention_5_accuracy: 0.3689\n",
      "Epoch 89/150\n",
      "91/91 [==============================] - 0s 5ms/step - loss: 3.3439 - dense_52_loss: 1.2872 - gender_attention_5_loss: 2.0567 - dense_52_accuracy: 0.4216 - gender_attention_5_accuracy: 0.3675\n",
      "Epoch 90/150\n",
      "91/91 [==============================] - 1s 6ms/step - loss: 3.5600 - dense_52_loss: 1.5849 - gender_attention_5_loss: 1.9751 - dense_52_accuracy: 0.3786 - gender_attention_5_accuracy: 0.3648\n",
      "Epoch 91/150\n",
      "91/91 [==============================] - 0s 5ms/step - loss: 3.4991 - dense_52_loss: 1.4094 - gender_attention_5_loss: 2.0896 - dense_52_accuracy: 0.3911 - gender_attention_5_accuracy: 0.3606\n",
      "Epoch 92/150\n",
      "91/91 [==============================] - 0s 5ms/step - loss: 3.2075 - dense_52_loss: 1.3889 - gender_attention_5_loss: 1.8186 - dense_52_accuracy: 0.3648 - gender_attention_5_accuracy: 0.3675\n",
      "Epoch 93/150\n",
      "91/91 [==============================] - 0s 5ms/step - loss: 3.1042 - dense_52_loss: 1.1946 - gender_attention_5_loss: 1.9096 - dense_52_accuracy: 0.3994 - gender_attention_5_accuracy: 0.3578\n",
      "Epoch 94/150\n",
      "91/91 [==============================] - 0s 5ms/step - loss: 3.4260 - dense_52_loss: 1.3179 - gender_attention_5_loss: 2.1081 - dense_52_accuracy: 0.4078 - gender_attention_5_accuracy: 0.3578\n",
      "Epoch 95/150\n",
      "91/91 [==============================] - 0s 5ms/step - loss: 3.1605 - dense_52_loss: 1.3114 - gender_attention_5_loss: 1.8491 - dense_52_accuracy: 0.3800 - gender_attention_5_accuracy: 0.3689\n",
      "Epoch 96/150\n",
      "91/91 [==============================] - 0s 5ms/step - loss: 3.1458 - dense_52_loss: 1.2393 - gender_attention_5_loss: 1.9065 - dense_52_accuracy: 0.4119 - gender_attention_5_accuracy: 0.3578\n",
      "Epoch 97/150\n",
      "91/91 [==============================] - 0s 5ms/step - loss: 3.2034 - dense_52_loss: 1.2023 - gender_attention_5_loss: 2.0011 - dense_52_accuracy: 0.4008 - gender_attention_5_accuracy: 0.3454\n",
      "Epoch 98/150\n",
      "91/91 [==============================] - 0s 5ms/step - loss: 3.2568 - dense_52_loss: 1.3696 - gender_attention_5_loss: 1.8872 - dense_52_accuracy: 0.4036 - gender_attention_5_accuracy: 0.3467\n",
      "Epoch 99/150\n",
      "91/91 [==============================] - 0s 5ms/step - loss: 2.8804 - dense_52_loss: 1.1619 - gender_attention_5_loss: 1.7184 - dense_52_accuracy: 0.4175 - gender_attention_5_accuracy: 0.3578\n",
      "Epoch 100/150\n",
      "91/91 [==============================] - 0s 5ms/step - loss: 3.2477 - dense_52_loss: 1.2483 - gender_attention_5_loss: 1.9995 - dense_52_accuracy: 0.4161 - gender_attention_5_accuracy: 0.3454\n",
      "Epoch 101/150\n",
      "91/91 [==============================] - 0s 5ms/step - loss: 3.2910 - dense_52_loss: 1.2040 - gender_attention_5_loss: 2.0870 - dense_52_accuracy: 0.4244 - gender_attention_5_accuracy: 0.3689\n",
      "Epoch 102/150\n",
      "91/91 [==============================] - 0s 5ms/step - loss: 3.3100 - dense_52_loss: 1.1501 - gender_attention_5_loss: 2.1599 - dense_52_accuracy: 0.3994 - gender_attention_5_accuracy: 0.3606\n",
      "Epoch 103/150\n",
      "91/91 [==============================] - 0s 4ms/step - loss: 2.9204 - dense_52_loss: 1.1339 - gender_attention_5_loss: 1.7865 - dense_52_accuracy: 0.3967 - gender_attention_5_accuracy: 0.3662\n",
      "Epoch 104/150\n",
      "91/91 [==============================] - 0s 5ms/step - loss: 3.0901 - dense_52_loss: 1.1185 - gender_attention_5_loss: 1.9716 - dense_52_accuracy: 0.4341 - gender_attention_5_accuracy: 0.3606\n",
      "Epoch 105/150\n",
      "91/91 [==============================] - 0s 5ms/step - loss: 3.2081 - dense_52_loss: 1.1812 - gender_attention_5_loss: 2.0270 - dense_52_accuracy: 0.4064 - gender_attention_5_accuracy: 0.3731\n",
      "Epoch 106/150\n",
      "91/91 [==============================] - 1s 6ms/step - loss: 3.1965 - dense_52_loss: 1.1383 - gender_attention_5_loss: 2.0582 - dense_52_accuracy: 0.3967 - gender_attention_5_accuracy: 0.3814\n",
      "Epoch 107/150\n",
      "91/91 [==============================] - 0s 5ms/step - loss: 3.3103 - dense_52_loss: 1.2038 - gender_attention_5_loss: 2.1065 - dense_52_accuracy: 0.4175 - gender_attention_5_accuracy: 0.3689\n",
      "Epoch 108/150\n",
      "91/91 [==============================] - 0s 5ms/step - loss: 3.1636 - dense_52_loss: 1.1062 - gender_attention_5_loss: 2.0574 - dense_52_accuracy: 0.4244 - gender_attention_5_accuracy: 0.3897\n",
      "Epoch 109/150\n",
      "91/91 [==============================] - 0s 5ms/step - loss: 3.0564 - dense_52_loss: 1.1981 - gender_attention_5_loss: 1.8583 - dense_52_accuracy: 0.4300 - gender_attention_5_accuracy: 0.3648\n",
      "Epoch 110/150\n",
      "91/91 [==============================] - 0s 5ms/step - loss: 2.9684 - dense_52_loss: 1.1184 - gender_attention_5_loss: 1.8501 - dense_52_accuracy: 0.4327 - gender_attention_5_accuracy: 0.3662\n",
      "Epoch 111/150\n",
      "91/91 [==============================] - 0s 5ms/step - loss: 3.0328 - dense_52_loss: 1.1922 - gender_attention_5_loss: 1.8406 - dense_52_accuracy: 0.4272 - gender_attention_5_accuracy: 0.3842\n",
      "Epoch 112/150\n",
      "91/91 [==============================] - 0s 5ms/step - loss: 3.2824 - dense_52_loss: 1.4354 - gender_attention_5_loss: 1.8470 - dense_52_accuracy: 0.4258 - gender_attention_5_accuracy: 0.3786\n",
      "Epoch 113/150\n",
      "91/91 [==============================] - 0s 4ms/step - loss: 2.7556 - dense_52_loss: 1.1499 - gender_attention_5_loss: 1.6057 - dense_52_accuracy: 0.3925 - gender_attention_5_accuracy: 0.3842\n",
      "Epoch 114/150\n",
      "91/91 [==============================] - 0s 5ms/step - loss: 2.5751 - dense_52_loss: 1.1513 - gender_attention_5_loss: 1.4238 - dense_52_accuracy: 0.3939 - gender_attention_5_accuracy: 0.3773\n",
      "Epoch 115/150\n",
      "91/91 [==============================] - 0s 5ms/step - loss: 2.7513 - dense_52_loss: 1.0957 - gender_attention_5_loss: 1.6556 - dense_52_accuracy: 0.4383 - gender_attention_5_accuracy: 0.3648\n",
      "Epoch 116/150\n",
      "91/91 [==============================] - 0s 5ms/step - loss: 2.4585 - dense_52_loss: 1.1124 - gender_attention_5_loss: 1.3461 - dense_52_accuracy: 0.4244 - gender_attention_5_accuracy: 0.3745\n",
      "Epoch 117/150\n",
      "91/91 [==============================] - 0s 5ms/step - loss: 2.4692 - dense_52_loss: 1.1706 - gender_attention_5_loss: 1.2986 - dense_52_accuracy: 0.4105 - gender_attention_5_accuracy: 0.3925\n",
      "Epoch 118/150\n",
      "91/91 [==============================] - 0s 5ms/step - loss: 2.5761 - dense_52_loss: 1.2167 - gender_attention_5_loss: 1.3594 - dense_52_accuracy: 0.3717 - gender_attention_5_accuracy: 0.3703\n",
      "Epoch 119/150\n",
      "91/91 [==============================] - 0s 5ms/step - loss: 2.5739 - dense_52_loss: 1.1984 - gender_attention_5_loss: 1.3755 - dense_52_accuracy: 0.3828 - gender_attention_5_accuracy: 0.3745\n",
      "Epoch 120/150\n",
      "91/91 [==============================] - 0s 5ms/step - loss: 2.3257 - dense_52_loss: 1.1299 - gender_attention_5_loss: 1.1958 - dense_52_accuracy: 0.4369 - gender_attention_5_accuracy: 0.3620\n",
      "Epoch 121/150\n",
      "91/91 [==============================] - 0s 5ms/step - loss: 2.3661 - dense_52_loss: 1.0770 - gender_attention_5_loss: 1.2891 - dense_52_accuracy: 0.4369 - gender_attention_5_accuracy: 0.3703\n",
      "Epoch 122/150\n",
      "91/91 [==============================] - 0s 5ms/step - loss: 2.4969 - dense_52_loss: 1.1148 - gender_attention_5_loss: 1.3820 - dense_52_accuracy: 0.4327 - gender_attention_5_accuracy: 0.3759\n",
      "Epoch 123/150\n",
      "91/91 [==============================] - 0s 5ms/step - loss: 2.4125 - dense_52_loss: 1.0678 - gender_attention_5_loss: 1.3446 - dense_52_accuracy: 0.4549 - gender_attention_5_accuracy: 0.3689\n",
      "Epoch 124/150\n",
      "91/91 [==============================] - 1s 6ms/step - loss: 2.7121 - dense_52_loss: 1.3799 - gender_attention_5_loss: 1.3322 - dense_52_accuracy: 0.3773 - gender_attention_5_accuracy: 0.3870\n",
      "Epoch 125/150\n",
      "91/91 [==============================] - 0s 5ms/step - loss: 2.4222 - dense_52_loss: 1.1148 - gender_attention_5_loss: 1.3074 - dense_52_accuracy: 0.3953 - gender_attention_5_accuracy: 0.3662\n",
      "Epoch 126/150\n",
      "91/91 [==============================] - 0s 5ms/step - loss: 2.3707 - dense_52_loss: 1.0973 - gender_attention_5_loss: 1.2734 - dense_52_accuracy: 0.4189 - gender_attention_5_accuracy: 0.3689\n",
      "Epoch 127/150\n",
      "91/91 [==============================] - 0s 5ms/step - loss: 2.3858 - dense_52_loss: 1.1112 - gender_attention_5_loss: 1.2746 - dense_52_accuracy: 0.4189 - gender_attention_5_accuracy: 0.3759\n",
      "Epoch 128/150\n",
      "91/91 [==============================] - 0s 5ms/step - loss: 2.4147 - dense_52_loss: 1.1039 - gender_attention_5_loss: 1.3108 - dense_52_accuracy: 0.4216 - gender_attention_5_accuracy: 0.3689\n",
      "Epoch 129/150\n",
      "91/91 [==============================] - 0s 5ms/step - loss: 2.3037 - dense_52_loss: 1.1023 - gender_attention_5_loss: 1.2014 - dense_52_accuracy: 0.4438 - gender_attention_5_accuracy: 0.3759\n",
      "Epoch 130/150\n",
      "91/91 [==============================] - 1s 6ms/step - loss: 2.3764 - dense_52_loss: 1.1269 - gender_attention_5_loss: 1.2496 - dense_52_accuracy: 0.4230 - gender_attention_5_accuracy: 0.3662\n",
      "Epoch 131/150\n",
      "91/91 [==============================] - 0s 5ms/step - loss: 2.4018 - dense_52_loss: 1.1312 - gender_attention_5_loss: 1.2706 - dense_52_accuracy: 0.4411 - gender_attention_5_accuracy: 0.3662\n",
      "Epoch 132/150\n",
      "91/91 [==============================] - 1s 6ms/step - loss: 2.3761 - dense_52_loss: 1.0698 - gender_attention_5_loss: 1.3063 - dense_52_accuracy: 0.4327 - gender_attention_5_accuracy: 0.3592\n",
      "Epoch 133/150\n",
      "91/91 [==============================] - 0s 5ms/step - loss: 2.3693 - dense_52_loss: 1.0523 - gender_attention_5_loss: 1.3169 - dense_52_accuracy: 0.4577 - gender_attention_5_accuracy: 0.3592\n",
      "Epoch 134/150\n",
      "91/91 [==============================] - 1s 6ms/step - loss: 2.3522 - dense_52_loss: 1.0783 - gender_attention_5_loss: 1.2739 - dense_52_accuracy: 0.4272 - gender_attention_5_accuracy: 0.3675\n",
      "Epoch 135/150\n",
      "91/91 [==============================] - 0s 5ms/step - loss: 2.2764 - dense_52_loss: 1.0512 - gender_attention_5_loss: 1.2252 - dense_52_accuracy: 0.4508 - gender_attention_5_accuracy: 0.3606\n",
      "Epoch 136/150\n",
      "91/91 [==============================] - 1s 6ms/step - loss: 2.2960 - dense_52_loss: 1.0724 - gender_attention_5_loss: 1.2237 - dense_52_accuracy: 0.4202 - gender_attention_5_accuracy: 0.3218\n",
      "Epoch 137/150\n",
      "91/91 [==============================] - 0s 5ms/step - loss: 2.3992 - dense_52_loss: 1.1899 - gender_attention_5_loss: 1.2093 - dense_52_accuracy: 0.4119 - gender_attention_5_accuracy: 0.3467\n",
      "Epoch 138/150\n",
      "91/91 [==============================] - 1s 6ms/step - loss: 2.3723 - dense_52_loss: 1.0733 - gender_attention_5_loss: 1.2990 - dense_52_accuracy: 0.4230 - gender_attention_5_accuracy: 0.3675\n",
      "Epoch 139/150\n",
      "91/91 [==============================] - 0s 5ms/step - loss: 2.2223 - dense_52_loss: 1.0581 - gender_attention_5_loss: 1.1642 - dense_52_accuracy: 0.4105 - gender_attention_5_accuracy: 0.3814\n",
      "Epoch 140/150\n",
      "91/91 [==============================] - 1s 6ms/step - loss: 2.4988 - dense_52_loss: 1.2713 - gender_attention_5_loss: 1.2275 - dense_52_accuracy: 0.3634 - gender_attention_5_accuracy: 0.3578\n",
      "Epoch 141/150\n",
      "91/91 [==============================] - 0s 5ms/step - loss: 2.4528 - dense_52_loss: 1.0960 - gender_attention_5_loss: 1.3568 - dense_52_accuracy: 0.4286 - gender_attention_5_accuracy: 0.3648\n",
      "Epoch 142/150\n",
      "91/91 [==============================] - 0s 5ms/step - loss: 2.4250 - dense_52_loss: 1.0622 - gender_attention_5_loss: 1.3628 - dense_52_accuracy: 0.4494 - gender_attention_5_accuracy: 0.3606\n",
      "Epoch 143/150\n",
      "91/91 [==============================] - 0s 5ms/step - loss: 2.3582 - dense_52_loss: 1.1115 - gender_attention_5_loss: 1.2467 - dense_52_accuracy: 0.4272 - gender_attention_5_accuracy: 0.3551\n",
      "Epoch 144/150\n",
      "91/91 [==============================] - 1s 6ms/step - loss: 2.6473 - dense_52_loss: 1.1595 - gender_attention_5_loss: 1.4878 - dense_52_accuracy: 0.3870 - gender_attention_5_accuracy: 0.3717\n",
      "Epoch 145/150\n",
      "91/91 [==============================] - 0s 5ms/step - loss: 2.5368 - dense_52_loss: 1.0908 - gender_attention_5_loss: 1.4460 - dense_52_accuracy: 0.4133 - gender_attention_5_accuracy: 0.3786\n",
      "Epoch 146/150\n",
      "91/91 [==============================] - 0s 5ms/step - loss: 2.3678 - dense_52_loss: 1.0641 - gender_attention_5_loss: 1.3036 - dense_52_accuracy: 0.4189 - gender_attention_5_accuracy: 0.3454\n",
      "Epoch 147/150\n",
      "91/91 [==============================] - 0s 5ms/step - loss: 2.1750 - dense_52_loss: 1.0486 - gender_attention_5_loss: 1.1264 - dense_52_accuracy: 0.4313 - gender_attention_5_accuracy: 0.3010\n",
      "Epoch 148/150\n",
      "91/91 [==============================] - 1s 6ms/step - loss: 2.2937 - dense_52_loss: 1.0578 - gender_attention_5_loss: 1.2359 - dense_52_accuracy: 0.4286 - gender_attention_5_accuracy: 0.2552\n",
      "Epoch 149/150\n",
      "91/91 [==============================] - 0s 5ms/step - loss: 2.2137 - dense_52_loss: 1.1095 - gender_attention_5_loss: 1.1042 - dense_52_accuracy: 0.3925 - gender_attention_5_accuracy: 0.2718\n",
      "Epoch 150/150\n",
      "91/91 [==============================] - 1s 6ms/step - loss: 2.1388 - dense_52_loss: 1.0378 - gender_attention_5_loss: 1.1010 - dense_52_accuracy: 0.4577 - gender_attention_5_accuracy: 0.2788\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x26d40b96cd0>"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델 훈련\n",
    "model.fit([signals, genders], labels, epochs=150, batch_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "b37862d9-9178-4df1-a5ce-e07bf59e9394",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_6\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " signal_input (InputLayer)      [(None, 17)]         0           []                               \n",
      "                                                                                                  \n",
      " gender_input (InputLayer)      [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " gender_attention_5 (GenderAtte  ((None, 8),         456         ['signal_input[0][0]',           \n",
      " ntion)                          (None, None))                    'gender_input[0][0]']           \n",
      "                                                                                                  \n",
      " dense_51 (Dense)               (None, 32)           288         ['gender_attention_5[0][0]']     \n",
      "                                                                                                  \n",
      " dense_52 (Dense)               (None, 3)            99          ['dense_51[0][0]']               \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 843\n",
      "Trainable params: 843\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 모델 요약 출력\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8361b994-2fa3-4015-bb82-93c302d3fb96",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "f8e416bc-f6e3-4501-bc04-12836c08826a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 0s 3ms/step\n",
      "Attention Output Shape: (721, 8)\n",
      "Attention Output Sample:\n",
      " [[ 15.273754  45.429115  27.20805  -86.0716   -30.36104  -12.996181\n",
      "  -49.00752  -14.2495  ]\n",
      " [ 15.273754  45.429115  27.20805  -86.0716   -30.36104  -12.996181\n",
      "  -49.00752  -14.2495  ]\n",
      " [ 15.273754  45.429115  27.20805  -86.0716   -30.36104  -12.996181\n",
      "  -49.00752  -14.2495  ]\n",
      " [ 15.273754  45.429115  27.20805  -86.0716   -30.36104  -12.996181\n",
      "  -49.00752  -14.2495  ]\n",
      " [ 15.273754  45.429115  27.20805  -86.0716   -30.36104  -12.996181\n",
      "  -49.00752  -14.2495  ]]\n"
     ]
    }
   ],
   "source": [
    "# Attention Output 및 예측 결과 얻기\n",
    "predictions, attention_output = model.predict([signals, genders])\n",
    "\n",
    "# Attention Output 확인\n",
    "print(\"Attention Output Shape:\", attention_output.shape)\n",
    "print(\"Attention Output Sample:\\n\", attention_output[:5])  # 샘플 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "d39d9e81-27d4-4805-a767-d87d82a20dd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined Input Shape: (721, 25)\n"
     ]
    }
   ],
   "source": [
    "# 원본 signals와 attention output 결합\n",
    "combined_input = np.concatenate((signals, attention_output), axis=1)  # 열 방향으로 결합\n",
    "\n",
    "# 결합된 입력 데이터의 shape 확인\n",
    "print(\"Combined Input Shape:\", combined_input.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e07f4f06-65f3-4191-aa38-bf8c7d2ecc16",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bca01256-9b4c-4e7d-bd54-77899f26dc03",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "cbad1064-c1f8-4eb0-96fc-48dc56d14535",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "91/91 [==============================] - 1s 3ms/step - loss: 23.6203 - accuracy: 0.3773\n",
      "Epoch 2/200\n",
      "91/91 [==============================] - 0s 3ms/step - loss: 9.7624 - accuracy: 0.3662\n",
      "Epoch 3/200\n",
      "91/91 [==============================] - 0s 3ms/step - loss: 7.6511 - accuracy: 0.3703\n",
      "Epoch 4/200\n",
      "91/91 [==============================] - 0s 3ms/step - loss: 7.2548 - accuracy: 0.3828\n",
      "Epoch 5/200\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 6.7903 - accuracy: 0.4133\n",
      "Epoch 6/200\n",
      "91/91 [==============================] - 0s 3ms/step - loss: 6.4055 - accuracy: 0.4105\n",
      "Epoch 7/200\n",
      "91/91 [==============================] - 0s 3ms/step - loss: 4.6589 - accuracy: 0.4105\n",
      "Epoch 8/200\n",
      "91/91 [==============================] - 0s 3ms/step - loss: 4.5643 - accuracy: 0.3953\n",
      "Epoch 9/200\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 5.1549 - accuracy: 0.4133\n",
      "Epoch 10/200\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 4.9397 - accuracy: 0.4078\n",
      "Epoch 11/200\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 5.3892 - accuracy: 0.4189\n",
      "Epoch 12/200\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 3.9219 - accuracy: 0.4175\n",
      "Epoch 13/200\n",
      "91/91 [==============================] - 0s 3ms/step - loss: 3.6586 - accuracy: 0.4147\n",
      "Epoch 14/200\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 3.5170 - accuracy: 0.4646\n",
      "Epoch 15/200\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 3.8399 - accuracy: 0.4494\n",
      "Epoch 16/200\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 4.3399 - accuracy: 0.3925\n",
      "Epoch 17/200\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 4.5514 - accuracy: 0.4244\n",
      "Epoch 18/200\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 3.6263 - accuracy: 0.4189\n",
      "Epoch 19/200\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 4.1163 - accuracy: 0.4105\n",
      "Epoch 20/200\n",
      "91/91 [==============================] - 0s 3ms/step - loss: 3.4953 - accuracy: 0.4632\n",
      "Epoch 21/200\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 3.8189 - accuracy: 0.4300\n",
      "Epoch 22/200\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 4.8851 - accuracy: 0.3911\n",
      "Epoch 23/200\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 4.6185 - accuracy: 0.4244\n",
      "Epoch 24/200\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 5.3850 - accuracy: 0.4036\n",
      "Epoch 25/200\n",
      "91/91 [==============================] - 0s 3ms/step - loss: 2.8722 - accuracy: 0.4494\n",
      "Epoch 26/200\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 3.0683 - accuracy: 0.4272\n",
      "Epoch 27/200\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 4.2900 - accuracy: 0.4105\n",
      "Epoch 28/200\n",
      "91/91 [==============================] - 0s 3ms/step - loss: 3.9908 - accuracy: 0.3994\n",
      "Epoch 29/200\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 4.2154 - accuracy: 0.4175\n",
      "Epoch 30/200\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 3.8339 - accuracy: 0.4411\n",
      "Epoch 31/200\n",
      "91/91 [==============================] - 0s 3ms/step - loss: 3.2164 - accuracy: 0.4521\n",
      "Epoch 32/200\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 2.8350 - accuracy: 0.4535\n",
      "Epoch 33/200\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 5.3026 - accuracy: 0.4175\n",
      "Epoch 34/200\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 4.0302 - accuracy: 0.4272\n",
      "Epoch 35/200\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 4.9686 - accuracy: 0.4119\n",
      "Epoch 36/200\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 3.6250 - accuracy: 0.4105\n",
      "Epoch 37/200\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 2.9492 - accuracy: 0.4355\n",
      "Epoch 38/200\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 3.2350 - accuracy: 0.4577\n",
      "Epoch 39/200\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 3.7475 - accuracy: 0.4286\n",
      "Epoch 40/200\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 3.7845 - accuracy: 0.4244\n",
      "Epoch 41/200\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 2.3591 - accuracy: 0.4757\n",
      "Epoch 42/200\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 4.9094 - accuracy: 0.4341\n",
      "Epoch 43/200\n",
      "91/91 [==============================] - 0s 3ms/step - loss: 2.9506 - accuracy: 0.4896\n",
      "Epoch 44/200\n",
      "91/91 [==============================] - 0s 3ms/step - loss: 2.8158 - accuracy: 0.4244\n",
      "Epoch 45/200\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 3.2239 - accuracy: 0.4660\n",
      "Epoch 46/200\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 2.8659 - accuracy: 0.4868\n",
      "Epoch 47/200\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 2.9907 - accuracy: 0.4258\n",
      "Epoch 48/200\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 2.6464 - accuracy: 0.4563\n",
      "Epoch 49/200\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 2.8499 - accuracy: 0.4674\n",
      "Epoch 50/200\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 2.6979 - accuracy: 0.4799\n",
      "Epoch 51/200\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 2.8093 - accuracy: 0.4244\n",
      "Epoch 52/200\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 3.5410 - accuracy: 0.4480\n",
      "Epoch 53/200\n",
      "91/91 [==============================] - 0s 4ms/step - loss: 2.9924 - accuracy: 0.4369\n",
      "Epoch 54/200\n",
      "91/91 [==============================] - 0s 3ms/step - loss: 4.0968 - accuracy: 0.4189\n",
      "Epoch 55/200\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 4.8491 - accuracy: 0.4258\n",
      "Epoch 56/200\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 3.9281 - accuracy: 0.4272\n",
      "Epoch 57/200\n",
      "91/91 [==============================] - 0s 3ms/step - loss: 3.2162 - accuracy: 0.4521\n",
      "Epoch 58/200\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 2.3875 - accuracy: 0.4632\n",
      "Epoch 59/200\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 2.5782 - accuracy: 0.4757\n",
      "Epoch 60/200\n",
      "91/91 [==============================] - 0s 3ms/step - loss: 2.1473 - accuracy: 0.4674\n",
      "Epoch 61/200\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 2.9157 - accuracy: 0.4300\n",
      "Epoch 62/200\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 2.0130 - accuracy: 0.4716\n",
      "Epoch 63/200\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 3.2860 - accuracy: 0.4521\n",
      "Epoch 64/200\n",
      "91/91 [==============================] - 0s 3ms/step - loss: 2.1962 - accuracy: 0.4563\n",
      "Epoch 65/200\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 2.3086 - accuracy: 0.4730\n",
      "Epoch 66/200\n",
      "91/91 [==============================] - 0s 3ms/step - loss: 2.2163 - accuracy: 0.4716\n",
      "Epoch 67/200\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 3.7899 - accuracy: 0.4466\n",
      "Epoch 68/200\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 2.8956 - accuracy: 0.4702\n",
      "Epoch 69/200\n",
      "91/91 [==============================] - 0s 3ms/step - loss: 2.2332 - accuracy: 0.4896\n",
      "Epoch 70/200\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 2.3567 - accuracy: 0.4591\n",
      "Epoch 71/200\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 2.7795 - accuracy: 0.4674\n",
      "Epoch 72/200\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 2.6137 - accuracy: 0.4743\n",
      "Epoch 73/200\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 3.0396 - accuracy: 0.4216\n",
      "Epoch 74/200\n",
      "91/91 [==============================] - 0s 4ms/step - loss: 3.7898 - accuracy: 0.4300\n",
      "Epoch 75/200\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 2.1533 - accuracy: 0.4535\n",
      "Epoch 76/200\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 2.0839 - accuracy: 0.4965\n",
      "Epoch 77/200\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 2.1812 - accuracy: 0.4910\n",
      "Epoch 78/200\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 2.5125 - accuracy: 0.4799\n",
      "Epoch 79/200\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 2.8512 - accuracy: 0.4438\n",
      "Epoch 80/200\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 2.8245 - accuracy: 0.4438\n",
      "Epoch 81/200\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 2.6133 - accuracy: 0.3911\n",
      "Epoch 82/200\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 2.3834 - accuracy: 0.4480\n",
      "Epoch 83/200\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 2.1760 - accuracy: 0.4743\n",
      "Epoch 84/200\n",
      "91/91 [==============================] - 0s 4ms/step - loss: 2.9825 - accuracy: 0.4494\n",
      "Epoch 85/200\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 2.4315 - accuracy: 0.4730\n",
      "Epoch 86/200\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 3.2930 - accuracy: 0.4286\n",
      "Epoch 87/200\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 2.9775 - accuracy: 0.4480\n",
      "Epoch 88/200\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 2.0217 - accuracy: 0.4674\n",
      "Epoch 89/200\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 2.0311 - accuracy: 0.4605\n",
      "Epoch 90/200\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 2.2714 - accuracy: 0.4452\n",
      "Epoch 91/200\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 2.6859 - accuracy: 0.4480\n",
      "Epoch 92/200\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 2.7981 - accuracy: 0.4230\n",
      "Epoch 93/200\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 2.5212 - accuracy: 0.4660\n",
      "Epoch 94/200\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.8465 - accuracy: 0.4938\n",
      "Epoch 95/200\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 2.4030 - accuracy: 0.4591\n",
      "Epoch 96/200\n",
      "91/91 [==============================] - 0s 3ms/step - loss: 2.4837 - accuracy: 0.4494\n",
      "Epoch 97/200\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 2.5282 - accuracy: 0.4688\n",
      "Epoch 98/200\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 2.4896 - accuracy: 0.4521\n",
      "Epoch 99/200\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 2.3336 - accuracy: 0.4632\n",
      "Epoch 100/200\n",
      "91/91 [==============================] - 0s 3ms/step - loss: 1.9938 - accuracy: 0.4591\n",
      "Epoch 101/200\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 2.2414 - accuracy: 0.4619\n",
      "Epoch 102/200\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 2.2406 - accuracy: 0.4577\n",
      "Epoch 103/200\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 2.3247 - accuracy: 0.4799\n",
      "Epoch 104/200\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 2.2154 - accuracy: 0.4591\n",
      "Epoch 105/200\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 2.0088 - accuracy: 0.4757\n",
      "Epoch 106/200\n",
      "91/91 [==============================] - 0s 3ms/step - loss: 2.5379 - accuracy: 0.4619\n",
      "Epoch 107/200\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 2.9089 - accuracy: 0.4521\n",
      "Epoch 108/200\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 2.2791 - accuracy: 0.4730\n",
      "Epoch 109/200\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 2.0186 - accuracy: 0.5021\n",
      "Epoch 110/200\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 2.0085 - accuracy: 0.4882\n",
      "Epoch 111/200\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 2.1379 - accuracy: 0.4619\n",
      "Epoch 112/200\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 2.1496 - accuracy: 0.4563\n",
      "Epoch 113/200\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.8829 - accuracy: 0.4924\n",
      "Epoch 114/200\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 2.1792 - accuracy: 0.4743\n",
      "Epoch 115/200\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 2.3590 - accuracy: 0.4688\n",
      "Epoch 116/200\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 2.8783 - accuracy: 0.4730\n",
      "Epoch 117/200\n",
      "91/91 [==============================] - 0s 3ms/step - loss: 1.8958 - accuracy: 0.4827\n",
      "Epoch 118/200\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 2.3178 - accuracy: 0.4951\n",
      "Epoch 119/200\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.9474 - accuracy: 0.4910\n",
      "Epoch 120/200\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.6802 - accuracy: 0.4743\n",
      "Epoch 121/200\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.7552 - accuracy: 0.4896\n",
      "Epoch 122/200\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.9581 - accuracy: 0.4813\n",
      "Epoch 123/200\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 2.0859 - accuracy: 0.4965\n",
      "Epoch 124/200\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.6753 - accuracy: 0.4868\n",
      "Epoch 125/200\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 2.9221 - accuracy: 0.4383\n",
      "Epoch 126/200\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 2.2459 - accuracy: 0.4840\n",
      "Epoch 127/200\n",
      "91/91 [==============================] - 0s 3ms/step - loss: 1.6751 - accuracy: 0.4854\n",
      "Epoch 128/200\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 2.1605 - accuracy: 0.4868\n",
      "Epoch 129/200\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 2.3060 - accuracy: 0.4619\n",
      "Epoch 130/200\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.3833 - accuracy: 0.5243\n",
      "Epoch 131/200\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.6195 - accuracy: 0.4965\n",
      "Epoch 132/200\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 2.1107 - accuracy: 0.4757\n",
      "Epoch 133/200\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.9733 - accuracy: 0.4646\n",
      "Epoch 134/200\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.7740 - accuracy: 0.4813\n",
      "Epoch 135/200\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.5483 - accuracy: 0.4799\n",
      "Epoch 136/200\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.8178 - accuracy: 0.4785\n",
      "Epoch 137/200\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.5620 - accuracy: 0.4868\n",
      "Epoch 138/200\n",
      "91/91 [==============================] - 0s 3ms/step - loss: 2.1651 - accuracy: 0.4854\n",
      "Epoch 139/200\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.7840 - accuracy: 0.5007\n",
      "Epoch 140/200\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 2.2490 - accuracy: 0.4702\n",
      "Epoch 141/200\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.6831 - accuracy: 0.5021\n",
      "Epoch 142/200\n",
      "91/91 [==============================] - 0s 3ms/step - loss: 1.6914 - accuracy: 0.4854\n",
      "Epoch 143/200\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.9795 - accuracy: 0.4632\n",
      "Epoch 144/200\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.6950 - accuracy: 0.5076\n",
      "Epoch 145/200\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.8671 - accuracy: 0.4854\n",
      "Epoch 146/200\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4956 - accuracy: 0.5146\n",
      "Epoch 147/200\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.8458 - accuracy: 0.4993\n",
      "Epoch 148/200\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 2.0807 - accuracy: 0.4702\n",
      "Epoch 149/200\n",
      "91/91 [==============================] - 0s 3ms/step - loss: 1.9160 - accuracy: 0.4813\n",
      "Epoch 150/200\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.9878 - accuracy: 0.4646\n",
      "Epoch 151/200\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.6275 - accuracy: 0.4993\n",
      "Epoch 152/200\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.8878 - accuracy: 0.4716\n",
      "Epoch 153/200\n",
      "91/91 [==============================] - 0s 3ms/step - loss: 1.3570 - accuracy: 0.5201\n",
      "Epoch 154/200\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.6716 - accuracy: 0.4993\n",
      "Epoch 155/200\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 2.0116 - accuracy: 0.5062\n",
      "Epoch 156/200\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.8380 - accuracy: 0.4619\n",
      "Epoch 157/200\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.2807 - accuracy: 0.5312\n",
      "Epoch 158/200\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 5.7225 - accuracy: 0.4133\n",
      "Epoch 159/200\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.6934 - accuracy: 0.4882\n",
      "Epoch 160/200\n",
      "91/91 [==============================] - 0s 3ms/step - loss: 1.5175 - accuracy: 0.4924\n",
      "Epoch 161/200\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.6577 - accuracy: 0.4979\n",
      "Epoch 162/200\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4894 - accuracy: 0.4951\n",
      "Epoch 163/200\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4572 - accuracy: 0.5076\n",
      "Epoch 164/200\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.2786 - accuracy: 0.5021\n",
      "Epoch 165/200\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.6264 - accuracy: 0.5035\n",
      "Epoch 166/200\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 2.2369 - accuracy: 0.4702\n",
      "Epoch 167/200\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.8050 - accuracy: 0.5090\n",
      "Epoch 168/200\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.3646 - accuracy: 0.5201\n",
      "Epoch 169/200\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.5665 - accuracy: 0.5035\n",
      "Epoch 170/200\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.5734 - accuracy: 0.4910\n",
      "Epoch 171/200\n",
      "91/91 [==============================] - 0s 3ms/step - loss: 1.3333 - accuracy: 0.5104\n",
      "Epoch 172/200\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.2665 - accuracy: 0.5173\n",
      "Epoch 173/200\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.5157 - accuracy: 0.5146\n",
      "Epoch 174/200\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.5939 - accuracy: 0.5021\n",
      "Epoch 175/200\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4516 - accuracy: 0.4813\n",
      "Epoch 176/200\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.5293 - accuracy: 0.4965\n",
      "Epoch 177/200\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 2.0967 - accuracy: 0.4577\n",
      "Epoch 178/200\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4206 - accuracy: 0.5146\n",
      "Epoch 179/200\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.2841 - accuracy: 0.5437\n",
      "Epoch 180/200\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.6091 - accuracy: 0.4979\n",
      "Epoch 181/200\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.6197 - accuracy: 0.5118\n",
      "Epoch 182/200\n",
      "91/91 [==============================] - 0s 3ms/step - loss: 1.2860 - accuracy: 0.5132\n",
      "Epoch 183/200\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4675 - accuracy: 0.4882\n",
      "Epoch 184/200\n",
      "91/91 [==============================] - 0s 3ms/step - loss: 1.8713 - accuracy: 0.4868\n",
      "Epoch 185/200\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4526 - accuracy: 0.5021\n",
      "Epoch 186/200\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.1753 - accuracy: 0.5215\n",
      "Epoch 187/200\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.2380 - accuracy: 0.5617\n",
      "Epoch 188/200\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.3895 - accuracy: 0.5173\n",
      "Epoch 189/200\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 2.1894 - accuracy: 0.5021\n",
      "Epoch 190/200\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.2592 - accuracy: 0.5049\n",
      "Epoch 191/200\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4599 - accuracy: 0.4951\n",
      "Epoch 192/200\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.8413 - accuracy: 0.4882\n",
      "Epoch 193/200\n",
      "91/91 [==============================] - 0s 3ms/step - loss: 1.4797 - accuracy: 0.4827\n",
      "Epoch 194/200\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.3826 - accuracy: 0.5160\n",
      "Epoch 195/200\n",
      "91/91 [==============================] - 0s 3ms/step - loss: 1.4143 - accuracy: 0.5007\n",
      "Epoch 196/200\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.6944 - accuracy: 0.4965\n",
      "Epoch 197/200\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.7436 - accuracy: 0.4840\n",
      "Epoch 198/200\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4284 - accuracy: 0.5035\n",
      "Epoch 199/200\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.4695 - accuracy: 0.4771\n",
      "Epoch 200/200\n",
      "91/91 [==============================] - 0s 2ms/step - loss: 1.5458 - accuracy: 0.5049\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1.9207 - accuracy: 0.5354\n",
      "Loss: 1.9207, Accuracy: 0.5354\n"
     ]
    }
   ],
   "source": [
    "# 새로운 분류 모델 정의\n",
    "def create_combined_model(input_dim, hidden_dim, output_dim):\n",
    "    # 입력 정의\n",
    "    combined_input = Input(shape=(input_dim,), name='combined_input')  # combined_input 크기 설정\n",
    "\n",
    "    # Hidden Layer\n",
    "    x = layers.Dense(hidden_dim, activation='relu')(combined_input)\n",
    "    \n",
    "    # 출력 Layer (질병군 분류)\n",
    "    output = layers.Dense(output_dim, activation='softmax')(x)\n",
    "\n",
    "    # 모델 정의\n",
    "    model = Model(inputs=combined_input, outputs=output)\n",
    "\n",
    "    # 모델 컴파일\n",
    "    model.compile(optimizer=Adam(),\n",
    "                  loss=SparseCategoricalCrossentropy(),\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "# 원본 signals와 attention output 결합\n",
    "combined_input = np.concatenate((signals, attention_output), axis=1)  # 열 방향으로 결합\n",
    "\n",
    "# 새로운 모델 정의 및 학습\n",
    "input_dim = combined_input.shape[1]  # combined_input의 입력 차원\n",
    "combined_model = create_combined_model(input_dim, 64, 3)  # 새로운 모델 생성\n",
    "combined_model.fit(combined_input, labels, epochs=200, batch_size=8)  # 새로운 모델 학습\n",
    "\n",
    "# 학습 결과 평가\n",
    "loss, accuracy = combined_model.evaluate(combined_input, labels)\n",
    "print(f\"Loss: {loss:.4f}, Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba3c65df-3d4b-4f48-a65c-60d71feb75e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "a70d5907-7e37-4d3b-836f-ec26797c4dac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([121.79536 ,  24.883703,  69.96055 , -77.295334, -29.869204,\n",
       "       -22.590967, -47.84129 , -51.401432], dtype=float32)"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention_weights[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "a62c66a8-f884-4207-9167-3dba99d62941",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Male Attention Output Mean:\n",
      " [ 39.205296  75.1536    42.610256 -84.176704 -36.05272  -29.771793\n",
      " -71.2097   -37.13153 ]\n",
      "Female Attention Output Mean:\n",
      " [ 38.40839   73.11647   42.961193 -82.04955  -35.49542  -28.916817\n",
      " -69.10542  -35.82285 ]\n"
     ]
    }
   ],
   "source": [
    "# Attention Output 성별에 따른 평균 비교\n",
    "male_attention_output = attention_output[genders.flatten() == 0]\n",
    "female_attention_output = attention_output[genders.flatten() == 1]\n",
    "\n",
    "print(\"Male Attention Output Mean:\\n\", male_attention_output.mean(axis=0))\n",
    "print(\"Female Attention Output Mean:\\n\", female_attention_output.mean(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83310946-080d-4788-8704-def2250915f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be3eebf1-b728-4a1e-bef5-c9d6d5bd1008",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "78414918-4892-4b7e-9c50-3ddae731543c",
   "metadata": {},
   "source": [
    "> How can we adopt gender characteristic to extract significant features from signals?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "abb3ec44-2949-4f14-b925-b500c67bb95f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GenderAttention(layers.Layer):\n",
    "    def __init__(self, attention_dim):\n",
    "        super(GenderAttention, self).__init__()\n",
    "        self.male_query_dense = layers.Dense(attention_dim)\n",
    "        self.male_key_dense = layers.Dense(attention_dim)\n",
    "        self.male_value_dense = layers.Dense(attention_dim)\n",
    "\n",
    "        self.female_query_dense = layers.Dense(attention_dim)\n",
    "        self.female_key_dense = layers.Dense(attention_dim)\n",
    "        self.female_value_dense = layers.Dense(attention_dim)\n",
    "    \n",
    "    def call(self, x, gender):\n",
    "        male_mask = tf.cast(gender == 0, tf.float32)\n",
    "        female_mask = tf.cast(gender == 1, tf.float32)\n",
    "        \n",
    "        male_Q = self.male_query_dense(x) * male_mask\n",
    "        male_K = self.male_key_dense(x) * male_mask\n",
    "        male_V = self.male_value_dense(x) * male_mask\n",
    "        \n",
    "        female_Q = self.female_query_dense(x) * female_mask\n",
    "        female_K = self.female_key_dense(x) * female_mask\n",
    "        female_V = self.female_value_dense(x) * female_mask\n",
    "        \n",
    "        Q = male_Q + female_Q\n",
    "        K = male_K + female_K\n",
    "        V = male_V + female_V\n",
    "\n",
    "        # Attention score 계산 시 너무 큰 값 방지를 위해 평균을 뺀 후 softmax 적용\n",
    "        attention_scores = tf.matmul(Q, K, transpose_b=True) / tf.sqrt(tf.cast(tf.shape(Q)[-1], tf.float32))\n",
    "        \n",
    "        # 평균 제거로 안정화\n",
    "        attention_scores -= tf.reduce_mean(attention_scores, axis=-1, keepdims=True)\n",
    "        \n",
    "        # softmax 적용\n",
    "        attention_weights = tf.nn.softmax(attention_scores, axis=-1)\n",
    "\n",
    "        # 가중합 (Attention output)\n",
    "        attention_output = tf.matmul(attention_weights, V)\n",
    "\n",
    "        return attention_output, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "561ceb4f-f5a3-41cb-9de4-242594780722",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "91/91 [==============================] - 1s 7ms/step - loss: nan - dense_144_loss: 1.0485 - gender_attention_17_loss: nan - dense_144_accuracy: 0.4508 - gender_attention_17_accuracy: 0.1526  \n",
      "Epoch 2/50\n",
      "91/91 [==============================] - 1s 6ms/step - loss: nan - dense_144_loss: nan - gender_attention_17_loss: nan - dense_144_accuracy: 0.4508 - gender_attention_17_accuracy: 0.4508\n",
      "Epoch 3/50\n",
      "91/91 [==============================] - 1s 6ms/step - loss: nan - dense_144_loss: nan - gender_attention_17_loss: nan - dense_144_accuracy: 0.4508 - gender_attention_17_accuracy: 0.4508\n",
      "Epoch 4/50\n",
      "91/91 [==============================] - 1s 7ms/step - loss: nan - dense_144_loss: nan - gender_attention_17_loss: nan - dense_144_accuracy: 0.4508 - gender_attention_17_accuracy: 0.4508\n",
      "Epoch 5/50\n",
      "91/91 [==============================] - 1s 6ms/step - loss: nan - dense_144_loss: nan - gender_attention_17_loss: nan - dense_144_accuracy: 0.4508 - gender_attention_17_accuracy: 0.4508\n",
      "Epoch 6/50\n",
      "91/91 [==============================] - 1s 6ms/step - loss: nan - dense_144_loss: nan - gender_attention_17_loss: nan - dense_144_accuracy: 0.4508 - gender_attention_17_accuracy: 0.4508\n",
      "Epoch 7/50\n",
      "91/91 [==============================] - 1s 6ms/step - loss: nan - dense_144_loss: nan - gender_attention_17_loss: nan - dense_144_accuracy: 0.4508 - gender_attention_17_accuracy: 0.4508\n",
      "Epoch 8/50\n",
      "91/91 [==============================] - 1s 6ms/step - loss: nan - dense_144_loss: nan - gender_attention_17_loss: nan - dense_144_accuracy: 0.4508 - gender_attention_17_accuracy: 0.4508\n",
      "Epoch 9/50\n",
      "91/91 [==============================] - 1s 6ms/step - loss: nan - dense_144_loss: nan - gender_attention_17_loss: nan - dense_144_accuracy: 0.4508 - gender_attention_17_accuracy: 0.4508\n",
      "Epoch 10/50\n",
      "91/91 [==============================] - 1s 7ms/step - loss: nan - dense_144_loss: nan - gender_attention_17_loss: nan - dense_144_accuracy: 0.4508 - gender_attention_17_accuracy: 0.4508\n",
      "Epoch 11/50\n",
      "91/91 [==============================] - 1s 6ms/step - loss: nan - dense_144_loss: nan - gender_attention_17_loss: nan - dense_144_accuracy: 0.4508 - gender_attention_17_accuracy: 0.4508\n",
      "Epoch 12/50\n",
      "91/91 [==============================] - 1s 6ms/step - loss: nan - dense_144_loss: nan - gender_attention_17_loss: nan - dense_144_accuracy: 0.4508 - gender_attention_17_accuracy: 0.4508\n",
      "Epoch 13/50\n",
      "91/91 [==============================] - 1s 6ms/step - loss: nan - dense_144_loss: nan - gender_attention_17_loss: nan - dense_144_accuracy: 0.4508 - gender_attention_17_accuracy: 0.4508\n",
      "Epoch 14/50\n",
      "91/91 [==============================] - 1s 6ms/step - loss: nan - dense_144_loss: nan - gender_attention_17_loss: nan - dense_144_accuracy: 0.4508 - gender_attention_17_accuracy: 0.4508\n",
      "Epoch 15/50\n",
      "91/91 [==============================] - 1s 6ms/step - loss: nan - dense_144_loss: nan - gender_attention_17_loss: nan - dense_144_accuracy: 0.4508 - gender_attention_17_accuracy: 0.4508\n",
      "Epoch 16/50\n",
      "91/91 [==============================] - 1s 6ms/step - loss: nan - dense_144_loss: nan - gender_attention_17_loss: nan - dense_144_accuracy: 0.4508 - gender_attention_17_accuracy: 0.4508\n",
      "Epoch 17/50\n",
      "91/91 [==============================] - 1s 6ms/step - loss: nan - dense_144_loss: nan - gender_attention_17_loss: nan - dense_144_accuracy: 0.4508 - gender_attention_17_accuracy: 0.4508\n",
      "Epoch 18/50\n",
      "91/91 [==============================] - 1s 6ms/step - loss: nan - dense_144_loss: nan - gender_attention_17_loss: nan - dense_144_accuracy: 0.4508 - gender_attention_17_accuracy: 0.4508\n",
      "Epoch 19/50\n",
      "91/91 [==============================] - 1s 6ms/step - loss: nan - dense_144_loss: nan - gender_attention_17_loss: nan - dense_144_accuracy: 0.4508 - gender_attention_17_accuracy: 0.4508\n",
      "Epoch 20/50\n",
      "91/91 [==============================] - 1s 7ms/step - loss: nan - dense_144_loss: nan - gender_attention_17_loss: nan - dense_144_accuracy: 0.4508 - gender_attention_17_accuracy: 0.4508\n",
      "Epoch 21/50\n",
      "91/91 [==============================] - 1s 7ms/step - loss: nan - dense_144_loss: nan - gender_attention_17_loss: nan - dense_144_accuracy: 0.4508 - gender_attention_17_accuracy: 0.4508\n",
      "Epoch 22/50\n",
      "91/91 [==============================] - 1s 6ms/step - loss: nan - dense_144_loss: nan - gender_attention_17_loss: nan - dense_144_accuracy: 0.4508 - gender_attention_17_accuracy: 0.4508\n",
      "Epoch 23/50\n",
      "91/91 [==============================] - 1s 6ms/step - loss: nan - dense_144_loss: nan - gender_attention_17_loss: nan - dense_144_accuracy: 0.4508 - gender_attention_17_accuracy: 0.4508\n",
      "Epoch 24/50\n",
      "91/91 [==============================] - 1s 6ms/step - loss: nan - dense_144_loss: nan - gender_attention_17_loss: nan - dense_144_accuracy: 0.4508 - gender_attention_17_accuracy: 0.4508\n",
      "Epoch 25/50\n",
      "91/91 [==============================] - 1s 6ms/step - loss: nan - dense_144_loss: nan - gender_attention_17_loss: nan - dense_144_accuracy: 0.4508 - gender_attention_17_accuracy: 0.4508\n",
      "Epoch 26/50\n",
      "91/91 [==============================] - 1s 6ms/step - loss: nan - dense_144_loss: nan - gender_attention_17_loss: nan - dense_144_accuracy: 0.4508 - gender_attention_17_accuracy: 0.4508\n",
      "Epoch 27/50\n",
      "91/91 [==============================] - 1s 7ms/step - loss: nan - dense_144_loss: nan - gender_attention_17_loss: nan - dense_144_accuracy: 0.4508 - gender_attention_17_accuracy: 0.4508\n",
      "Epoch 28/50\n",
      "91/91 [==============================] - 1s 6ms/step - loss: nan - dense_144_loss: nan - gender_attention_17_loss: nan - dense_144_accuracy: 0.4508 - gender_attention_17_accuracy: 0.4508\n",
      "Epoch 29/50\n",
      "91/91 [==============================] - 1s 6ms/step - loss: nan - dense_144_loss: nan - gender_attention_17_loss: nan - dense_144_accuracy: 0.4508 - gender_attention_17_accuracy: 0.4508\n",
      "Epoch 30/50\n",
      "91/91 [==============================] - 1s 6ms/step - loss: nan - dense_144_loss: nan - gender_attention_17_loss: nan - dense_144_accuracy: 0.4508 - gender_attention_17_accuracy: 0.4508\n",
      "Epoch 31/50\n",
      "91/91 [==============================] - 0s 5ms/step - loss: nan - dense_144_loss: nan - gender_attention_17_loss: nan - dense_144_accuracy: 0.4508 - gender_attention_17_accuracy: 0.4508\n",
      "Epoch 32/50\n",
      "91/91 [==============================] - 1s 6ms/step - loss: nan - dense_144_loss: nan - gender_attention_17_loss: nan - dense_144_accuracy: 0.4508 - gender_attention_17_accuracy: 0.4508\n",
      "Epoch 33/50\n",
      "91/91 [==============================] - 0s 5ms/step - loss: nan - dense_144_loss: nan - gender_attention_17_loss: nan - dense_144_accuracy: 0.4508 - gender_attention_17_accuracy: 0.4508\n",
      "Epoch 34/50\n",
      "91/91 [==============================] - 1s 7ms/step - loss: nan - dense_144_loss: nan - gender_attention_17_loss: nan - dense_144_accuracy: 0.4508 - gender_attention_17_accuracy: 0.4508\n",
      "Epoch 35/50\n",
      "91/91 [==============================] - 1s 6ms/step - loss: nan - dense_144_loss: nan - gender_attention_17_loss: nan - dense_144_accuracy: 0.4508 - gender_attention_17_accuracy: 0.4508\n",
      "Epoch 36/50\n",
      "91/91 [==============================] - 1s 6ms/step - loss: nan - dense_144_loss: nan - gender_attention_17_loss: nan - dense_144_accuracy: 0.4508 - gender_attention_17_accuracy: 0.4508\n",
      "Epoch 37/50\n",
      "91/91 [==============================] - 0s 5ms/step - loss: nan - dense_144_loss: nan - gender_attention_17_loss: nan - dense_144_accuracy: 0.4508 - gender_attention_17_accuracy: 0.4508\n",
      "Epoch 38/50\n",
      "91/91 [==============================] - 1s 6ms/step - loss: nan - dense_144_loss: nan - gender_attention_17_loss: nan - dense_144_accuracy: 0.4508 - gender_attention_17_accuracy: 0.4508\n",
      "Epoch 39/50\n",
      "91/91 [==============================] - 1s 7ms/step - loss: nan - dense_144_loss: nan - gender_attention_17_loss: nan - dense_144_accuracy: 0.4508 - gender_attention_17_accuracy: 0.4508\n",
      "Epoch 40/50\n",
      "91/91 [==============================] - 1s 6ms/step - loss: nan - dense_144_loss: nan - gender_attention_17_loss: nan - dense_144_accuracy: 0.4508 - gender_attention_17_accuracy: 0.4508\n",
      "Epoch 41/50\n",
      "91/91 [==============================] - 1s 7ms/step - loss: nan - dense_144_loss: nan - gender_attention_17_loss: nan - dense_144_accuracy: 0.4508 - gender_attention_17_accuracy: 0.4508\n",
      "Epoch 42/50\n",
      "91/91 [==============================] - 1s 7ms/step - loss: nan - dense_144_loss: nan - gender_attention_17_loss: nan - dense_144_accuracy: 0.4508 - gender_attention_17_accuracy: 0.4508\n",
      "Epoch 43/50\n",
      "91/91 [==============================] - 1s 6ms/step - loss: nan - dense_144_loss: nan - gender_attention_17_loss: nan - dense_144_accuracy: 0.4508 - gender_attention_17_accuracy: 0.4508\n",
      "Epoch 44/50\n",
      "91/91 [==============================] - 1s 6ms/step - loss: nan - dense_144_loss: nan - gender_attention_17_loss: nan - dense_144_accuracy: 0.4508 - gender_attention_17_accuracy: 0.4508\n",
      "Epoch 45/50\n",
      "91/91 [==============================] - 1s 6ms/step - loss: nan - dense_144_loss: nan - gender_attention_17_loss: nan - dense_144_accuracy: 0.4508 - gender_attention_17_accuracy: 0.4508\n",
      "Epoch 46/50\n",
      "91/91 [==============================] - 1s 6ms/step - loss: nan - dense_144_loss: nan - gender_attention_17_loss: nan - dense_144_accuracy: 0.4508 - gender_attention_17_accuracy: 0.4508\n",
      "Epoch 47/50\n",
      "91/91 [==============================] - 1s 6ms/step - loss: nan - dense_144_loss: nan - gender_attention_17_loss: nan - dense_144_accuracy: 0.4508 - gender_attention_17_accuracy: 0.4508\n",
      "Epoch 48/50\n",
      "91/91 [==============================] - 1s 6ms/step - loss: nan - dense_144_loss: nan - gender_attention_17_loss: nan - dense_144_accuracy: 0.4508 - gender_attention_17_accuracy: 0.4508\n",
      "Epoch 49/50\n",
      "91/91 [==============================] - 1s 6ms/step - loss: nan - dense_144_loss: nan - gender_attention_17_loss: nan - dense_144_accuracy: 0.4508 - gender_attention_17_accuracy: 0.4508\n",
      "Epoch 50/50\n",
      "91/91 [==============================] - 1s 6ms/step - loss: nan - dense_144_loss: nan - gender_attention_17_loss: nan - dense_144_accuracy: 0.4508 - gender_attention_17_accuracy: 0.4508\n",
      "23/23 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "# 모델 정의\n",
    "def create_model(input_dim, attention_dim, hidden_dim, output_dim):\n",
    "    # 입력 정의\n",
    "    signal_input = Input(shape=(input_dim,), name='signal_input')\n",
    "    gender_input = Input(shape=(1,), name='gender_input')\n",
    "\n",
    "    # GenderAttention 레이어 적용\n",
    "    attention_output, attention_weights = GenderAttention(attention_dim)(signal_input, gender_input)\n",
    "\n",
    "    # Hidden Layer\n",
    "    x = layers.Dense(hidden_dim, activation='relu')(attention_output)\n",
    "    \n",
    "    # 출력 Layer (질병군 분류)\n",
    "    output = layers.Dense(output_dim, activation='softmax')(x)\n",
    "\n",
    "    # 모델 정의\n",
    "    model = Model(inputs=[signal_input, gender_input], outputs=[output, attention_weights])\n",
    "\n",
    "    # 모델 컴파일\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-5),\n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "# # 샘플 데이터 생성 (100개의 샘플)\n",
    "# signals = np.random.randn(100, 17).astype(np.float32)  # 생체신호 변수 (17개)\n",
    "# genders = np.random.randint(0, 2, (100, 1)).astype(np.float32)  # 성별 (M:0, F:1)\n",
    "# labels = np.random.randint(0, 3, (100,))  # 질병군 (A:0, B:1, C:2)\n",
    "\n",
    "# 모델 생성 및 학습\n",
    "model = create_model(input_dim=17, attention_dim=8, hidden_dim=24, output_dim=3)\n",
    "model.fit([signals, genders], labels, epochs=50, batch_size=8)\n",
    "\n",
    "# Attention Output 및 Weights 얻기\n",
    "predictions, attention_weights = model.predict([signals, genders])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "0e47f99e-a8c7-4e51-83f2-41b937a39b85",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 1, 0, 0, 1, 1, 0, 0, 0, 0, 2, 2, 1, 1, 1, 2, 1, 1, 0, 0, 1, 1,\n",
       "       1, 1, 1, 2, 2, 0, 0, 1, 0, 2, 0, 0, 2, 0, 1, 2, 1, 0, 0, 1, 0, 0,\n",
       "       1, 1, 0, 0, 0, 0, 2, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0,\n",
       "       1, 2, 0, 1, 1, 0, 0, 2, 1, 2, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 2,\n",
       "       0, 0, 1, 2, 1, 0, 1, 0, 1, 2, 0, 1, 0, 1, 2, 0, 1, 0, 0, 0, 1, 2,\n",
       "       1, 1, 0, 2, 1, 0, 1, 1, 0, 2, 1, 1, 1, 0, 1, 0, 0, 0, 2, 1, 0, 0,\n",
       "       1, 1, 1, 0, 1, 1, 2, 1, 2, 0, 1, 2, 0, 2, 0, 2, 0, 1, 1, 0, 1, 1,\n",
       "       0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 2, 1, 2, 2, 1, 1, 1, 2, 0, 0, 0, 0,\n",
       "       1, 0, 0, 0, 1, 1, 2, 1, 2, 1, 1, 0, 1, 1, 1, 1, 2, 0, 0, 0, 2, 1,\n",
       "       1, 0, 2, 1, 1, 0, 2, 1, 1, 2, 0, 0, 2, 0, 2, 1, 0, 1, 1, 0, 1, 2,\n",
       "       2, 1, 2, 0, 2, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0,\n",
       "       2, 1, 1, 2, 1, 0, 2, 1, 2, 1, 1, 2, 1, 2, 1, 0, 1, 0, 0, 0, 1, 1,\n",
       "       2, 1, 2, 2, 0, 1, 2, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1,\n",
       "       1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 2, 0, 0,\n",
       "       0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0,\n",
       "       0, 0, 0, 2, 0, 0, 0, 1, 1, 0, 1, 0, 1, 2, 1, 0, 1, 0, 2, 2, 0, 0,\n",
       "       0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 2, 2, 1, 0,\n",
       "       1, 1, 2, 0, 1, 1, 1, 0, 0, 1, 1, 2, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1,\n",
       "       0, 0, 0, 1, 2, 0, 0, 0, 1, 1, 1, 1, 1, 2, 1, 0, 1, 1, 0, 0, 1, 0,\n",
       "       1, 1, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0,\n",
       "       0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 2, 0,\n",
       "       1, 1, 1, 2, 0, 1, 0, 2, 1, 1, 1, 0, 0, 2, 1, 0, 0, 1, 0, 1, 1, 0,\n",
       "       0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 2, 0, 0, 2, 0, 1, 1, 1, 0,\n",
       "       1, 1, 0, 0, 2, 1, 2, 0, 0, 0, 1, 2, 1, 1, 1, 2, 0, 0, 1, 1, 1, 0,\n",
       "       0, 0, 0, 2, 2, 0, 0, 0, 0, 0, 1, 1, 2, 1, 1, 2, 0, 0, 0, 1, 0, 0,\n",
       "       0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 2, 2, 0, 0, 2, 0, 2, 0, 1, 0,\n",
       "       0, 0, 2, 2, 0, 1, 2, 0, 0, 1, 1, 1, 1, 0, 0, 2, 2, 1, 2, 2, 0, 2,\n",
       "       1, 1, 0, 0, 2, 2, 2, 1, 0, 0, 2, 0, 0, 1, 0, 1, 1, 0, 1, 2, 2, 1,\n",
       "       0, 1, 0, 2, 1, 0, 0, 0, 0, 0, 1, 0, 0, 2, 2, 2, 0, 2, 0, 0, 2, 0,\n",
       "       2, 0, 0, 1, 1, 1, 0, 1, 0, 2, 1, 0, 1, 0, 2, 0, 1, 0, 2, 0, 2, 1,\n",
       "       0, 0, 0, 2, 1, 2, 1, 2, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1,\n",
       "       0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 2, 1, 0, 0, 2, 2, 0, 0, 2, 2, 0,\n",
       "       1, 0, 2, 0, 0, 0, 0, 1, 1, 1, 0, 2, 0, 0, 0, 2, 1], dtype=int64)"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60228f6f-ea20-40b9-96cb-2c01b4dec546",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
