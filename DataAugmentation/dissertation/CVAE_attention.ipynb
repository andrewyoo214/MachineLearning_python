{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a409186e-356f-4a34-835f-c006018fabff",
   "metadata": {},
   "source": [
    "# CVAE + attention practices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "0d9adca5-bebb-4919-8a2b-d84ec4835ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a7a27358-959d-4a41-9084-9d66af6206cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3f5a3ff4-9884-4373-a5ea-9c118dde07d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f731884-f8ea-420e-b815-c63e14525637",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3e533fe1-f4c0-4b72-b2c9-bc7816f15a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_ori = pd.read_csv(\"C:/Users/andre/Downloads/heart_disease.csv\") ## home direc.\n",
    "data_ori = pd.read_csv('E:/RESEARCH/Datasets/dissertation/heart_disease_sampled.csv') ## heart disease public dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "14861381-1ce2-4ef4-883a-03550f2d47ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 최소값과 최대값을 확인\n",
    "min_age = data_ori['age'].min()\n",
    "max_age = data_ori['age'].max()\n",
    "\n",
    "# 연령 구간을 10살씩 끊어서 정의\n",
    "age_bins = list(range(min_age // 10 * 10, max_age + 10, 10))  # 10살 간격으로 구간 정의\n",
    "age_labels = [f\"({i}, {i+10}]\" for i in age_bins[:-1]]  # 구간 레이블 생성\n",
    "\n",
    "# pd.cut()을 사용하여 연령을 구간별로 그룹화\n",
    "data_ori['age_group'] = pd.cut(data_ori['age'], bins=age_bins, labels=age_labels, right=False)\n",
    "\n",
    "# age_group을 카테고리형 변수로 변환하고 코드화 (0부터 시작)\n",
    "data_ori['age_enc'] = pd.Categorical(data_ori['age_group']).codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "65aad966-42a4-4be9-9585-1c6a56ee283d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>target</th>\n",
       "      <th>age_group</th>\n",
       "      <th>age_enc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>54</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>188</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>113</td>\n",
       "      <td>0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>(50, 60]</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>43</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>132</td>\n",
       "      <td>341</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>136</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>(40, 50]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>62</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>130</td>\n",
       "      <td>263</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>97</td>\n",
       "      <td>0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>(60, 70]</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>62</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>130</td>\n",
       "      <td>263</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>97</td>\n",
       "      <td>0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>(60, 70]</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>47</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>108</td>\n",
       "      <td>243</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>152</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>(40, 50]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  slope  \\\n",
       "0   54    1   0       120   188    0        1      113      0      1.4      1   \n",
       "1   43    0   0       132   341    1        0      136      1      3.0      1   \n",
       "2   62    0   2       130   263    0        1       97      0      1.2      1   \n",
       "3   62    0   2       130   263    0        1       97      0      1.2      1   \n",
       "4   47    1   2       108   243    0        1      152      0      0.0      2   \n",
       "\n",
       "   ca  thal  target age_group  age_enc  \n",
       "0   1     3       0  (50, 60]        3  \n",
       "1   0     3       0  (40, 50]        2  \n",
       "2   1     3       0  (60, 70]        4  \n",
       "3   1     3       0  (60, 70]        4  \n",
       "4   0     2       0  (40, 50]        2  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_ori.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c9f66be3-3ff3-4e02-bb57-a6b8ec7678c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_ori = data_ori.drop(['age_group', 'age'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c761a94f-3442-42fa-90cf-0e57d2e30ff8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['sex', 'cp', 'trestbps', 'chol', 'fbs', 'restecg', 'thalach', 'exang',\n",
       "       'oldpeak', 'slope', 'ca', 'thal', 'target', 'age_enc'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_ori.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b224bfd8-7f79-48fd-b91c-5aa539dd5a26",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c034c6dc-6d7c-4e8e-9cfc-a51bfded7b6b",
   "metadata": {},
   "source": [
    "# First trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84684df1-8742-4146-a19e-023b84e4ae93",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_dim, condition_dim, latent_dim):\n",
    "        super(Encoder, self).__init__()\n",
    "        \n",
    "        self.input_dim = input_dim\n",
    "        self.condition_dim = condition_dim\n",
    "        self.latent_dim = latent_dim\n",
    "        \n",
    "        self.fc1 = nn.Linear(input_dim + condition_dim, 128)  # x와 condition 결합 후 크기\n",
    "        self.fc2 = nn.Linear(128, 128)\n",
    "        self.fc3_mu = nn.Linear(128, latent_dim)\n",
    "        self.fc3_logvar = nn.Linear(128, latent_dim)\n",
    "\n",
    "    def forward(self, x, condition):\n",
    "        # x와 condition을 결합 (생체신호 + 조건)\n",
    "        x_condition = torch.cat([x, condition], dim=-1)\n",
    "        print(f\"x_condition shape in Encoder: {x_condition.shape}\")  # 차원 출력\n",
    "        \n",
    "        h = F.relu(self.fc1(x_condition))\n",
    "        print(f\"h shape after fc1: {h.shape}\")\n",
    "        \n",
    "        h = F.relu(self.fc2(h))\n",
    "        print(f\"h shape after fc2: {h.shape}\")\n",
    "        \n",
    "        mu = self.fc3_mu(h)\n",
    "        logvar = self.fc3_logvar(h)\n",
    "        \n",
    "        return mu, logvar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb77a2e8-39ec-4978-aa6a-28cd1e40ad42",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, latent_dim, condition_dim, output_dim):\n",
    "        super(Decoder, self).__init__()\n",
    "        \n",
    "        self.latent_dim = latent_dim\n",
    "        self.condition_dim = condition_dim\n",
    "        self.output_dim = output_dim\n",
    "        \n",
    "        self.fc1 = nn.Linear(latent_dim + condition_dim, 128)  # z와 condition 결합 후 크기\n",
    "        self.fc2 = nn.Linear(128, 128)\n",
    "        self.fc3 = nn.Linear(128, output_dim)\n",
    "        \n",
    "    def forward(self, z, condition):\n",
    "        # z와 condition을 결합\n",
    "        z_condition = torch.cat([z, condition], dim=-1)\n",
    "        print(f\"z_condition shape in Decoder: {z_condition.shape}\")  # 차원 출력\n",
    "        \n",
    "        h = F.relu(self.fc1(z_condition))\n",
    "        print(f\"h shape after fc1: {h.shape}\")\n",
    "        \n",
    "        h = F.relu(self.fc2(h))\n",
    "        print(f\"h shape after fc2: {h.shape}\")\n",
    "        \n",
    "        output = self.fc3(h)\n",
    "        print(f\"Output shape: {output.shape}\")\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8178ce1a-621b-47f2-ab73-4beb3a326e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CVAE(nn.Module):\n",
    "    def __init__(self, input_dim, condition_dim, latent_dim, output_dim):\n",
    "        super(CVAE, self).__init__()\n",
    "        self.encoder = Encoder(input_dim, condition_dim, latent_dim)\n",
    "        self.decoder = Decoder(latent_dim, condition_dim, output_dim)\n",
    "\n",
    "    def reparameterize(self, mu, logvar):\n",
    "        std = torch.exp(0.5 * logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + eps * std\n",
    "\n",
    "    def forward(self, x, condition):\n",
    "        # Encoder에서 mu, logvar 계산\n",
    "        mu, logvar = self.encoder(x, condition)\n",
    "        \n",
    "        # Reparameterization trick\n",
    "        z = self.reparameterize(mu, logvar)\n",
    "        print(f\"z shape after reparameterization: {z.shape}\")\n",
    "        \n",
    "        # Decoder에서 output 생성\n",
    "        reconstructed_x = self.decoder(z, condition)\n",
    "        return reconstructed_x, mu, logvar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "352a84ec-8c88-4c30-9d8e-deca05e83860",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_function(reconstructed_x, x, mu, logvar):\n",
    "    # 재구성 손실 (MSE 또는 BCE)\n",
    "    reconstruction_loss = F.mse_loss(reconstructed_x, x, reduction='sum')\n",
    "    \n",
    "    # KL Divergence\n",
    "    kl_loss = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "    \n",
    "    # 총 손실\n",
    "    loss = reconstruction_loss + kl_loss\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e956766b-c052-451a-8ffc-9e5961acad3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 샘플 예시 (x: 15개의 생체신호, condition: 연령, 성별, 질병)\n",
    "x = torch.randn(32, 15)  # 배치 크기: 32, 생체신호 15개\n",
    "condition = torch.randn(32, 3)  # 배치 크기: 32, 연령, 성별, 질병 3개\n",
    "\n",
    "# 차원 출력\n",
    "print(f\"x shape: {x.shape}\")\n",
    "print(f\"condition shape: {condition.shape}\")\n",
    "\n",
    "model = CVAE(input_dim=15, condition_dim=3, latent_dim=10, output_dim=15)\n",
    "output, mu, logvar = model(x, condition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5bbd082-b467-47e8-9a97-6ed6976b8dd4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aeb512d-54c7-4788-a5f8-75d1604db6a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "236d5a33-4bb3-4d43-943c-8e87c80d222c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 랜덤 시드 설정 (재현성을 위해)\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# 예시 데이터 생성\n",
    "num_samples = 1000  # 샘플 수\n",
    "\n",
    "# 생체신호 변수 (15개) - 예시로 임의의 값 생성\n",
    "biometric_signals = np.random.rand(num_samples, 15)\n",
    "\n",
    "# 연령 변수 (0 ~ 80세, 10단위로 나눈 연령대)\n",
    "age_groups = np.random.choice([0, 1, 2, 3, 4], num_samples)  # 0: 10대, 1: 20대, 2: 30대, 3: 40대, 4: 50대 이상\n",
    "ages = age_groups * 10 + np.random.randint(0, 10, num_samples)  # 나이\n",
    "\n",
    "# 성별 변수 (0: 남성, 1: 여성)\n",
    "sex = np.random.choice([0, 1], num_samples)\n",
    "\n",
    "# 질병 변수 (타겟, 예시로 두 가지 질병: 0: 건강, 1: 질병1, 2: 질병2)\n",
    "disease = np.random.choice([0, 1, 2], num_samples)\n",
    "\n",
    "# DataFrame으로 변환\n",
    "data = pd.DataFrame(biometric_signals, columns=[f'biometric_{i+1}' for i in range(15)])\n",
    "data['age'] = ages\n",
    "data['sex'] = sex\n",
    "data['age_group'] = age_groups\n",
    "data['disease'] = disease\n",
    "data = data.drop('age', axis=1)\n",
    "\n",
    "\n",
    "# 예시 데이터 확인\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96a05eb6-51c2-4bde-a262-21e46985918c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class MedicalDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "        self.x = torch.tensor(data.iloc[:, :-3].values, dtype=torch.float32)  # 생체신호 변수 (15개)\n",
    "        self.conditions = torch.tensor(data[['age_group', 'sex', 'disease']].values, dtype=torch.float32)  # 조건 변수 (연령, 성별, 질병)\n",
    "        self.y = torch.tensor(data['disease'].values, dtype=torch.long)  # 질병 변수 (타겟)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.x[idx], self.conditions[idx], self.y[idx]\n",
    "\n",
    "# 데이터셋 준비\n",
    "dataset = MedicalDataset(data)\n",
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c57b162-8ea9-49f1-be32-22940016c83c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 모델 초기화\n",
    "input_dim = 15  # 생체신호 변수 개수\n",
    "condition_dim = 3  # age, sex, disease\n",
    "latent_dim = 10  # 잠재 공간 차원\n",
    "output_dim = 15  # 생체신호 출력 차원\n",
    "\n",
    "model = CVAE(input_dim, condition_dim, latent_dim, output_dim).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "# 모델 학습\n",
    "num_epochs = 20\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for x, condition, y in dataloader:\n",
    "        x = x.to(device)\n",
    "        condition = condition.to(device)\n",
    "\n",
    "        # 모델 순전파\n",
    "        reconstructed_x, mu, logvar = model(x, condition)\n",
    "\n",
    "        # 손실 함수 계산\n",
    "        loss = loss_function(reconstructed_x, x, mu, logvar)\n",
    "        \n",
    "        # 역전파\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    avg_loss = running_loss / len(dataloader)\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {avg_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "480d0b84-4a47-49df-8e39-2518b1836245",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_virtual_patient_conditions(data, num_samples=num_samples):\n",
    "    # 원본 데이터에서 조건 분포를 기준으로 샘플링\n",
    "    conditions = []\n",
    "    for _ in range(num_samples):\n",
    "        # 예시: 성별, 연령대, 질병을 샘플링\n",
    "        gender = np.random.choice(data['sex'].unique())\n",
    "        age_group = np.random.choice(data['age_group'].unique())\n",
    "        disease = np.random.choice(data['disease'].unique())\n",
    "        conditions.append([gender, age_group, disease])\n",
    "    return torch.tensor(conditions, dtype=torch.float32)\n",
    "\n",
    "# 가상 환자 조건 샘플링\n",
    "virtual_conditions = sample_virtual_patient_conditions(data, num_samples=100)\n",
    "virtual_conditions = virtual_conditions.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "149ac592-588f-4114-b2c8-b6f8d51122dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_synthetic_data(model, conditions):\n",
    "    model.eval()  # 모델을 평가 모드로 설정\n",
    "    with torch.no_grad():\n",
    "        # 가상 조건에 대해 잠재 공간에서 샘플링\n",
    "        latent_space_sample = torch.randn(conditions.size(0), latent_dim).to(device)  # 잠재 벡터\n",
    "        synthetic_data = model.decoder(latent_space_sample, conditions)\n",
    "    return synthetic_data\n",
    "\n",
    "# synthetic data 생성\n",
    "synthetic_data = generate_synthetic_data(model, virtual_conditions)\n",
    "# print(synthetic_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "196a43a1-bac7-439d-bb78-423791b436dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "synthetic_data[99]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff4cfe2a-d317-4486-9916-bcbd4476ada8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e661faa2-cfd5-4e5c-963c-5ec3d090e275",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45cfb0bc-8009-4cee-b827-898178c9005e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "81b337f2-5a40-4775-b754-65558b5c9a02",
   "metadata": {},
   "source": [
    "# Second trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93855b30-a3d9-4ec1-8f3e-80e0c24ef7f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data_ori.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a082199b-20c0-4fef-b2b0-4ebc2dce83ea",
   "metadata": {},
   "source": [
    "* 데이터 처리 및 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35171ab8-a886-48b6-a311-e0d34afa230c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BiometricDataset(Dataset):\n",
    "    def __init__(self, data, scaler=None):\n",
    "        self.features = data.drop(columns=['age_enc', 'sex', 'target']).values  # 15개 생체신호 변수\n",
    "        self.age = data['age_enc'].values\n",
    "        self.gender = data['sex'].values\n",
    "        self.disease = data['target'].values\n",
    "        \n",
    "\n",
    "        # 스케일링\n",
    "        if scaler is None:\n",
    "            self.scaler = StandardScaler().fit(self.features)\n",
    "        else:\n",
    "            self.scaler = scaler\n",
    "        self.features = self.scaler.transform(self.features)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.features)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            'features': torch.tensor(self.features[idx], dtype=torch.float32),\n",
    "            'age_enc': torch.tensor(self.age[idx], dtype=torch.float32),\n",
    "            'sex': torch.tensor(self.gender[idx], dtype=torch.float32),\n",
    "            'target': torch.tensor(self.disease[idx], dtype=torch.float32)\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f979120-e48c-4a73-9b91-5aa3f74bad78",
   "metadata": {},
   "source": [
    "* CVAE 모델 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54c3e87c-1aa7-4fdc-979e-50fa56e581ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class CVAEWithAttention(nn.Module):\n",
    "    def __init__(self, input_dim, condition_dim, latent_dim):\n",
    "        super(CVAEWithAttention, self).__init__()\n",
    "        \n",
    "        # 인코더: input_dim + condition_dim 크기 조정\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_dim + condition_dim, 256),  # 크기 조정\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 64)\n",
    "        )\n",
    "        self.fc_mu = nn.Linear(64, latent_dim)\n",
    "        self.fc_logvar = nn.Linear(64, latent_dim)\n",
    "        \n",
    "        # 디코더: latent_dim + condition_dim 크기 조정\n",
    "        self.decoder_fc = nn.Sequential(\n",
    "            nn.Linear(latent_dim + condition_dim, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 256),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        # Attention 블록: self_attention과 cross_attention\n",
    "        self.self_attention = nn.MultiheadAttention(embed_dim=256, num_heads=4)\n",
    "        self.cross_attention = nn.MultiheadAttention(embed_dim=256, num_heads=4)\n",
    "        \n",
    "        # 최종 출력 크기\n",
    "        self.decoder_out = nn.Linear(256, input_dim)\n",
    "    \n",
    "    def encode(self, x, condition):\n",
    "        # 인코더에서 x와 condition을 결합\n",
    "        h = self.encoder(torch.cat([x, condition], dim=1))\n",
    "        mu = self.fc_mu(h)\n",
    "        logvar = self.fc_logvar(h)\n",
    "        return mu, logvar\n",
    "\n",
    "    def reparameterize(self, mu, logvar):\n",
    "        std = torch.exp(0.5 * logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + eps * std\n",
    "\n",
    "    def decode(self, z, condition):\n",
    "        # 디코더에서 z와 condition을 결합\n",
    "        h = self.decoder_fc(torch.cat([z, condition], dim=1))\n",
    "        \n",
    "        # Self-attention 적용\n",
    "        h = h.unsqueeze(0)  # (1, batch_size, feature_size)\n",
    "        attn_output, _ = self.self_attention(h, h, h)\n",
    "        \n",
    "        # Cross-attention 적용\n",
    "        condition_vector = condition.unsqueeze(0).expand_as(attn_output)  # (1, batch_size, feature_size)\n",
    "        attn_output, _ = self.cross_attention(attn_output, condition_vector, condition_vector)\n",
    "        \n",
    "        h = attn_output.squeeze(0)  # (batch_size, feature_size)\n",
    "        return self.decoder_out(h)\n",
    "    \n",
    "    def forward(self, x, condition):\n",
    "        mu, logvar = self.encode(x, condition)\n",
    "        z = self.reparameterize(mu, logvar)\n",
    "        recon_x = self.decode(z, condition)\n",
    "        return recon_x, mu, logvar"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "778a7d69-b3d4-40f1-8b08-ee376164c47b",
   "metadata": {},
   "source": [
    "* 손실함수 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f79ebd0-8ae0-4190-9dd8-8fb677d3fdf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_function(recon_x, x, mu, logvar):\n",
    "    recon_loss = nn.MSELoss()(recon_x, x)\n",
    "    kl_divergence = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "    return recon_loss + kl_divergence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31c0d579-b947-47b9-b732-fd61baa06411",
   "metadata": {},
   "source": [
    "* 모델 학습 코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55e71420-e7c8-4fef-a84a-c73023021120",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, dataloader, num_epochs=50):\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        total_loss = 0\n",
    "        for batch in dataloader:\n",
    "            features = batch['features']\n",
    "            age = batch['age_enc'].unsqueeze(1)\n",
    "            gender = batch['sex'].unsqueeze(1)\n",
    "            disease = batch['target'].unsqueeze(1)\n",
    "            \n",
    "            # condition 생성\n",
    "            condition = torch.cat([age, gender, disease], dim=1)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            recon_features, mu, logvar = model(features, condition)\n",
    "            loss = loss_function(recon_features, features, mu, logvar)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "        print(f\"Epoch {epoch + 1}, Loss: {total_loss / len(dataloader)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4c35938-822d-476f-bb6c-56eca428d1f5",
   "metadata": {},
   "source": [
    "* Synthetic data 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bddd363d-bf0c-4801-8ccb-3b74f86d2d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_synthetic_data(model, condition_list, num_samples=100):\n",
    "    model.eval()\n",
    "    synthetic_data = []\n",
    "    with torch.no_grad():\n",
    "        for condition in condition_list:\n",
    "            condition_tensor = torch.tensor(condition, dtype=torch.float32).unsqueeze(0)\n",
    "            z = torch.randn(num_samples, model.latent_dim)\n",
    "            samples = model.decode(z, condition_tensor.repeat(num_samples, 1))\n",
    "            synthetic_data.append(samples.numpy())\n",
    "    return np.vstack(synthetic_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ead35c0-9357-48f7-a099-2c90371b46c9",
   "metadata": {},
   "source": [
    "* 전체 코드 실행 예시"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2710c72f-6028-4ec1-a868-db5ad573d13c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 로드 및 전처리\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(data.drop(columns=['age_enc', 'sex', 'target']).values)  # 생체신호 변수만 사용하여 fit\n",
    "\n",
    "# PyTorch Dataset 생성\n",
    "dataset = BiometricDataset(data, scaler=scaler)\n",
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c730acc1-cd85-47f3-bde6-b3abc354260d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 초기화 및 학습\n",
    "input_dim = 11  # 생체신호 변수 개수\n",
    "condition_dim = 3  # 연령, 성별, 질병 변수 개수\n",
    "latent_dim = 10  # latent space 차원\n",
    "model = CVAEWithAttention(input_dim, condition_dim, latent_dim)\n",
    "train_model(model, dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd140100-c966-47ea-9265-d848f922b469",
   "metadata": {},
   "outputs": [],
   "source": [
    "# synthetic data 생성\n",
    "# 가정: 가상 환자 조건 샘플링 (예: [(50, 1, 2), (40, 0, 1)] 등) -> 연령, 성별, 질병 정보\n",
    "condition_list = [(50, 1, 2), (40, 0, 1)]\n",
    "synthetic_data = generate_synthetic_data(model, condition_list)\n",
    "print(\"Synthetic Data 생성 완료\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b059be2c-a71e-42dc-8029-2888b57e822c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9e88901-db55-42f2-8c36-88d9c9eddd4a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "253e0d40-466f-40a9-b9ac-5386feaeeedd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "011c1fff-f3f3-4eba-acb1-d6697d01a51d",
   "metadata": {},
   "source": [
    "# Third trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "15c34244-d129-430c-afcf-aeb0f63690b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_try = data_ori.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "c99aa285-39d4-4e6e-9e6d-f416f58567ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['sex', 'cp', 'trestbps', 'chol', 'fbs', 'restecg', 'thalach', 'exang',\n",
       "       'oldpeak', 'slope', 'ca', 'thal', 'target', 'age_enc'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_try.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "3b9ffdcb-604e-49ab-9c62-09c1ca999cbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target\n",
       "1    526\n",
       "0    260\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_try.target.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d0112374-1807-476c-834b-1d13668155c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. 연령, 성별, 질병 변수를 condition으로 사용하기 위해 분리\n",
    "x_data = data_try.drop(['sex', 'age_enc', 'target'], axis=1)\n",
    "conditions = data_try[['age_enc', 'sex', 'target']]  # 연령, 성별, 질병 변수\n",
    "\n",
    "# 3. 스케일링\n",
    "scaler = StandardScaler()\n",
    "x_data_scaled = scaler.fit_transform(x_data)\n",
    "\n",
    "# 4. PyTorch Dataset 생성\n",
    "class MedicalDataset(Dataset):\n",
    "    def __init__(self, x_data, conditions):\n",
    "        self.x_data = torch.tensor(x_data, dtype=torch.float32)\n",
    "        self.conditions = torch.tensor(conditions.values, dtype=torch.float32)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.x_data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.x_data[idx], self.conditions[idx]\n",
    "\n",
    "dataset = MedicalDataset(x_data_scaled, conditions)\n",
    "dataloader = DataLoader(dataset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "263c06db-cc83-4ba7-829d-e77836093363",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# CVAE 모델 정의\n",
    "class CVAE(nn.Module):\n",
    "    def __init__(self, input_dim, cond_dim, latent_dim):\n",
    "        super(CVAE, self).__init__()\n",
    "        \n",
    "        # 인코더\n",
    "        self.latent_dim = latent_dim  # latent_dim 속성 추가\n",
    "        self.encoder_fc1 = nn.Linear(input_dim + cond_dim, 128)\n",
    "        self.encoder_fc2 = nn.Linear(128, 64)\n",
    "        self.fc_mu = nn.Linear(64, latent_dim)\n",
    "        self.fc_logvar = nn.Linear(64, latent_dim)\n",
    "        \n",
    "        # 디코더\n",
    "        self.decoder_fc1 = nn.Linear(latent_dim + cond_dim, 64)\n",
    "        self.decoder_fc2 = nn.Linear(64, 128)\n",
    "        \n",
    "        # Attention Blocks\n",
    "        self.self_attention = nn.MultiheadAttention(embed_dim=128, num_heads=4)\n",
    "        self.cross_attention = nn.MultiheadAttention(embed_dim=128, num_heads=4)\n",
    "        \n",
    "        # Reconstructing layer\n",
    "        self.decoder_fc3 = nn.Linear(128, input_dim)\n",
    "        \n",
    "    def encode(self, x, cond):\n",
    "        x = torch.cat([x, cond], dim=1)\n",
    "        x = F.relu(self.encoder_fc1(x))\n",
    "        x = F.relu(self.encoder_fc2(x))\n",
    "        mu = self.fc_mu(x)\n",
    "        logvar = self.fc_logvar(x)\n",
    "        return mu, logvar\n",
    "\n",
    "    def reparameterize(self, mu, logvar):\n",
    "        std = torch.exp(0.5 * logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + eps * std\n",
    "\n",
    "    def decode(self, z, cond):\n",
    "        x = torch.cat([z, cond], dim=1)\n",
    "        x = F.relu(self.decoder_fc1(x))\n",
    "        x = F.relu(self.decoder_fc2(x))\n",
    "        \n",
    "        # Self-Attention: 생체신호-연령, 생체신호-성별 특징 반영\n",
    "        x = x.unsqueeze(0)  # (1, batch, feature) 형식으로 변환\n",
    "        x, _ = self.self_attention(x, x, x)\n",
    "        \n",
    "        # Cross-Attention: 연령, 성별이 생체신호에 주는 영향 반영\n",
    "        x, _ = self.cross_attention(x, x, x)\n",
    "        \n",
    "        x = x.squeeze(0)\n",
    "        x = self.decoder_fc3(x)\n",
    "        return x\n",
    "\n",
    "    def forward(self, x, cond):\n",
    "        mu, logvar = self.encode(x, cond)\n",
    "        z = self.reparameterize(mu, logvar)\n",
    "        recon_x = self.decode(z, cond)\n",
    "        return recon_x, mu, logvar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0e6b7340-9c38-4b4a-bd40-e68f2f2fcba5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 11.023799148831355\n",
      "Epoch 2, Loss: 10.529149994595361\n",
      "Epoch 3, Loss: 10.064863559247277\n",
      "Epoch 4, Loss: 9.753921567028716\n",
      "Epoch 5, Loss: 9.709560151621888\n",
      "Epoch 6, Loss: 9.612575754257863\n",
      "Epoch 7, Loss: 9.626881800838403\n",
      "Epoch 8, Loss: 9.487061672841623\n",
      "Epoch 9, Loss: 9.415604084199318\n",
      "Epoch 10, Loss: 9.381310149913526\n",
      "Epoch 11, Loss: 9.327868900832936\n",
      "Epoch 12, Loss: 9.335747211640724\n",
      "Epoch 13, Loss: 9.339203793280603\n",
      "Epoch 14, Loss: 9.121593329742664\n",
      "Epoch 15, Loss: 9.125183454906667\n",
      "Epoch 16, Loss: 9.088118186737137\n",
      "Epoch 17, Loss: 8.978340420710829\n",
      "Epoch 18, Loss: 8.952489702452837\n",
      "Epoch 19, Loss: 8.881169947655753\n",
      "Epoch 20, Loss: 8.893800536488152\n",
      "Epoch 21, Loss: 8.82877658523676\n",
      "Epoch 22, Loss: 8.830778068561894\n",
      "Epoch 23, Loss: 8.798233362251262\n",
      "Epoch 24, Loss: 8.73868811221523\n",
      "Epoch 25, Loss: 8.660898087285554\n",
      "Epoch 26, Loss: 8.704927672563315\n",
      "Epoch 27, Loss: 8.690282263525267\n",
      "Epoch 28, Loss: 8.61813292369891\n",
      "Epoch 29, Loss: 8.630260962566346\n",
      "Epoch 30, Loss: 8.565106826277482\n",
      "Epoch 31, Loss: 8.493140300721613\n",
      "Epoch 32, Loss: 8.480060451206663\n",
      "Epoch 33, Loss: 8.388716117722995\n",
      "Epoch 34, Loss: 8.315603707582897\n",
      "Epoch 35, Loss: 8.406361412456018\n",
      "Epoch 36, Loss: 8.204769241294182\n",
      "Epoch 37, Loss: 8.275976612974366\n",
      "Epoch 38, Loss: 8.360686828768587\n",
      "Epoch 39, Loss: 8.156327361672282\n",
      "Epoch 40, Loss: 8.182335870563225\n",
      "Epoch 41, Loss: 8.12177672640968\n",
      "Epoch 42, Loss: 8.258692821473566\n",
      "Epoch 43, Loss: 8.035947125073305\n",
      "Epoch 44, Loss: 8.054598257438524\n",
      "Epoch 45, Loss: 7.991401342338581\n",
      "Epoch 46, Loss: 8.120831147405028\n",
      "Epoch 47, Loss: 7.926044143793237\n",
      "Epoch 48, Loss: 7.892064490087766\n",
      "Epoch 49, Loss: 7.989034172232825\n",
      "Epoch 50, Loss: 7.951755727520426\n",
      "Epoch 51, Loss: 7.9261121191747925\n",
      "Epoch 52, Loss: 7.85271510155753\n",
      "Epoch 53, Loss: 7.862219880858754\n",
      "Epoch 54, Loss: 7.984268926178832\n",
      "Epoch 55, Loss: 7.8194551152430725\n",
      "Epoch 56, Loss: 7.872911060129413\n",
      "Epoch 57, Loss: 7.858511461253081\n",
      "Epoch 58, Loss: 7.865189181029342\n",
      "Epoch 59, Loss: 7.800950766216404\n",
      "Epoch 60, Loss: 7.711966788799101\n",
      "Epoch 61, Loss: 7.711019656737038\n",
      "Epoch 62, Loss: 7.826623348789361\n",
      "Epoch 63, Loss: 7.709033063349833\n",
      "Epoch 64, Loss: 7.741508580952807\n",
      "Epoch 65, Loss: 7.709788392821644\n",
      "Epoch 66, Loss: 7.618700469116521\n",
      "Epoch 67, Loss: 7.651513582574199\n",
      "Epoch 68, Loss: 7.5376061980657605\n",
      "Epoch 69, Loss: 7.50475967446053\n",
      "Epoch 70, Loss: 7.436049094940263\n",
      "Epoch 71, Loss: 7.574595016984236\n",
      "Epoch 72, Loss: 7.5066591607402\n",
      "Epoch 73, Loss: 7.58979257675831\n",
      "Epoch 74, Loss: 7.445275605179881\n",
      "Epoch 75, Loss: 7.502446570165891\n",
      "Epoch 76, Loss: 7.54373205830426\n",
      "Epoch 77, Loss: 7.366710866680582\n",
      "Epoch 78, Loss: 7.447896962250765\n",
      "Epoch 79, Loss: 7.500231580273189\n",
      "Epoch 80, Loss: 7.396842655638095\n",
      "Epoch 81, Loss: 7.438615852336544\n",
      "Epoch 82, Loss: 7.499974238660196\n",
      "Epoch 83, Loss: 7.34192321622038\n",
      "Epoch 84, Loss: 7.385379121503757\n",
      "Epoch 85, Loss: 7.317327154805035\n",
      "Epoch 86, Loss: 7.3539474914395475\n",
      "Epoch 87, Loss: 7.216562557463124\n",
      "Epoch 88, Loss: 7.226886331883399\n",
      "Epoch 89, Loss: 7.213480107353541\n",
      "Epoch 90, Loss: 7.162657497493365\n",
      "Epoch 91, Loss: 7.292033265868519\n",
      "Epoch 92, Loss: 7.264672645782393\n",
      "Epoch 93, Loss: 7.148811340332031\n",
      "Epoch 94, Loss: 7.225136405032403\n",
      "Epoch 95, Loss: 7.141519192217567\n",
      "Epoch 96, Loss: 7.290318379875358\n",
      "Epoch 97, Loss: 7.018108804717318\n",
      "Epoch 98, Loss: 7.15896725836601\n",
      "Epoch 99, Loss: 7.136270207606502\n",
      "Epoch 100, Loss: 7.038928587624741\n"
     ]
    }
   ],
   "source": [
    "def loss_function(recon_x, x, mu, logvar):\n",
    "    recon_loss = F.mse_loss(recon_x, x, reduction='sum')\n",
    "    kl_divergence = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "    return recon_loss + kl_divergence\n",
    "\n",
    "model = CVAE(input_dim=11, cond_dim=3, latent_dim=10)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "# 학습 루프\n",
    "num_epochs = 100\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    for x_batch, cond_batch in dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        recon_x, mu, logvar = model(x_batch, cond_batch)\n",
    "        loss = loss_function(recon_x, x_batch, mu, logvar)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "    print(f\"Epoch {epoch+1}, Loss: {train_loss / len(dataloader.dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c133e5c2-d65b-497b-bb61-bf3af2e15fdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 조건에 따른 synthetic data 생성 함수\n",
    "def generate_synthetic_data(model, sample_conditions_list):\n",
    "    synthetic_samples = []\n",
    "\n",
    "    for condition in sample_conditions_list:\n",
    "        age, gender, disease = condition\n",
    "\n",
    "        # 조건 텐서로 변환\n",
    "        condition_tensor = torch.tensor([age, gender, disease], dtype=torch.float32).unsqueeze(0)\n",
    "\n",
    "        # 잠재 공간에서 샘플링하여 synthetic data 생성\n",
    "        with torch.no_grad():\n",
    "            z = torch.randn(1, model.latent_dim)  # 모델의 latent_dim 크기에 맞게 샘플링\n",
    "            synthetic_sample = model.decode(z, condition_tensor)  # 조건을 적용하여 디코더로 생성\n",
    "            synthetic_samples.append(synthetic_sample.squeeze(0).numpy())  # numpy 배열로 변환\n",
    "\n",
    "    synthetic_data = np.array(synthetic_samples)\n",
    "    return synthetic_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "id": "58abd70a-5145-433a-8e81-679f34e54a77",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def sample_conditions(data, n):\n",
    "    # 조건 변수 선택\n",
    "    condition_data = data[['age_enc', 'sex', 'target']]\n",
    "    \n",
    "    # 목표 비율 계산 (target, sex, age_enc 각 클래스가 동일하게 분포된다고 가정)\n",
    "    total_count = len(condition_data) + n\n",
    "    unique_targets = condition_data['target'].unique()\n",
    "    unique_sexes = condition_data['sex'].unique()\n",
    "    unique_ages = condition_data['age_enc'].unique()\n",
    "    \n",
    "    target_goal_count = total_count / len(unique_targets)\n",
    "    sex_goal_count = total_count / (len(unique_targets) * len(unique_sexes))\n",
    "    age_goal_count = total_count / (len(unique_targets) * len(unique_sexes) * len(unique_ages))\n",
    "    \n",
    "    # 최종 샘플링 조건 리스트\n",
    "    sampled_conditions = []\n",
    "    \n",
    "    for target in unique_targets:\n",
    "        # target별로 필요한 샘플 수 계산\n",
    "        current_target_count = condition_data[condition_data['target'] == target].shape[0]\n",
    "        target_sample_count = max(0, int(target_goal_count - current_target_count))\n",
    "        \n",
    "        if target_sample_count > 0:\n",
    "            for sex in unique_sexes:\n",
    "                # sex별로 필요한 샘플 수 계산\n",
    "                target_sex_data = condition_data[(condition_data['target'] == target) & (condition_data['sex'] == sex)]\n",
    "                current_sex_count = target_sex_data.shape[0]\n",
    "                sex_sample_count = max(0, int(sex_goal_count - current_sex_count))\n",
    "                \n",
    "                if sex_sample_count > 0:\n",
    "                    for age in unique_ages:\n",
    "                        # age_enc별로 필요한 샘플 수 계산\n",
    "                        current_age_count = target_sex_data[target_sex_data['age_enc'] == age].shape[0]\n",
    "                        age_sample_count = max(0, int(age_goal_count - current_age_count))\n",
    "                        \n",
    "                        # 필요한 샘플 수만큼 조건 추가\n",
    "                        sampled_conditions.extend([[age, sex, target]] * age_sample_count)\n",
    "                        \n",
    "    # 최종 샘플링 조건 리스트 반환\n",
    "    return sampled_conditions[:n]  # 요청된 n개만 반환\n",
    "\n",
    "\n",
    "# 함수 실행 예시\n",
    "sampled_conditions_list = sample_conditions(data_try, 260)\n",
    "# print(sampled_conditions_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db1eb317-0d39-4d87-96c4-01277dd21774",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "id": "2c797987-1ed5-43be-beaa-31bfeb56de9e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 샘플링된 조건에 따른 synthetic data 생성\n",
    "synthetic_data = generate_synthetic_data(model, sampled_conditions_list)\n",
    "synthetic_data = scaler.inverse_transform(synthetic_data)  # 스케일링 역변환\n",
    "# print(\"Synthetic Data Generated:\\n\", synthetic_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "id": "fdc15b1c-647a-4879-bdc6-fc5617f01116",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(260, 11)"
      ]
     },
     "execution_count": 348,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "synthetic_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edb13210-482b-4810-8348-2258434eb1ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "id": "591be86d-4f48-466a-a073-3af2681f7f50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['age_enc', 'sex', 'target', 'cp', 'trestbps', 'chol', 'fbs', 'restecg',\n",
       "       'thalach', 'exang', 'oldpeak', 'slope', 'ca', 'thal'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 349,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_try.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "id": "afcfb904-8a6e-4045-ba9a-dd7d86b73673",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 예시용 변수 이름 목록 (생체신호 변수 이름 11개)\n",
    "signal_columns = ['cp', 'trestbps', 'chol', 'fbs', 'restecg', 'thalach', 'exang','oldpeak', 'slope', 'ca', 'thal']\n",
    "\n",
    "def create_synthetic_dataframe(synthetic_data, sample_conditions_list):\n",
    "    # 1. synthetic_data를 DataFrame으로 변환\n",
    "    synthetic_df = pd.DataFrame(synthetic_data, columns=signal_columns)\n",
    "    \n",
    "    # 2. sample_conditions_list를 DataFrame으로 변환\n",
    "    conditions_df = pd.DataFrame(sample_conditions_list, columns=['age_enc', 'sex', 'target'])\n",
    "    \n",
    "    # 3. synthetic_df와 conditions_df를 열 방향으로 결합\n",
    "    combined_df = pd.concat([conditions_df, synthetic_df], axis=1)\n",
    "    \n",
    "    return combined_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "id": "c847536a-15b8-4279-831f-4f9220bde724",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Synthetic DataFrame Shape: (260, 14)\n",
      "Synthetic DataFrame:\n",
      "      age_enc  sex  target        cp    trestbps        chol       fbs  \\\n",
      "0          2    1       0  0.745298  115.875313  215.286880 -0.011856   \n",
      "1          2    1       0  0.937059  130.197876  259.437744 -0.037308   \n",
      "2          2    1       0  0.815450  130.289551  231.322128 -0.028973   \n",
      "3          2    1       0  0.263390  123.105484  249.743134  0.385161   \n",
      "4          1    1       0  0.347753  120.127998  224.843948 -0.019644   \n",
      "..       ...  ...     ...       ...         ...         ...       ...   \n",
      "255        5    0       0 -0.467913  146.262314  273.678772 -0.058663   \n",
      "256        5    0       0  0.514561  130.019974  219.892151 -0.053984   \n",
      "257        5    0       0  1.165741  153.643204  309.787872  0.112906   \n",
      "258        5    0       0  0.972478  135.467651  217.171631  0.053369   \n",
      "259        5    0       0 -0.106641  162.670761  276.136383 -0.109894   \n",
      "\n",
      "      restecg     thalach     exang   oldpeak     slope        ca      thal  \n",
      "0    0.580106  149.460052  0.144458  0.394125  1.606972  1.070406  2.140567  \n",
      "1    0.638359  154.454895  0.344994  1.448831  1.421775  0.326687  3.022001  \n",
      "2    0.858442  141.678131  0.473527  2.217300  0.992834  0.009559  3.009585  \n",
      "3    0.293886  149.107132  0.228976  0.209591  1.787884  3.153171  2.539160  \n",
      "4    0.529717  147.629410  0.613146  0.791738  1.474576  0.464992  2.807143  \n",
      "..        ...         ...       ...       ...       ...       ...       ...  \n",
      "255  1.125067  125.900902  0.880721  2.864261  0.553667  1.746378  2.708917  \n",
      "256  1.122885  121.244545  0.503981  1.665931  0.963670  1.254134  2.199261  \n",
      "257  0.123365  146.084290  0.064300  0.973658  1.490043  2.159269  2.052257  \n",
      "258  1.069478  112.952492  0.419933  1.984408  0.938464  1.478960  1.582162  \n",
      "259  1.676759  121.345665  0.774837  3.373544  0.488191  1.608804  2.416462  \n",
      "\n",
      "[260 rows x 14 columns]\n"
     ]
    }
   ],
   "source": [
    "synthetic_df = create_synthetic_dataframe(synthetic_data, sampled_conditions_list)\n",
    "\n",
    "print(\"Final Synthetic DataFrame Shape:\", synthetic_df.shape)\n",
    "print(\"Synthetic DataFrame:\\n\", synthetic_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "id": "4dbfc8b1-df61-490d-b98f-a2bc000b5883",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target\n",
       "0    260\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 352,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "synthetic_df.target.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "id": "533717d9-2d59-4ed7-9370-0e6bb81a81ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['age_enc', 'sex', 'target', 'cp', 'trestbps', 'chol', 'fbs', 'restecg',\n",
       "       'thalach', 'exang', 'oldpeak', 'slope', 'ca', 'thal'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 353,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_try.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "id": "f66b928f-29f6-411f-bfcf-8426abe146f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['age_enc', 'sex', 'target', 'cp', 'trestbps', 'chol', 'fbs', 'restecg',\n",
       "       'thalach', 'exang', 'oldpeak', 'slope', 'ca', 'thal'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 354,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "synthetic_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "142f00a4-758c-4aed-a5e6-2f97ba0b02d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "id": "269dbb8a-1a0e-47aa-b65f-167b5eed0541",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 예시: synthetic_df와 data의 컬럼 순서를 맞추기\n",
    "data_try = data_try[synthetic_df.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "id": "7fa5f06c-6aae-43b6-8d9b-7fbd9b782c3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['age_enc', 'sex', 'target', 'cp', 'trestbps', 'chol', 'fbs', 'restecg',\n",
       "       'thalach', 'exang', 'oldpeak', 'slope', 'ca', 'thal'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 356,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_try.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "id": "72740c4b-5acb-4ff6-a609-3f822bbc710e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined DataFrame shape: (1046, 14)\n",
      "Combined DataFrame:\n",
      "    age_enc  sex  target   cp  trestbps   chol  fbs  restecg  thalach  exang  \\\n",
      "0        3    1       0  0.0     120.0  188.0  0.0      1.0    113.0    0.0   \n",
      "1        2    0       0  0.0     132.0  341.0  1.0      0.0    136.0    1.0   \n",
      "2        4    0       0  2.0     130.0  263.0  0.0      1.0     97.0    0.0   \n",
      "3        4    0       0  2.0     130.0  263.0  0.0      1.0     97.0    0.0   \n",
      "4        2    1       0  2.0     108.0  243.0  0.0      1.0    152.0    0.0   \n",
      "\n",
      "   oldpeak  slope   ca  thal  \n",
      "0      1.4    1.0  1.0   3.0  \n",
      "1      3.0    1.0  0.0   3.0  \n",
      "2      1.2    1.0  1.0   3.0  \n",
      "3      1.2    1.0  1.0   3.0  \n",
      "4      0.0    2.0  0.0   2.0  \n",
      "------------------------------------------\n",
      "Combined DataFrame:\n",
      "       age_enc  sex  target        cp    trestbps        chol       fbs  \\\n",
      "1041        5    0       0 -0.467913  146.262314  273.678772 -0.058663   \n",
      "1042        5    0       0  0.514561  130.019974  219.892151 -0.053984   \n",
      "1043        5    0       0  1.165741  153.643204  309.787872  0.112906   \n",
      "1044        5    0       0  0.972478  135.467651  217.171631  0.053369   \n",
      "1045        5    0       0 -0.106641  162.670761  276.136383 -0.109894   \n",
      "\n",
      "       restecg     thalach     exang   oldpeak     slope        ca      thal  \n",
      "1041  1.125067  125.900902  0.880721  2.864261  0.553667  1.746378  2.708917  \n",
      "1042  1.122885  121.244545  0.503981  1.665931  0.963670  1.254134  2.199261  \n",
      "1043  0.123365  146.084290  0.064300  0.973658  1.490043  2.159269  2.052257  \n",
      "1044  1.069478  112.952492  0.419933  1.984408  0.938464  1.478960  1.582162  \n",
      "1045  1.676759  121.345665  0.774837  3.373544  0.488191  1.608804  2.416462  \n"
     ]
    }
   ],
   "source": [
    "# synthetic_df와 data를 결합\n",
    "combined_df = pd.concat([data_try, synthetic_df], ignore_index=True)\n",
    "\n",
    "# 결과 확인\n",
    "print(\"Combined DataFrame shape:\", combined_df.shape)\n",
    "print(\"Combined DataFrame:\\n\", combined_df.head())\n",
    "print(\"------------------------------------------\")\n",
    "print(\"Combined DataFrame:\\n\", combined_df.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "id": "0a3fc2cd-8e9a-4e8d-9146-16f4ead9a247",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target\n",
       "1    526\n",
       "0    520\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 358,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df.target.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "id": "75aa3618-dd7e-4ca7-91fe-762e20f46967",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target\n",
       "1    526\n",
       "0    260\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 359,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_try.target.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "id": "08be84e0-3231-42fe-9098-b52c496b5762",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_vis = combined_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "id": "9f4f6b7a-a530-4355-ae5c-09c7f6095b47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x700 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x700 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# main_dx별 개수 계산\n",
    "main_dx_counts = data_vis['target'].value_counts()\n",
    "\n",
    "# main_dx별 성별 비율 계산 (성별이 'M'과 'F'로 나누어짐)\n",
    "gender_counts = data_vis.groupby(['target', 'sex']).size().unstack(fill_value=0)\n",
    "gender_ratio = gender_counts.div(gender_counts.sum(axis=1), axis=0)\n",
    "\n",
    "# main_dx별 연령대 비율 계산 (연령대별 비율 계산)\n",
    "age_counts = data_vis.groupby(['target', 'age_enc']).size().unstack(fill_value=0)\n",
    "age_ratio = age_counts.div(age_counts.sum(axis=1), axis=0)\n",
    "\n",
    "# 그래프 크기 설정\n",
    "plt.figure(figsize=(10, 7))\n",
    "fig, ax = plt.subplots(figsize=(10, 7))\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams['font.family'] = 'Times New Roman'\n",
    "\n",
    "# x 위치 설정 (막대의 중심이 각 main_dx에 맞도록)\n",
    "x = range(len(main_dx_counts))\n",
    "\n",
    "# main_dx의 개수에 대한 막대 그리기\n",
    "bar_width = 0.15\n",
    "plt.bar(x, main_dx_counts.values, width=bar_width, label='Total Count', align='center')\n",
    "\n",
    "# 성별 비율에 대한 막대 그리기 (남성 비율, 여성 비율)\n",
    "male_height = gender_ratio.loc[main_dx_counts.index, 0] * main_dx_counts.values\n",
    "female_height = gender_ratio.loc[main_dx_counts.index, 1] * main_dx_counts.values\n",
    "plt.bar([i + bar_width for i in x], male_height, width=bar_width, label='Male Proportion', align='center')\n",
    "plt.bar([i + bar_width for i in x], female_height, bottom=male_height, width=bar_width, label='Female Proportion', align='center')\n",
    "\n",
    "# 연령대 비율에 대한 막대 그리기 (각 연령대에 대해 표시)\n",
    "age_bar_width = 0.15  # 연령대 막대 너비 설정\n",
    "bottoms = 0\n",
    "\n",
    "# 연령대별 막대 그리기\n",
    "for i, age_group in enumerate(age_ratio.columns):\n",
    "    age_height = age_ratio.loc[main_dx_counts.index, age_group] * main_dx_counts.values\n",
    "    plt.bar([i + bar_width*2 for i in x], age_height, width=age_bar_width, label=f'Age Group {age_group}', align='center', bottom=bottoms)\n",
    "    # 누적된 bottom 값 업데이트\n",
    "    bottoms += age_height\n",
    "\n",
    "# x축, y축, 레이블 설정\n",
    "plt.xlabel('Main Diagnosis')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "# x축의 main_dx 이름을 세 개의 막대 중앙에 맞추기\n",
    "plt.xticks([i + bar_width for i in x], main_dx_counts.index, rotation=0)\n",
    "ax.set_xticklabels(['Heart Disease', 'Normal'])\n",
    "\n",
    "# Legend 이름 변경\n",
    "plt.legend(loc='center')\n",
    "\n",
    "# 그래프 표시\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0740dd1f-22bc-435d-b769-91ed74d67e5d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c74dc081-9938-408b-9069-372b5f621d42",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3930f1e1-1cc4-4dd2-a38f-c436e6ba059a",
   "metadata": {},
   "source": [
    "# Fourth Trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "id": "8782841e-7396-420c-8a1a-6042e2cedfc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_fourth = data_ori.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "id": "8955c349-cbe1-4095-a42e-65a5f5693bb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.1 Scaler로 연속형 데이터 정규화\n",
    "scaler = StandardScaler()\n",
    "continuous_features =['cp', 'trestbps', 'chol', 'fbs', 'restecg', 'thalach', 'exang','oldpeak', 'slope', 'ca', 'thal']\n",
    "data_fourth[continuous_features] = scaler.fit_transform(data_fourth[continuous_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "id": "01ff54e0-858d-4298-b55f-2246e4785c95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['sex', 'cp', 'trestbps', 'chol', 'fbs', 'restecg', 'thalach', 'exang',\n",
       "       'oldpeak', 'slope', 'ca', 'thal', 'target', 'age_enc'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 366,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_fourth.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "id": "e08d76ed-1f56-4b1b-8ef1-f54f1c49ac0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.2 PyTorch Dataset 정의\n",
    "class MedicalDataset(Dataset):\n",
    "    def __init__(self, dataframe):\n",
    "        self.data = dataframe\n",
    "        self.features = dataframe[continuous_features].values.astype(np.float32)\n",
    "        self.conditions = dataframe[['age_enc', 'sex', 'target']].values.astype(np.float32)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return torch.tensor(self.features[idx]), torch.tensor(self.conditions[idx])\n",
    "\n",
    "# Dataset 및 DataLoader 생성\n",
    "dataset = MedicalDataset(data_fourth)\n",
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "id": "51642e4e-4630-4c14-b4b3-342e6bb09897",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multi-Head Self-Attention Block\n",
    "class MultiHeadSelfAttention(nn.Module):\n",
    "    def __init__(self, embed_size, heads):\n",
    "        super(MultiHeadSelfAttention, self).__init__()\n",
    "        self.embed_size = embed_size\n",
    "        self.heads = heads\n",
    "        self.head_dim = embed_size // heads\n",
    "\n",
    "        assert self.head_dim * heads == embed_size, \"Embed size must be divisible by heads\"\n",
    "\n",
    "        self.values = nn.Linear(self.head_dim, embed_size, bias=False)\n",
    "        self.keys = nn.Linear(self.head_dim, embed_size, bias=False)\n",
    "        self.queries = nn.Linear(self.head_dim, embed_size, bias=False)\n",
    "        self.fc_out = nn.Linear(embed_size, embed_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        N, seq_length, embed_size = x.shape\n",
    "        values = self.values(x)\n",
    "        keys = self.keys(x)\n",
    "        queries = self.queries(x)\n",
    "\n",
    "        # Attention score 계산\n",
    "        energy = torch.einsum(\"nqk,nvk->nqv\", [queries, keys])  # (N, seq_length, seq_length)\n",
    "        attention = torch.softmax(energy / (self.embed_size ** (1/2)), dim=2)\n",
    "\n",
    "        out = torch.einsum(\"nqv,nvk->nqk\", [attention, values])\n",
    "        out = self.fc_out(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "# Cross-Attention Block\n",
    "class CrossAttention(nn.Module):\n",
    "    def __init__(self, embed_size):\n",
    "        super(CrossAttention, self).__init__()\n",
    "        self.embed_size = embed_size\n",
    "        self.query = nn.Linear(embed_size, embed_size)\n",
    "        self.key = nn.Linear(embed_size, embed_size)\n",
    "        self.value = nn.Linear(embed_size, embed_size)\n",
    "\n",
    "    def forward(self, x, context):\n",
    "        queries = self.query(x)\n",
    "        keys = self.key(context)\n",
    "        values = self.value(context)\n",
    "\n",
    "        # Attention score 계산\n",
    "        energy = torch.einsum(\"nqk,nvk->nqv\", [queries, keys])\n",
    "        attention = torch.softmax(energy / (self.embed_size ** (1/2)), dim=2)\n",
    "\n",
    "        out = torch.einsum(\"nqv,nvk->nqk\", [attention, values])\n",
    "        return out\n",
    "\n",
    "\n",
    "# CVAE 모델 정의\n",
    "class CVAE(nn.Module):\n",
    "    def __init__(self, input_dim, condition_dim, latent_dim):\n",
    "        super(CVAE, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_dim + condition_dim, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.fc_mu = nn.Linear(64, latent_dim)\n",
    "        self.fc_logvar = nn.Linear(64, latent_dim)\n",
    "\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(latent_dim + condition_dim, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 128),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.self_attention = MultiHeadSelfAttention(embed_size=128, heads=4)\n",
    "        self.cross_attention = CrossAttention(embed_size=128)\n",
    "        self.final_layer = nn.Linear(128, input_dim)\n",
    "\n",
    "    def reparameterize(self, mu, logvar):\n",
    "        std = torch.exp(0.5 * logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + eps * std\n",
    "\n",
    "    def forward(self, x, conditions):\n",
    "        # 인코더\n",
    "        encoder_input = torch.cat([x, conditions], dim=1)\n",
    "        encoded = self.encoder(encoder_input)\n",
    "        mu = self.fc_mu(encoded)\n",
    "        logvar = self.fc_logvar(encoded)\n",
    "        z = self.reparameterize(mu, logvar)\n",
    "\n",
    "        # 디코더\n",
    "        decoder_input = torch.cat([z, conditions], dim=1)\n",
    "        decoded = self.decoder(decoder_input)\n",
    "\n",
    "        # Attention 적용\n",
    "        decoded = self.self_attention(decoded.unsqueeze(1)).squeeze(1)\n",
    "        decoded = self.cross_attention(decoded.unsqueeze(1), conditions.unsqueeze(1)).squeeze(1)\n",
    "\n",
    "        # 최종 출력\n",
    "        reconstructed = self.final_layer(decoded)\n",
    "        return reconstructed, mu, logvar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "id": "87a34f68-70ed-486d-b03a-da05f86fb154",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (32x128 and 32x128)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[371], line 19\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch_features, batch_conditions \u001b[38;5;129;01min\u001b[39;00m dataloader:\n\u001b[0;32m     18\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m---> 19\u001b[0m     reconstructed, mu, logvar \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_conditions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     20\u001b[0m     loss \u001b[38;5;241m=\u001b[39m loss_function(reconstructed, batch_features, mu, logvar)\n\u001b[0;32m     21\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\paper\\lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\paper\\lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[370], line 94\u001b[0m, in \u001b[0;36mCVAE.forward\u001b[1;34m(self, x, conditions)\u001b[0m\n\u001b[0;32m     91\u001b[0m decoded \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecoder(decoder_input)\n\u001b[0;32m     93\u001b[0m \u001b[38;5;66;03m# Attention 적용\u001b[39;00m\n\u001b[1;32m---> 94\u001b[0m decoded \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mself_attention\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdecoded\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munsqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     95\u001b[0m decoded \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcross_attention(decoded\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m1\u001b[39m), conditions\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m1\u001b[39m))\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     97\u001b[0m \u001b[38;5;66;03m# 최종 출력\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\paper\\lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\paper\\lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[370], line 18\u001b[0m, in \u001b[0;36mMultiHeadSelfAttention.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m     17\u001b[0m     N, seq_length, embed_size \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mshape\n\u001b[1;32m---> 18\u001b[0m     values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     19\u001b[0m     keys \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkeys(x)\n\u001b[0;32m     20\u001b[0m     queries \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mqueries(x)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\paper\\lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\paper\\lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\paper\\lib\\site-packages\\torch\\nn\\modules\\linear.py:117\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    116\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (32x128 and 32x128)"
     ]
    }
   ],
   "source": [
    "from torch.optim import Adam\n",
    "\n",
    "# 모델 및 손실 함수 정의\n",
    "model = CVAE(input_dim=11, condition_dim=3, latent_dim=10)\n",
    "optimizer = Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "def loss_function(recon_x, x, mu, logvar):\n",
    "    recon_loss = F.mse_loss(recon_x, x, reduction=\"sum\")\n",
    "    kl_div = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "    return recon_loss + kl_div\n",
    "\n",
    "# 학습 루프\n",
    "num_epochs = 50\n",
    "model.train()\n",
    "for epoch in range(num_epochs):\n",
    "    total_loss = 0\n",
    "    for batch_features, batch_conditions in dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        reconstructed, mu, logvar = model(batch_features, batch_conditions)\n",
    "        loss = loss_function(reconstructed, batch_features, mu, logvar)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    print(f\"Epoch {epoch + 1}, Loss: {total_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fced782f-6168-4db6-af0e-f1a930fafda3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7da03e3a-4071-446c-b9e4-8afbb2b10c6e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4b1b9a4-f533-4bc0-a9a1-c7fbc0464c4a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15221724-31d5-4750-853d-8a16e67cf3c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e83e6f2-0d83-415e-b843-c6828415a4ac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
